{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "CleanDinAEDec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNHzBS8nvpZB"
      },
      "source": [
        "# Init "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5iO50AvvpZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc6731e-f5ac-4fc4-cedb-469a8355b5be"
      },
      "source": [
        "#Import data \n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "from random import randrange\n",
        "import sklearn\n",
        "from sklearn import decomposition\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse import diags\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.ndimage.morphology import distance_transform_edt as bwdist\n",
        "import scipy.ndimage as nd\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import scipy.stats as ss \n",
        "from keras.constraints import Constraint\n",
        "from keras import backend as K\n",
        "from datetime import date, datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1516245111902222615\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14638920512\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 14770454739934563556\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg2QP-hPvpZM"
      },
      "source": [
        "# Parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EB_5VAtvpZP"
      },
      "source": [
        "DirSAVE                     = '/'\n",
        "flagTrWMissingData          = 0  # Training phase with or without missing data\n",
        "flagloadOIData              = 0    # load OI: work on rough variable or anomaly\n",
        "lname_cov                   = [\"ssh_mod\"]\n",
        "lid_cov                     = [\"OI\"]\n",
        "size_tw                     = 1   # Length of the 4th dimension          \n",
        "Wsquare                     = 4     # half-width of holes\n",
        "Nsquare                     = 3     # number of holes\n",
        "DimAE                       = 20  # Dimension of the latent space\n",
        "flagLoadModel               = 0     # load pre-defined AE model or not\n",
        "sigNoise                    = 1e-1\n",
        "flagTrOuputWOMissingData    = 1\n",
        "stdMask                     = 0.\n",
        "dropout                     = 0.03 #[0.6,0.7,0.8]0.03\n",
        "wl2                         = 0.0000\n",
        "batch_size                  = 16# monter un peu \n",
        "NbEpoc                      = 14\n",
        "Niter                       = 14\n",
        "thrMisData                  = 0\n",
        "flagPred                    = False #1 pour prediction, sinon interp\n",
        "FlagextendTr                = False #true pour depasser la taille de train de base\n",
        "N_cov                       = 0\n",
        "flagUseMaskinEncoder        = 0\n",
        "\n",
        "def createGlobParams(params):\n",
        "    return dict(((k, eval(k)) for k in params))\n",
        "list_globParams=[\n",
        "    'flagTrOuputWOMissingData','flagTrWMissingData',\\\n",
        "    'flagloadOIData','size_tw','Wsquare',\\\n",
        "    'Nsquare','DimAE','flagLoadModel',\\\n",
        "    'sigNoise',\\\n",
        "    'stdMask',\\\n",
        "    'dropout','wl2','batch_size',\\\n",
        "    'NbEpoc','Niter','DirSAVE','flagPred','FlagextendTr','N_cov']\n",
        "globParams = createGlobParams(list_globParams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ovPNEb-vpZV"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTnPawODvpZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3648c6-3a41-438e-d22b-e68b944b9b64"
      },
      "source": [
        "dataset= np.load(\"/content/drive/My Drive/DATA/Thèse/ZOI/Dataset_64_ZOI.npy\",allow_pickle='TRUE').item()\n",
        "dataH=dataset['CSED_Hourly']\n",
        "mask=dataset['Cloud_Daily']\n",
        "lat_grid=dataset['Lat_ZOI']\n",
        "lon_grid=dataset['Lon_ZOI']\n",
        "#corr lalpaciens var exp des norm\n",
        "# =============================================================================\n",
        "# Creation of the test and training dataset\n",
        "# =============================================================================\n",
        "def prepdata(xH,mask,N_Catalog=0):\n",
        "    if N_Catalog!=0:\n",
        "        test=np.zeros(mask[-365:].shape)\n",
        "        for i in range(0,len(test)):\n",
        "            test[i]=xH[26304+i*24+12].reshape(test.shape[1],test.shape[2])\n",
        "\n",
        "        train=np.zeros((N_Catalog*365,xH.shape[1],xH.shape[2]))\n",
        "\n",
        "        for i in range(N_Catalog):\n",
        "            for j in range(len(test)):\n",
        "                h=randrange(0,24)\n",
        "                train[i*365+j]=xH[i*365+j*24+h]\n",
        "    else:\n",
        "        xD=np.empty((xH.shape[0]//24,xH.shape[1],xH.shape[2]))\n",
        "        for i in range(len(xD)):\n",
        "            xD[i]=xH[12+i*24]\n",
        "    mask_train = mask[:-100]\n",
        "    mask_pred  = mask[-100:]\n",
        "    x_train    = xD[:len(mask_train)]\n",
        "    #y_pred     = xD[len(mask_train)-100:len(mask_train)]\n",
        "    y_pred     = xD[len(mask_train):len(mask_train)+len(mask_pred)]\n",
        "    return mask_train,mask_pred,x_train,y_pred\n",
        "\n",
        "\n",
        "mask[np.where(mask==0)]=1;mask[np.where(np.isnan(mask))]=0 # O for missing data\n",
        "mask_train,mask_pred,x_train,y_pred = prepdata(dataH,mask)\n",
        "\n",
        "x_train,x_test,mask_train,mask_test=sklearn.model_selection.train_test_split(x_train,mask_train,test_size=0.33)\n",
        "# list of test dates\n",
        "indN_Tt = np.arange(len(x_train),len(x_train)+len(x_test))\n",
        "indN_Tr = np.arange(len(x_train))\n",
        "lday_test=[ datetime.strftime(datetime.strptime(\"2001-1-01\",'%Y-%m-%d')\\\n",
        "                      + timedelta(days=np.float64(i)),\"%Y-%m-%d\") for i in indN_Tt ]\n",
        "indLat     = np.arange(0,64)\n",
        "indLon     = np.arange(0,64)      \n",
        "print(indLat.shape,indLon.shape,indN_Tr.shape,indN_Tt.shape)\n",
        "print(x_train.shape,x_test.shape,y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64,) (64,) (895,) (441,)\n",
            "(895, 64, 64) (441, 64, 64) (100, 64, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa-gXMCZvpZc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "dff41bac-6f91-487a-cf4e-d6b8b1ac5b72"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(mask_pred[7].reshape(64,64))\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7ff6d33f17b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1WOy6QyvpZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219e4265-1c8a-45ea-9b0c-250a299e7298"
      },
      "source": [
        "gt_train= x_train\n",
        "gt_test = x_test\n",
        "gt_pred = np.copy(y_pred)\n",
        "err_train = np.random.normal(0,thrMisData*np.nanvar(x_train),(x_train.shape))\n",
        "err_test = np.random.normal(0,thrMisData*np.nanvar(x_test),(x_test.shape))\n",
        "err_pred = np.random.normal(0,thrMisData*np.nanvar(y_pred),(y_pred.shape))\n",
        "\n",
        "stdsc=sklearn.preprocessing.StandardScaler()\n",
        "stdsc.fit(y_pred.reshape(y_pred.shape[0],-1))\n",
        "mean_Tr = stdsc.mean_\n",
        "medabs  = np.copy(mean_Tr)\n",
        "med     = np.copy(mean_Tr)\n",
        "\n",
        "for i in range(len(medabs)):\n",
        "  med[i]    =np.nanmedian(gt_train.reshape(gt_train.shape[0],-1)[:,i])\n",
        "  medabs[i] =np.nanmedian(np.absolute(gt_train.reshape(gt_train.shape[0],-1)[:,i]-med[i]))\n",
        "  \n",
        "\n",
        "print('MEAN',mean_Tr.shape)\n",
        "std_Tr = stdsc.var_\n",
        "\n",
        "gt_train        = gt_train.reshape(x_train.shape[0],-1)-mean_Tr\n",
        "x_train         = x_train.reshape(x_train.shape[0],-1)-mean_Tr\n",
        "#x_train_missing = stdsc.fit_transform(x_train_missing.reshape(x_train_missing.shape[0],-1))\n",
        "gt_test         = gt_test.reshape(len(x_test),-1)-mean_Tr                       \n",
        "x_test          = x_test.reshape(len(x_test),-1)-mean_Tr\n",
        "#x_test_missing  = stdsc.fit_transform(x_test_missing.reshape(x_test_missing.shape[0],-1))\n",
        "#y_pred_missing  = stdsc.fit_transform(y_pred_missing.reshape(len(y_pred),-1))\n",
        "y_pred          = y_pred.reshape(len(y_pred),-1)-mean_Tr\n",
        "#gt_pred         = stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1))\n",
        "\n",
        "if flagTrWMissingData == 1 :\n",
        "    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n",
        "else :\n",
        "    mask_train[:]=1\n",
        "    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n",
        "\n",
        "x_test_missing=x_test.reshape(x_test.shape[0],indLat.shape[0],indLon.shape[0])*mask_test\n",
        "if flagPred:\n",
        "  mask_pred[len(mask_pred)//2:,:,:] = 0\n",
        "y_pred_missing=y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0])*mask_pred\n",
        "\n",
        "#Dimensionning                           \n",
        "gt_train        = gt_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_train         = x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_train_missing = x_train_missing.reshape(x_train_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "mask_train      = mask_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "\n",
        "gt_test         = gt_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_test          = x_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_test_missing  = x_test_missing.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)   \n",
        "mask_test       = mask_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "\n",
        "#gt_pred         = gt_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "y_pred          = y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "y_pred_missing  = y_pred_missing.reshape(y_pred_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "mask_pred       = mask_pred.reshape(mask_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "\n",
        "#Change Nan to 0 Check isany Nan/inf \n",
        "def isany(x):\n",
        "    x[np.where(np.isnan(x))]=0\n",
        "    print(np.any(np.isnan(x)))\n",
        "    print(np.any(np.isinf(x)))\n",
        "    print(x.shape)\n",
        "\n",
        "isany(x_train)\n",
        "isany(x_test)\n",
        "isany(x_train_missing)\n",
        "isany(x_test_missing)\n",
        "isany(mask_test)\n",
        "isany(mask_train)\n",
        "isany(y_pred)\n",
        "isany(y_pred_missing)\n",
        "isany(x_train)\n",
        "isany(gt_test)\n",
        "isany(gt_train)\n",
        "#isany(gt_pred)\n",
        "\n",
        "\n",
        "print(\"... (after normalization) mean Tr = %f\"%(np.mean(gt_train)))\n",
        "print(\"... (after normalization) mean Tt = %f\"%(np.mean(gt_test)))\n",
        "#print(\"... (after normalization) mean Pred = %f\"%(np.mean(gt_pred)))\n",
        "print(\"... (after normalization) mean x_train = %f\"%(np.mean(x_train)))\n",
        "print(\"... (after normalization) mean x_train_missing = %f\"%(np.mean(x_train_missing)))\n",
        "print(\"... (after normalization) mean x_test = %f\"%(np.mean(x_test)))\n",
        "print(\"... (after normalization) mean x_test_missing = %f\"%(np.mean(x_test_missing)))\n",
        "print(\"... (after normalization) mean y_pred = %f\"%(np.mean(y_pred)))\n",
        "print(\"... (after normalization) mean y_pred_missing = %f\"%(np.mean(y_pred_missing)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  result = op(x, *args, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered\n",
            "  overwrite_input=overwrite_input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MEAN (4096,)\n",
            "False\n",
            "False\n",
            "(895, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(441, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(895, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(441, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(441, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(895, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(100, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(100, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(895, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(441, 64, 64, 1)\n",
            "False\n",
            "False\n",
            "(895, 64, 64, 1)\n",
            "... (after normalization) mean Tr = 0.099569\n",
            "... (after normalization) mean Tt = 0.085622\n",
            "... (after normalization) mean x_train = 0.099569\n",
            "... (after normalization) mean x_train_missing = 0.099569\n",
            "... (after normalization) mean x_test = 0.085622\n",
            "... (after normalization) mean x_test_missing = 0.015756\n",
            "... (after normalization) mean y_pred = -0.000000\n",
            "... (after normalization) mean y_pred_missing = -0.004867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93mvfED-vpZn"
      },
      "source": [
        "### Define AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0NuuUoBvpZo"
      },
      "source": [
        "def fl24(dict_global_Params,x_data,mask_data):\n",
        "\n",
        "     # import Global Parameters\n",
        "    for key,val in dict_global_Params.items():\n",
        "        exec(\"globals()['\"+key+\"']=val\")\n",
        "\n",
        "    DimCAE = DimAE\n",
        "\n",
        "    input_layer = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n",
        "    mask       = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n",
        "\n",
        "    x = keras.layers.Conv2D(DimAE,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(input_layer)            \n",
        "    x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n",
        "    x = keras.layers.Conv2D(2*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n",
        "    x = keras.layers.Conv2D(4*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n",
        "    x = keras.layers.Conv2D(8*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    #x = keras.layers.Dropout(dropout)(x)\n",
        "    #x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n",
        "    #x = keras.layers.Conv2D(16*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.AveragePooling2D((5,5), padding='valid')(x)\n",
        "    x = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    \n",
        "    encoder    = keras.models.Model([input_layer,mask],x)\n",
        "                 \n",
        "    decoder_input = keras.layers.Input(shape=(int(np.floor(x_data.shape[1]/40)),int(np.floor(x_data.shape[2]/40)),DimAE))    \n",
        "    x = keras.layers.Conv2DTranspose(256,(32,32),strides=(32,32),use_bias=False,activation='relu',padding='same',output_padding=None,kernel_regularizer=keras.regularizers.l2(wl2))(decoder_input)\n",
        "    x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.Conv2DTranspose(128,(3,3),strides=(2,2),use_bias=False,activation='relu',padding='same',output_padding=None,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.Conv2D(64,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    \n",
        "    for kk in range(0,2):\n",
        "        dx = keras.layers.Conv2D(128,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "        dx = keras.layers.Dropout(dropout)(dx)\n",
        "        dx = keras.layers.Conv2D(64,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "        dx = keras.layers.Dropout(dropout)(dx)\n",
        "        x  = keras.layers.Add()([x,dx])\n",
        "\n",
        "    x = keras.layers.Conv2D(int(x_data.shape[3]/(N_cov+1)),(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "    decoder       = keras.models.Model(decoder_input,x)\n",
        "      \n",
        "    encoder.summary()\n",
        "    decoder.summary()\n",
        "\n",
        "    input_data = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n",
        "    mask       = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n",
        "    x          = decoder(encoder([input_data,mask]))\n",
        "    model_AE   = keras.models.Model([input_data,mask],x)\n",
        "  \n",
        "    #model_AE.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=1e-3))\n",
        "    size_tw = int(x_data.shape[3]/(N_cov+1))\n",
        "    model_AE.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=1e-3))\n",
        "    model_AE.summary()\n",
        "\n",
        "    if DimCAE > x_data.shape[0] :\n",
        "        DimCAE = DimAE\n",
        "\n",
        "    return  encoder, decoder, model_AE, DimCAE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg0RKrt2vpZx"
      },
      "source": [
        "def define_DINConvAE(NiterProjection,model_AE,shape,\\\n",
        "                    size_tw,N_cov=0):\n",
        "                     \n",
        "\n",
        "    # encoder-decoder with masked data\n",
        "    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    \n",
        "    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n",
        "    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n",
        "\n",
        "    # Iterations of fixed-point projection\n",
        "    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n",
        "    for kk in range(0,NiterProjection):\n",
        "        x_proj   = model_AE([x,mask])\n",
        "        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n",
        "        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n",
        "        x        = keras.layers.Add()([x,x_proj])\n",
        "\n",
        "    x_proj = model_AE([x,mask]) \n",
        "    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n",
        "\n",
        "    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "\n",
        "    maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n",
        "      \n",
        "    x_proj = global_model_FP([x_input,maskg])\n",
        "\n",
        "  \n",
        "    # AE error with x_proj\n",
        "    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj2 = model_AE([x_proj,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n",
        "    err2    = error(x_proj,x_proj2,mask,size_tw,shape,0,N_cov)\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj3 = model_AE([x_proj,keras.layers.Lambda(lambda x:0.*x)(mask)])\n",
        "    err3    = error(x_proj3,x_proj,mask,size_tw,shape,0,N_cov)\n",
        "    # add all errors\n",
        "    err    = keras.layers.Add()([err1,err2])\n",
        "    err    = keras.layers.Add()([err,err3])\n",
        "\n",
        "    # return global model\n",
        "    global_model_FP_Masked  = keras.models.Model([x_input,mask],err)\n",
        "    global_model_FP.summary()\n",
        "    global_model_FP_Masked.summary()\n",
        "  \n",
        "    return global_model_FP,global_model_FP_Masked\n",
        "\n",
        "def slice_layer(index):\n",
        "    def func(x_input):\n",
        "        return tf.gather(x_input, index, axis=3)\n",
        "    return keras.layers.Lambda(func)\n",
        "\n",
        "def assign_sliced_layer(size_tw,N_cov,x_output):\n",
        "    def func(x_input,x_output):\n",
        "        for i in range(1,(N_cov+1)):\n",
        "            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n",
        "            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n",
        "        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n",
        "                           for i in range(0,N_cov+1)]).T.flatten()\n",
        "        x_proj = slice_layer(index)(x_output)\n",
        "        return x_proj\n",
        "    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n",
        "\n",
        "def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n",
        "    if x1.shape[3]>x2.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    elif x2.shape[3]>x1.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    else:\n",
        "        err   = keras.layers.Subtract()([x1,x2])\n",
        "        err   = keras.layers.Multiply()([err,mask])\n",
        "    err   = keras.layers.Multiply()([err,err])\n",
        "    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n",
        "    err   = keras.layers.GlobalAveragePooling3D()(err)\n",
        "    err   = keras.layers.Reshape((1,))(err)\n",
        "    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n",
        "    return err\n",
        "\n",
        "def keras_custom_loss_function(size_tw):\n",
        "    def insert_Sobel(size_tw,dir=\"x\"):\n",
        "        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n",
        "        if dir==\"x\":\n",
        "            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n",
        "        if dir==\"y\":\n",
        "            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n",
        "        for i in range(size_tw):\n",
        "            kernel_weights[:,:,i,i]=sobel\n",
        "        return kernel_weights\n",
        "    def lossFunction(y_true,y_pred):\n",
        "        mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
        "        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n",
        "        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n",
        "        Gx_true = K.conv2d(y_true, filter_gx, padding=\"same\")\n",
        "        Gy_true = K.conv2d(y_true, filter_gy, padding=\"same\")\n",
        "        Grad_true = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_true,Gx_true]),\\\n",
        "                                       keras.layers.Multiply()([Gy_true,Gy_true])]))\n",
        "        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n",
        "        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n",
        "        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n",
        "        mae_grad = tf.keras.losses.mean_absolute_error(Grad_true, Grad_pred)\n",
        "        alpha= 0.5\n",
        "        loss = ((1.-alpha)*mae) + (alpha*mae_grad)\n",
        "        return loss\n",
        "    return lossFunction\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n",
        "\n",
        "    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n",
        "    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n",
        "    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n",
        "   \n",
        "    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n",
        "    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n",
        "    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n",
        "           \n",
        "    return exp_var_AE_Tr,exp_var_AE_Tt\n",
        "\n",
        "# functions for the evaluation of interpolation and auto-encoding performance\n",
        "def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n",
        "\n",
        "    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n",
        "    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n",
        "    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n",
        "    \n",
        "    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n",
        "    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n",
        "    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n",
        "            \n",
        "    return exp_var_AE_Tr,exp_var_AE_Tt\n",
        "\n",
        "def eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\n",
        "                           mask_test,x_test,x_test_missing,x_test_pred):\n",
        "    mse_train      = np.zeros((2))\n",
        "    mse_train[0]   = np.sum( mask_train * (x_train_pred - x_train_missing)**2 ) / np.sum( mask_train )\n",
        "    mse_train[1]   = np.mean( (x_train_pred - x_train)**2 )\n",
        "    exp_var_train  = 1. - mse_train #/ var_Tr\n",
        "            \n",
        "    mse_test        = np.zeros((2))\n",
        "    mse_test[0]     = np.sum( mask_test * (x_test_pred - x_test_missing)**2 ) / np.sum( mask_test )\n",
        "    mse_test[1]     = np.mean( (x_test_pred - x_test)**2 ) \n",
        "    exp_var_test = 1. - mse_test #/ var_Tt\n",
        "\n",
        "    mse_train_interp        = np.sum( (1.-mask_train) * (x_train_pred - x_train)**2 ) / np.sum( 1. - mask_train )\n",
        "    exp_var_train_interp    = 1. - mse_train_interp \n",
        "    \n",
        "    mse_test_interp        = np.sum( (1.-mask_test) * (x_test_pred - x_test)**2 ) / np.sum( 1. - mask_test )\n",
        "    exp_var_test_interp    = 1. - mse_test_interp\n",
        "            \n",
        "    return mse_train,exp_var_train,mse_test,exp_var_test,mse_train_interp,exp_var_train_interp,mse_test_interp,exp_var_test_interp\n",
        "\n",
        "# function to create recursive paths\n",
        "def mk_dir_recursive(dir_path):\n",
        "    if os.path.isdir(dir_path):\n",
        "        return\n",
        "    h, t = os.path.split(dir_path)  # head/tail\n",
        "    if not os.path.isdir(h):\n",
        "        mk_dir_recursive(h)\n",
        "\n",
        "    new_path = join_paths(h, t)\n",
        "    if not os.path.isdir(new_path):\n",
        "        os.mkdir(new_path)\n",
        "\n",
        "def Gradient(img, order):\n",
        "    \"\"\" calculate x, y gradient and magnitude \"\"\" \n",
        "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
        "    sobelx = sobelx/8.0\n",
        "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n",
        "    sobely = sobely/8.0\n",
        "    sobel_norm = np.sqrt(sobelx*sobelx+sobely*sobely)\n",
        "    if (order==0):\n",
        "        return sobelx\n",
        "    elif (order==1):\n",
        "        return sobely\n",
        "    else:\n",
        "        return sobel_norm\n",
        "\n",
        "def insert_Sobel(size_tw,dir=\"x\"):\n",
        "    kernel_weights=np.zeros((3,3,size_tw,size_tw))\n",
        "    if dir==\"x\":\n",
        "        sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n",
        "    if dir==\"y\":\n",
        "        sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n",
        "    for i in range(size_tw):\n",
        "        kernel_weights[:,:,i,i]=sobel\n",
        "    return kernel_weights\n",
        "\n",
        "# New loss function for unsupervised setting:\n",
        "# L = MAE + ||Grad||^2\n",
        "def keras_custom_loss_function2(size_tw):\n",
        "    def insert_Sobel(size_tw,dir=\"x\"):\n",
        "        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n",
        "        if dir==\"x\":\n",
        "            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n",
        "        if dir==\"y\":\n",
        "            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n",
        "        for i in range(size_tw):\n",
        "            kernel_weights[:,:,i,i]=sobel\n",
        "        return kernel_weights\n",
        "    def lossFunction(y_true,y_pred):\n",
        "        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n",
        "        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n",
        "        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n",
        "        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n",
        "        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n",
        "        loss = K.mean(keras.layers.Multiply()([Grad_pred,Grad_pred]))\n",
        "        return loss\n",
        "    return lossFunction\n",
        "\n",
        "def thresholding(x,thr):\n",
        "    greater = K.greater_equal(x,thr) #will return boolean values\n",
        "    greater = K.cast(greater, dtype=K.floatx()) #will convert bool to 0 and 1    \n",
        "    return greater\n",
        "\n",
        "def slice_layer(index):\n",
        "    def func(x_input):\n",
        "        return tf.gather(x_input, index, axis=3)\n",
        "    return keras.layers.Lambda(func)\n",
        "\n",
        "def assign_sliced_layer(size_tw,N_cov,x_output):\n",
        "    def func(x_input,x_output):\n",
        "        for i in range(1,(N_cov+1)):\n",
        "            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n",
        "            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n",
        "        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n",
        "                           for i in range(0,N_cov+1)]).T.flatten()\n",
        "        x_proj = slice_layer(index)(x_output)\n",
        "        return x_proj\n",
        "    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n",
        "\n",
        "def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n",
        "    if x1.shape[3]>x2.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    elif x2.shape[3]>x1.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    else:\n",
        "        err   = keras.layers.Subtract()([x1,x2])\n",
        "        err   = keras.layers.Multiply()([err,mask])\n",
        "    err   = keras.layers.Multiply()([err,err])\n",
        "    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n",
        "    # normalize err\n",
        "    err   = keras.layers.GlobalAveragePooling3D()(err)\n",
        "    err   = keras.layers.Reshape((1,))(err)\n",
        "    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n",
        "    return err\n",
        "\n",
        "def regularize_Gradient(x_proj,size_tw):\n",
        "    filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n",
        "    filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n",
        "    def Gradient(tensors):\n",
        "        tensor = tensors[0]\n",
        "        filter = tensors[1]\n",
        "        return K.conv2d(tensor, filter, padding=\"same\")\n",
        "    Gx_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gx])\n",
        "    Gy_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gy])\n",
        "    #Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "    #                                    keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n",
        "    Grad_pred = keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "                                        keras.layers.Multiply()([Gy_pred,Gy_pred])])\n",
        "    reg_Gradient   = keras.layers.Reshape((Grad_pred.shape[-3],Grad_pred.shape[-2],Grad_pred.shape[-1],1))(Grad_pred)\n",
        "    reg_Gradient   = keras.layers.GlobalAveragePooling3D()(reg_Gradient)\n",
        "    reg_Gradient   = keras.layers.Reshape((1,))(reg_Gradient)\n",
        "    reg_Gradient   = keras.layers.Lambda(lambda x: 1*x)(reg_Gradient)\n",
        "    return reg_Gradient\n",
        "\n",
        "def define_DINConvAE(NiterProjection,model_AE,shape,\\\n",
        "                     flagUseMaskinEncoder,\\\n",
        "                     size_tw,include_covariates,N_cov=0):\n",
        "\n",
        "    # encoder-decoder with masked data\n",
        "    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    \n",
        "    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n",
        "    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n",
        "\n",
        "    # Iterations of fixed-point projection\n",
        "    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n",
        "    for kk in range(0,NiterProjection):\n",
        "        x_proj   = model_AE([x,mask])\n",
        "        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n",
        "        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n",
        "        x        = keras.layers.Add()([x,x_proj])\n",
        "\n",
        "\n",
        "    x_proj = model_AE([x,mask]) \n",
        "    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n",
        "\n",
        "    # randomly sample an additionnal missing data mask\n",
        "    # additive noise + spatial smoothing\n",
        "    if flagUseMaskinEncoder == 1:\n",
        "        WAvFilter     = 3\n",
        "        NIterAvFilter = 3\n",
        "        thrNoise      = 1.5 * stdMask + 1e-7\n",
        "        maskg   = keras.layers.GaussianNoise(stdMask)(mask)\n",
        "        avFilter       = 1./(WAvFilter**3)*np.ones((WAvFilter,WAvFilter,WAvFilter,1,1))\n",
        "        spatialAvLayer = keras.layers.Conv3D(1,(WAvFilter,WAvFilter,WAvFilter),weights=[avFilter],\\\n",
        "                           padding='same',activation='linear',use_bias=False,name='SpatialAverage')\n",
        "        spatialAvLayer.trainable = False\n",
        "        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,3,1,2)))(maskg) \n",
        "        maskg  = keras.layers.Reshape((shape[3],shape[1],shape[2],1))(maskg)\n",
        "        for nn in range(0,NIterAvFilter):\n",
        "            maskg  = spatialAvLayer(maskg) \n",
        "        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,2,3,1,4)))(maskg) \n",
        "        maskg = keras.layers.Reshape((shape[1],shape[2],shape[3]))(maskg)\n",
        "        maskg = keras.layers.Lambda(lambda x: thresholding(x,thrNoise))(maskg)    \n",
        "        maskg  = keras.layers.Multiply()([mask,maskg])\n",
        "        maskg  = keras.layers.Subtract()([mask,maskg])       \n",
        "    else:\n",
        "        maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n",
        "\n",
        "    x_proj = global_model_FP([x_input,maskg])\n",
        "    # AE error with x_proj\n",
        "    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n",
        "    # AE error with x_proj\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj_ = x_proj\n",
        "    \n",
        "    x_proj2 = model_AE([x_proj_,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n",
        "    err2    = error(x_proj_,x_proj2,mask,size_tw,shape,0,N_cov)\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj3 = model_AE([x_proj_,keras.layers.Lambda(lambda x:0.*x)(mask)])\n",
        "    err3    = error(x_proj3,x_proj_,mask,size_tw,shape,0,N_cov)\n",
        "    # add all errors\n",
        "    err    = keras.layers.Add()([err1,err2])\n",
        "    err    = keras.layers.Add()([err,err3])\n",
        "\n",
        "    # return global model\n",
        "    global_model_FP_Masked  = keras.models.Model([x_input,mask],[err,x_proj])\n",
        "\n",
        "    global_model_FP.summary()\n",
        "    global_model_FP_Masked.summary()\n",
        "    return global_model_FP,global_model_FP_Masked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcs8QZ4uvpZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bb714c-0e21-45e9-c106-84211d648fd8"
      },
      "source": [
        "#Apply model     \n",
        "encoder, decoder, model_AE, DimCAE = fl24(globParams,x_train,mask_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 20)   180         input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 64, 64, 20)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 32, 32, 20)   0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 40)   7240        average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 40)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 16, 16, 40)   0           dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 80)   28880       average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 16, 16, 80)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 8, 8, 80)     0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 160)    115360      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 8, 8, 160)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 160)    0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 1, 1, 20)     3220        average_pooling2d_7[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 154,880\n",
            "Trainable params: 154,880\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 1, 1, 20)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 256)  5242880     input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 256)  0           conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 128)  294912      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 64, 64, 128)  0           conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 64)   73728       dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 128)  73728       conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 64, 64, 128)  0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 64)   73728       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 64, 64, 64)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 64, 64, 64)   0           conv2d_16[0][0]                  \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 128)  73728       add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 64, 64, 128)  0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 64)   73728       dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 64, 64, 64)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 64, 64, 64)   0           add_23[0][0]                     \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 1)    576         add_24[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,907,008\n",
            "Trainable params: 5,907,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_9 (Functional)            (None, 1, 1, 20)     154880      input_15[0][0]                   \n",
            "                                                                 input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_10 (Functional)           (None, 64, 64, 1)    5907008     model_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLreoecvpZw"
      },
      "source": [
        "### Train-Model - FP - Iterated projection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEbLPGz_vpZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcc9bd6-a436-49da-ee33-812112fedcfd"
      },
      "source": [
        "def flagProcess4_Optim0(dict_global_Params,x_train,x_train_missing,mask_train,gt_train,\\\n",
        "                    x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE):\n",
        "\n",
        "    for key,val in dict_global_Params.items():\n",
        "        exec(\"globals()['\"+key+\"']=val\")\n",
        "\n",
        "    meanTr = stdsc.mean_\n",
        "    stdTr = np.mean(stdsc.var_)\n",
        "    # ***************** #\n",
        "    # model compilation #\n",
        "    # ***************** #\n",
        "\n",
        "    # model fit\n",
        "    NbProjection   = [0,0,2,2,5,5,10,15,14]\n",
        "    NbProjection   = [5,5,5,5]\n",
        "    lrUpdate       = [1e-3,1e-4,1e-5,1e-5,1e-5,1e-6,1e-6,1e-5,1e-6]\n",
        "    if flagTrOuputWOMissingData==0:\n",
        "        lrUpdate   = [1e-4,1e-5,1e-6,1e-7]\n",
        "    else:\n",
        "        lrUpdate   = [1e-3,1e-4,1e-5,1e-6]\n",
        "    IterUpdate     = [0,3,10,15,20,25,30,35,40]\n",
        "    #IterUpdate     = [0,6,15,20]\n",
        "    val_split      = 0.1\n",
        "    \n",
        "    iterInit = 0\n",
        "    IterTrainAE = 0\n",
        "    IterUpdateInit = 10000\n",
        "    \n",
        "    ## initialization\n",
        "    x_train_init = np.copy(x_train_missing)\n",
        "    x_test_init  = np.copy(x_test_missing)\n",
        "\n",
        "    comptUpdate = 0\n",
        "\n",
        "    # ******************** #\n",
        "    # Start Learning model #\n",
        "    # ******************** #\n",
        "        \n",
        "    print(\"..... Start learning AE model\")\n",
        "    for iter in tqdm(range(iterInit,Niter)):\n",
        "        if iter == IterUpdate[comptUpdate]:\n",
        "            # update DINConvAE model\n",
        "            NBProjCurrent = NbProjection[comptUpdate]\n",
        "            print(\"..... Update/initialize number of projections in DINCOnvAE model # %d\"%(NbProjection[comptUpdate]))\n",
        "            global_model_FP,global_model_FP_Masked = define_DINConvAE(NbProjection[comptUpdate],model_AE,x_train.shape,\\\n",
        "                                                                          flagUseMaskinEncoder,\\\n",
        "                                                                          size_tw,N_cov)\n",
        "            if flagTrOuputWOMissingData == 1:\n",
        "                #global_model_FP.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "                global_model_FP.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "            else:\n",
        "                #global_model_FP_Masked.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "                global_model_FP_Masked.compile(loss=['mean_squared_error',keras_custom_loss_function2(size_tw)],loss_weights=[1.0,1e-10],optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "            if comptUpdate < len(NbProjection)-1:\n",
        "                comptUpdate += 1\n",
        "        \n",
        "        # gradient descent iteration            \n",
        "        if flagTrOuputWOMissingData == 1:\n",
        "            history = global_model_FP.fit([x_train_init,mask_train],gt_train,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs = NbEpoc,\n",
        "                  verbose = 1, \n",
        "                  validation_split=val_split)\n",
        "        else:\n",
        "            history = global_model_FP_Masked.fit([x_train_init,mask_train],[np.zeros((x_train_init.shape[0],1)),gt_train],\n",
        "                  batch_size=batch_size,\n",
        "                  epochs = NbEpoc,\n",
        "                  verbose = 1, \n",
        "                  validation_split=val_split)\n",
        "\n",
        "        # *********************** #\n",
        "        # Prediction on test data #\n",
        "        # *********************** #\n",
        "\n",
        "        # trained full-model\n",
        "        x_train_pred    = global_model_FP.predict([x_train_init,mask_train])\n",
        "        x_test_pred     = global_model_FP.predict([x_test_init,mask_test])\n",
        "\n",
        "        # trained AE applied to gap-free data\n",
        "        if flagUseMaskinEncoder == 1:\n",
        "          rec_AE_Tr     = model_AE.predict([x_train,np.zeros((mask_train.shape))])\n",
        "          rec_AE_Tt     = model_AE.predict([x_test,np.zeros((mask_train.shape))])\n",
        "        else:\n",
        "          rec_AE_Tr     = model_AE.predict([x_train,np.ones((mask_train.shape))])\n",
        "          rec_AE_Tt     = model_AE.predict([x_test,np.ones((mask_test.shape))])\n",
        "\n",
        "\n",
        "        mse_train,exp_var_train,\\\n",
        "        mse_test,exp_var_test,\\\n",
        "        mse_train_interp,exp_var_train_interp,\\\n",
        "        mse_test_interp,exp_var_test_interp =\\\n",
        "        eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\\\n",
        "                               mask_test,x_test,x_test_missing,x_test_pred)\n",
        "        \n",
        "        # interpolation and reconstruction score for the center image\n",
        "        # when dealing with time series\n",
        "        if x_train_init.shape[3] > 0 :\n",
        "            \n",
        "            dWCenter    = 32  \n",
        "            \n",
        "            dT = np.floor( x_train_init.shape[3] / 2 ).astype(int)\n",
        "            mse_train_center        = np.mean( (x_train_pred[:,:,:,dT] - x_train[:,:,:,dT] )**2 )\n",
        "            mse_train_center_interp = np.sum( (x_train_pred[:,:,:,dT]  - x_train[:,:,:,dT] )**2 * (1.-mask_train[:,:,:,dT])  ) / np.sum( (1.-mask_train[:,:,:,dT]) )\n",
        "            \n",
        "            mse_test_center         = np.mean( (x_test_pred[:,:,:,dT] - x_test[:,:,:,dT] )**2 )\n",
        "            mse_test_center_interp  = np.sum( (x_test_pred[:,:,:,dT]  - x_test[:,:,:,dT] )**2 * (1.-mask_test[:,:,:,dT])  ) / np.sum( (1-mask_test[:,:,:,dT]) )\n",
        "            \n",
        "            var_train_center        = np.var(  x_train[:,:,:,dT] )\n",
        "            var_test_center         = np.var(  x_test[:,:,:,dT] )\n",
        "            \n",
        "            exp_var_train_center         = 1.0 - mse_train_center / var_train_center\n",
        "            exp_var_train_interp_center  = 1.0 - mse_train_center_interp / var_train_center\n",
        "            exp_var_test_center          = 1.0 - mse_test_center  / var_test_center\n",
        "            exp_var_test_interp_center   = 1.0 - mse_test_center_interp/ var_test_center\n",
        "        # AE performance of the trained AE applied to gap-free data\n",
        "        exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n",
        "        \n",
        "        print(\".......... Auto-encoder performance when applied to gap-free data\")\n",
        "        print('.... explained variance AE (Tr)  : %.2f%%'%(100.*exp_var_AE_Tr))\n",
        "        print('.... explained variance AE (Tt)  : %.2f%%'%(100.*exp_var_AE_Tt))\n",
        "        \n",
        "        if flagUseMaskinEncoder == 1:\n",
        "        \n",
        "            exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n",
        "        \n",
        "            print('.... explained variance AE (Tr) with mask  : %.2f%%'%(100.*exp_var_AE_Tr))\n",
        "            print('.... explained variance AE (Tt) with mask  : %.2f%%'%(100.*exp_var_AE_Tt))\n",
        "\n",
        "\n",
        "\n",
        "        # update training data\n",
        "        if iter > IterUpdateInit:\n",
        "            # mask = 0(missing data) ; 1(data)\n",
        "          x_train_init = mask_train * x_train_missing + (1.-mask_train) * x_train_pred\n",
        "          x_test_init  = mask_test  * x_test_missing  + (1.-mask_test)  * x_test_pred\n",
        "    return global_model_FP,global_model_FP_Masked\n",
        "print('ready')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWWtqOlmvpZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee87c10-1bbf-4df5-dcc1-aeef6df3ec41"
      },
      "source": [
        "global_model_FP,global_model_FP_Masked=flagProcess4_Optim0(globParams,x_train,x_train_missing,mask_train,gt_train,x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "..... Start learning AE model\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_69 (Lambda)              (None, 64, 64, 1)    0           input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_70 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, 64, 64, 1)    6061888     lambda_69[0][0]                  \n",
            "                                                                 input_18[0][0]                   \n",
            "                                                                 add_25[0][0]                     \n",
            "                                                                 input_18[0][0]                   \n",
            "                                                                 add_26[0][0]                     \n",
            "                                                                 input_18[0][0]                   \n",
            "                                                                 add_27[0][0]                     \n",
            "                                                                 input_18[0][0]                   \n",
            "                                                                 add_28[0][0]                     \n",
            "                                                                 input_18[0][0]                   \n",
            "                                                                 add_29[0][0]                     \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_72 (Lambda)              (None, 64, 64, 1)    0           lambda_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_73 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_71 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_49 (Multiply)          (None, 64, 64, 1)    0           lambda_72[0][0]                  \n",
            "                                                                 lambda_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_48 (Multiply)          (None, 64, 64, 1)    0           model_11[0][0]                   \n",
            "                                                                 lambda_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 64, 64, 1)    0           multiply_49[0][0]                \n",
            "                                                                 multiply_48[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_75 (Lambda)              (None, 64, 64, 1)    0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_76 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_74 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_51 (Multiply)          (None, 64, 64, 1)    0           lambda_75[0][0]                  \n",
            "                                                                 lambda_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_50 (Multiply)          (None, 64, 64, 1)    0           model_11[1][0]                   \n",
            "                                                                 lambda_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 64, 64, 1)    0           multiply_51[0][0]                \n",
            "                                                                 multiply_50[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_78 (Lambda)              (None, 64, 64, 1)    0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_79 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_77 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_53 (Multiply)          (None, 64, 64, 1)    0           lambda_78[0][0]                  \n",
            "                                                                 lambda_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_52 (Multiply)          (None, 64, 64, 1)    0           model_11[2][0]                   \n",
            "                                                                 lambda_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 64, 64, 1)    0           multiply_53[0][0]                \n",
            "                                                                 multiply_52[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_81 (Lambda)              (None, 64, 64, 1)    0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_82 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_80 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_55 (Multiply)          (None, 64, 64, 1)    0           lambda_81[0][0]                  \n",
            "                                                                 lambda_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_54 (Multiply)          (None, 64, 64, 1)    0           model_11[3][0]                   \n",
            "                                                                 lambda_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 64, 64, 1)    0           multiply_55[0][0]                \n",
            "                                                                 multiply_54[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_84 (Lambda)              (None, 64, 64, 1)    0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_85 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_83 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_57 (Multiply)          (None, 64, 64, 1)    0           lambda_84[0][0]                  \n",
            "                                                                 lambda_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_56 (Multiply)          (None, 64, 64, 1)    0           model_11[4][0]                   \n",
            "                                                                 lambda_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 64, 64, 1)    0           multiply_57[0][0]                \n",
            "                                                                 multiply_56[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_86 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_12 (Functional)           (None, 64, 64, 1)    6061888     input_17[0][0]                   \n",
            "                                                                 lambda_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_88 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, 64, 64, 1)    6061888     model_12[0][0]                   \n",
            "                                                                 lambda_88[0][0]                  \n",
            "                                                                 model_12[0][0]                   \n",
            "                                                                 lambda_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_90 (Lambda)              (None, 64, 64, 1)    0           input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_9 (Subtract)           (None, 64, 64, 1)    0           model_12[0][0]                   \n",
            "                                                                 input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_10 (Subtract)          (None, 64, 64, 1)    0           model_12[0][0]                   \n",
            "                                                                 model_11[6][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_58 (Multiply)          (None, 64, 64, 1)    0           subtract_9[0][0]                 \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_60 (Multiply)          (None, 64, 64, 1)    0           subtract_10[0][0]                \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_11 (Subtract)          (None, 64, 64, 1)    0           model_11[7][0]                   \n",
            "                                                                 model_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_59 (Multiply)          (None, 64, 64, 1)    0           multiply_58[0][0]                \n",
            "                                                                 multiply_58[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_61 (Multiply)          (None, 64, 64, 1)    0           multiply_60[0][0]                \n",
            "                                                                 multiply_60[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_62 (Multiply)          (None, 64, 64, 1)    0           subtract_11[0][0]                \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_18 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_59[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_20 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_61[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_63 (Multiply)          (None, 64, 64, 1)    0           multiply_62[0][0]                \n",
            "                                                                 multiply_62[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_9 (Glo (None, 1)            0           reshape_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_10 (Gl (None, 1)            0           reshape_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_22 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_63[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_19 (Reshape)            (None, 1)            0           global_average_pooling3d_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_21 (Reshape)            (None, 1)            0           global_average_pooling3d_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_11 (Gl (None, 1)            0           reshape_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_87 (Lambda)              (None, 1)            0           reshape_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_89 (Lambda)              (None, 1)            0           reshape_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_23 (Reshape)            (None, 1)            0           global_average_pooling3d_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 1)            0           lambda_87[0][0]                  \n",
            "                                                                 lambda_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_91 (Lambda)              (None, 1)            0           reshape_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 1)            0           add_30[0][0]                     \n",
            "                                                                 lambda_91[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 28s 463ms/step - loss: 0.2704 - val_loss: 0.1837\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 453ms/step - loss: 0.1720 - val_loss: 0.1526\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.1526 - val_loss: 0.1426\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1443 - val_loss: 0.1389\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.1361 - val_loss: 0.1330\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.1351 - val_loss: 0.1311\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1269 - val_loss: 0.1292\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1250 - val_loss: 0.1272\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 453ms/step - loss: 0.1255 - val_loss: 0.1259\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1183 - val_loss: 0.1246\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1179 - val_loss: 0.1154\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1170 - val_loss: 0.1164\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1148 - val_loss: 0.1138\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1145 - val_loss: 0.1190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:149: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in double_scalars\n",
            "\r  7%|▋         | 1/14 [05:38<1:13:24, 338.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 87.09%\n",
            ".... explained variance AE (Tt)  : 86.52%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1136 - val_loss: 0.1238\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1111 - val_loss: 0.1113\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1097 - val_loss: 0.1098\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1079 - val_loss: 0.1115\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1127 - val_loss: 0.1114\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1055 - val_loss: 0.1076\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.1056 - val_loss: 0.1160\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1059 - val_loss: 0.1077\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.1019 - val_loss: 0.1044\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1014 - val_loss: 0.1124\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.1051 - val_loss: 0.1092\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 447ms/step - loss: 0.1001 - val_loss: 0.1070\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 447ms/step - loss: 0.1026 - val_loss: 0.1053\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 447ms/step - loss: 0.0995 - val_loss: 0.1036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 2/14 [11:10<1:07:20, 336.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 91.27%\n",
            ".... explained variance AE (Tt)  : 90.02%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0991 - val_loss: 0.1024\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0955 - val_loss: 0.1008\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0949 - val_loss: 0.1035\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0982 - val_loss: 0.1124\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0975 - val_loss: 0.0960\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0923 - val_loss: 0.0997\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0943 - val_loss: 0.0970\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0917 - val_loss: 0.0946\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0894 - val_loss: 0.0969\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0939 - val_loss: 0.0979\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0891 - val_loss: 0.0981\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0884 - val_loss: 0.0966\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0880 - val_loss: 0.0934\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0918 - val_loss: 0.0951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 3/14 [16:42<1:01:26, 335.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 93.13%\n",
            ".... explained variance AE (Tt)  : 91.90%\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_92 (Lambda)              (None, 64, 64, 1)    0           input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_93 (Lambda)              (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, 64, 64, 1)    6061888     lambda_92[0][0]                  \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 add_32[0][0]                     \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 add_33[0][0]                     \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 add_34[0][0]                     \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 add_35[0][0]                     \n",
            "                                                                 input_20[0][0]                   \n",
            "                                                                 add_36[0][0]                     \n",
            "                                                                 input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_95 (Lambda)              (None, 64, 64, 1)    0           lambda_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_96 (Lambda)              (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_94 (Lambda)              (None, 64, 64, 1)    0           lambda_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_65 (Multiply)          (None, 64, 64, 1)    0           lambda_95[0][0]                  \n",
            "                                                                 lambda_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_64 (Multiply)          (None, 64, 64, 1)    0           model_11[8][0]                   \n",
            "                                                                 lambda_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 64, 64, 1)    0           multiply_65[0][0]                \n",
            "                                                                 multiply_64[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_98 (Lambda)              (None, 64, 64, 1)    0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_99 (Lambda)              (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_97 (Lambda)              (None, 64, 64, 1)    0           lambda_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_67 (Multiply)          (None, 64, 64, 1)    0           lambda_98[0][0]                  \n",
            "                                                                 lambda_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_66 (Multiply)          (None, 64, 64, 1)    0           model_11[9][0]                   \n",
            "                                                                 lambda_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 64, 64, 1)    0           multiply_67[0][0]                \n",
            "                                                                 multiply_66[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_101 (Lambda)             (None, 64, 64, 1)    0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_102 (Lambda)             (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_100 (Lambda)             (None, 64, 64, 1)    0           lambda_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_69 (Multiply)          (None, 64, 64, 1)    0           lambda_101[0][0]                 \n",
            "                                                                 lambda_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_68 (Multiply)          (None, 64, 64, 1)    0           model_11[10][0]                  \n",
            "                                                                 lambda_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 64, 64, 1)    0           multiply_69[0][0]                \n",
            "                                                                 multiply_68[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_104 (Lambda)             (None, 64, 64, 1)    0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_105 (Lambda)             (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_103 (Lambda)             (None, 64, 64, 1)    0           lambda_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_71 (Multiply)          (None, 64, 64, 1)    0           lambda_104[0][0]                 \n",
            "                                                                 lambda_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_70 (Multiply)          (None, 64, 64, 1)    0           model_11[11][0]                  \n",
            "                                                                 lambda_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 64, 64, 1)    0           multiply_71[0][0]                \n",
            "                                                                 multiply_70[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_107 (Lambda)             (None, 64, 64, 1)    0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_108 (Lambda)             (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_106 (Lambda)             (None, 64, 64, 1)    0           lambda_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_73 (Multiply)          (None, 64, 64, 1)    0           lambda_107[0][0]                 \n",
            "                                                                 lambda_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_72 (Multiply)          (None, 64, 64, 1)    0           model_11[12][0]                  \n",
            "                                                                 lambda_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 64, 64, 1)    0           multiply_73[0][0]                \n",
            "                                                                 multiply_72[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_19 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_109 (Lambda)             (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_14 (Functional)           (None, 64, 64, 1)    6061888     input_19[0][0]                   \n",
            "                                                                 lambda_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_111 (Lambda)             (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, 64, 64, 1)    6061888     model_14[0][0]                   \n",
            "                                                                 lambda_111[0][0]                 \n",
            "                                                                 model_14[0][0]                   \n",
            "                                                                 lambda_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_113 (Lambda)             (None, 64, 64, 1)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_12 (Subtract)          (None, 64, 64, 1)    0           model_14[0][0]                   \n",
            "                                                                 input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_13 (Subtract)          (None, 64, 64, 1)    0           model_14[0][0]                   \n",
            "                                                                 model_11[14][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_74 (Multiply)          (None, 64, 64, 1)    0           subtract_12[0][0]                \n",
            "                                                                 input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_76 (Multiply)          (None, 64, 64, 1)    0           subtract_13[0][0]                \n",
            "                                                                 input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_14 (Subtract)          (None, 64, 64, 1)    0           model_11[15][0]                  \n",
            "                                                                 model_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_75 (Multiply)          (None, 64, 64, 1)    0           multiply_74[0][0]                \n",
            "                                                                 multiply_74[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_77 (Multiply)          (None, 64, 64, 1)    0           multiply_76[0][0]                \n",
            "                                                                 multiply_76[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_78 (Multiply)          (None, 64, 64, 1)    0           subtract_14[0][0]                \n",
            "                                                                 input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_24 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_75[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_26 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_77[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_79 (Multiply)          (None, 64, 64, 1)    0           multiply_78[0][0]                \n",
            "                                                                 multiply_78[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_12 (Gl (None, 1)            0           reshape_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_13 (Gl (None, 1)            0           reshape_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_28 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_79[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_25 (Reshape)            (None, 1)            0           global_average_pooling3d_12[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "reshape_27 (Reshape)            (None, 1)            0           global_average_pooling3d_13[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_14 (Gl (None, 1)            0           reshape_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_110 (Lambda)             (None, 1)            0           reshape_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_112 (Lambda)             (None, 1)            0           reshape_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_29 (Reshape)            (None, 1)            0           global_average_pooling3d_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 1)            0           lambda_110[0][0]                 \n",
            "                                                                 lambda_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_114 (Lambda)             (None, 1)            0           reshape_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 1)            0           add_37[0][0]                     \n",
            "                                                                 lambda_114[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 28s 463ms/step - loss: 0.0846 - val_loss: 0.0885\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0790 - val_loss: 0.0875\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0786 - val_loss: 0.0871\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0785 - val_loss: 0.0867\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0768 - val_loss: 0.0868\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0772 - val_loss: 0.0863\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0766 - val_loss: 0.0857\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0763 - val_loss: 0.0856\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0755 - val_loss: 0.0857\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0767 - val_loss: 0.0853\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0755 - val_loss: 0.0859\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0748 - val_loss: 0.0853\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0748 - val_loss: 0.0848\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0751 - val_loss: 0.0849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 4/14 [22:21<56:04, 336.44s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 95.08%\n",
            ".... explained variance AE (Tt)  : 93.73%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0752 - val_loss: 0.0848\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0746 - val_loss: 0.0844\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0744 - val_loss: 0.0844\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0742 - val_loss: 0.0842\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0739 - val_loss: 0.0842\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0737 - val_loss: 0.0846\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0736 - val_loss: 0.0842\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0736 - val_loss: 0.0835\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0730 - val_loss: 0.0835\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0730 - val_loss: 0.0832\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 455ms/step - loss: 0.0728 - val_loss: 0.0831\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0723 - val_loss: 0.0833\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0723 - val_loss: 0.0828\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0722 - val_loss: 0.0833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 5/14 [27:54<50:19, 335.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 95.42%\n",
            ".... explained variance AE (Tt)  : 94.02%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0721 - val_loss: 0.0833\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0719 - val_loss: 0.0828\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0716 - val_loss: 0.0826\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0715 - val_loss: 0.0830\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0713 - val_loss: 0.0824\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0712 - val_loss: 0.0823\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0710 - val_loss: 0.0827\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0710 - val_loss: 0.0829\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0704 - val_loss: 0.0818\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0703 - val_loss: 0.0816\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0702 - val_loss: 0.0816\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0701 - val_loss: 0.0818\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0698 - val_loss: 0.0818\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0695 - val_loss: 0.0814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 6/14 [33:27<44:37, 334.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 95.75%\n",
            ".... explained variance AE (Tt)  : 94.27%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0697 - val_loss: 0.0812\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0694 - val_loss: 0.0819\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0691 - val_loss: 0.0812\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0691 - val_loss: 0.0812\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0690 - val_loss: 0.0812\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0688 - val_loss: 0.0822\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0684 - val_loss: 0.0818\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0686 - val_loss: 0.0809\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 448ms/step - loss: 0.0681 - val_loss: 0.0806\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0681 - val_loss: 0.0808\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0677 - val_loss: 0.0805\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0676 - val_loss: 0.0803\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0673 - val_loss: 0.0804\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0675 - val_loss: 0.0807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 7/14 [39:00<38:59, 334.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 95.98%\n",
            ".... explained variance AE (Tt)  : 94.46%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0671 - val_loss: 0.0803\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0673 - val_loss: 0.0798\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0668 - val_loss: 0.0798\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0668 - val_loss: 0.0798\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0667 - val_loss: 0.0798\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0667 - val_loss: 0.0801\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0663 - val_loss: 0.0798\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0663 - val_loss: 0.0793\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0662 - val_loss: 0.0795\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0660 - val_loss: 0.0797\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0658 - val_loss: 0.0791\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0660 - val_loss: 0.0798\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 455ms/step - loss: 0.0656 - val_loss: 0.0793\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0656 - val_loss: 0.0790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 8/14 [44:34<33:23, 333.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.35%\n",
            ".... explained variance AE (Tt)  : 94.80%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0652 - val_loss: 0.0789\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0651 - val_loss: 0.0794\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0655 - val_loss: 0.0787\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0648 - val_loss: 0.0793\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0649 - val_loss: 0.0792\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0646 - val_loss: 0.0789\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0646 - val_loss: 0.0790\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0647 - val_loss: 0.0785\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0641 - val_loss: 0.0785\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0644 - val_loss: 0.0792\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0641 - val_loss: 0.0792\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0641 - val_loss: 0.0785\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0638 - val_loss: 0.0786\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 449ms/step - loss: 0.0638 - val_loss: 0.0782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 9/14 [50:07<27:48, 333.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.57%\n",
            ".... explained variance AE (Tt)  : 94.96%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0636 - val_loss: 0.0786\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0638 - val_loss: 0.0784\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0635 - val_loss: 0.0791\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0633 - val_loss: 0.0780\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0631 - val_loss: 0.0780\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0633 - val_loss: 0.0787\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0630 - val_loss: 0.0779\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0626 - val_loss: 0.0790\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0629 - val_loss: 0.0787\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0629 - val_loss: 0.0783\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0628 - val_loss: 0.0786\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0627 - val_loss: 0.0774\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0621 - val_loss: 0.0776\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0623 - val_loss: 0.0771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 10/14 [55:40<22:14, 333.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.80%\n",
            ".... explained variance AE (Tt)  : 95.17%\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_115 (Lambda)             (None, 64, 64, 1)    0           input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_116 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, 64, 64, 1)    6061888     lambda_115[0][0]                 \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 add_39[0][0]                     \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 add_40[0][0]                     \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 add_41[0][0]                     \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 add_42[0][0]                     \n",
            "                                                                 input_22[0][0]                   \n",
            "                                                                 add_43[0][0]                     \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_118 (Lambda)             (None, 64, 64, 1)    0           lambda_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_119 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_117 (Lambda)             (None, 64, 64, 1)    0           lambda_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_81 (Multiply)          (None, 64, 64, 1)    0           lambda_118[0][0]                 \n",
            "                                                                 lambda_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_80 (Multiply)          (None, 64, 64, 1)    0           model_11[16][0]                  \n",
            "                                                                 lambda_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 64, 64, 1)    0           multiply_81[0][0]                \n",
            "                                                                 multiply_80[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_121 (Lambda)             (None, 64, 64, 1)    0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_122 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_120 (Lambda)             (None, 64, 64, 1)    0           lambda_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_83 (Multiply)          (None, 64, 64, 1)    0           lambda_121[0][0]                 \n",
            "                                                                 lambda_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_82 (Multiply)          (None, 64, 64, 1)    0           model_11[17][0]                  \n",
            "                                                                 lambda_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 64, 64, 1)    0           multiply_83[0][0]                \n",
            "                                                                 multiply_82[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_124 (Lambda)             (None, 64, 64, 1)    0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_125 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_123 (Lambda)             (None, 64, 64, 1)    0           lambda_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_85 (Multiply)          (None, 64, 64, 1)    0           lambda_124[0][0]                 \n",
            "                                                                 lambda_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_84 (Multiply)          (None, 64, 64, 1)    0           model_11[18][0]                  \n",
            "                                                                 lambda_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 64, 64, 1)    0           multiply_85[0][0]                \n",
            "                                                                 multiply_84[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_127 (Lambda)             (None, 64, 64, 1)    0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_128 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_126 (Lambda)             (None, 64, 64, 1)    0           lambda_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_87 (Multiply)          (None, 64, 64, 1)    0           lambda_127[0][0]                 \n",
            "                                                                 lambda_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_86 (Multiply)          (None, 64, 64, 1)    0           model_11[19][0]                  \n",
            "                                                                 lambda_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 64, 64, 1)    0           multiply_87[0][0]                \n",
            "                                                                 multiply_86[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_130 (Lambda)             (None, 64, 64, 1)    0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_131 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_129 (Lambda)             (None, 64, 64, 1)    0           lambda_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_89 (Multiply)          (None, 64, 64, 1)    0           lambda_130[0][0]                 \n",
            "                                                                 lambda_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_88 (Multiply)          (None, 64, 64, 1)    0           model_11[20][0]                  \n",
            "                                                                 lambda_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 64, 64, 1)    0           multiply_89[0][0]                \n",
            "                                                                 multiply_88[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_132 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_16 (Functional)           (None, 64, 64, 1)    6061888     input_21[0][0]                   \n",
            "                                                                 lambda_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_134 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           (None, 64, 64, 1)    6061888     model_16[0][0]                   \n",
            "                                                                 lambda_134[0][0]                 \n",
            "                                                                 model_16[0][0]                   \n",
            "                                                                 lambda_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_136 (Lambda)             (None, 64, 64, 1)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_15 (Subtract)          (None, 64, 64, 1)    0           model_16[0][0]                   \n",
            "                                                                 input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_16 (Subtract)          (None, 64, 64, 1)    0           model_16[0][0]                   \n",
            "                                                                 model_11[22][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_90 (Multiply)          (None, 64, 64, 1)    0           subtract_15[0][0]                \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_92 (Multiply)          (None, 64, 64, 1)    0           subtract_16[0][0]                \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_17 (Subtract)          (None, 64, 64, 1)    0           model_11[23][0]                  \n",
            "                                                                 model_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_91 (Multiply)          (None, 64, 64, 1)    0           multiply_90[0][0]                \n",
            "                                                                 multiply_90[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_93 (Multiply)          (None, 64, 64, 1)    0           multiply_92[0][0]                \n",
            "                                                                 multiply_92[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_94 (Multiply)          (None, 64, 64, 1)    0           subtract_17[0][0]                \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_30 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_91[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_32 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_93[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_95 (Multiply)          (None, 64, 64, 1)    0           multiply_94[0][0]                \n",
            "                                                                 multiply_94[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_15 (Gl (None, 1)            0           reshape_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_16 (Gl (None, 1)            0           reshape_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_34 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_95[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_31 (Reshape)            (None, 1)            0           global_average_pooling3d_15[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "reshape_33 (Reshape)            (None, 1)            0           global_average_pooling3d_16[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_17 (Gl (None, 1)            0           reshape_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_133 (Lambda)             (None, 1)            0           reshape_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_135 (Lambda)             (None, 1)            0           reshape_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_35 (Reshape)            (None, 1)            0           global_average_pooling3d_17[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 1)            0           lambda_133[0][0]                 \n",
            "                                                                 lambda_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_137 (Lambda)             (None, 1)            0           reshape_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 1)            0           add_44[0][0]                     \n",
            "                                                                 lambda_137[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 6,061,888\n",
            "Trainable params: 6,061,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 28s 470ms/step - loss: 0.0614 - val_loss: 0.0768\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0615 - val_loss: 0.0767\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0609 - val_loss: 0.0767\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0606 - val_loss: 0.0766\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0609 - val_loss: 0.0766\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0601 - val_loss: 0.0765\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0594 - val_loss: 0.0768\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0611 - val_loss: 0.0766\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0609 - val_loss: 0.0766\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0607 - val_loss: 0.0765\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0605 - val_loss: 0.0766\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0598 - val_loss: 0.0766\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0607 - val_loss: 0.0766\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0596 - val_loss: 0.0765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▊  | 11/14 [1:01:20<16:46, 335.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.87%\n",
            ".... explained variance AE (Tt)  : 95.24%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0603 - val_loss: 0.0765\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0602 - val_loss: 0.0765\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0603 - val_loss: 0.0765\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0603 - val_loss: 0.0768\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0603 - val_loss: 0.0764\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0604 - val_loss: 0.0766\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0603 - val_loss: 0.0766\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0601 - val_loss: 0.0765\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0604 - val_loss: 0.0764\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0604 - val_loss: 0.0765\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0602 - val_loss: 0.0764\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0603 - val_loss: 0.0763\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0603 - val_loss: 0.0764\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0600 - val_loss: 0.0764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 12/14 [1:06:53<11:09, 334.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.90%\n",
            ".... explained variance AE (Tt)  : 95.26%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 452ms/step - loss: 0.0601 - val_loss: 0.0765\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0601 - val_loss: 0.0764\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0602 - val_loss: 0.0763\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0602 - val_loss: 0.0763\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0600 - val_loss: 0.0765\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0601 - val_loss: 0.0764\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0599 - val_loss: 0.0763\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0599 - val_loss: 0.0764\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0600 - val_loss: 0.0764\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0600 - val_loss: 0.0763\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0601 - val_loss: 0.0763\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0600 - val_loss: 0.0764\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0600 - val_loss: 0.0763\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0599 - val_loss: 0.0762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 13/14 [1:12:26<05:34, 334.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.93%\n",
            ".... explained variance AE (Tt)  : 95.29%\n",
            "Epoch 1/14\n",
            "51/51 [==============================] - 23s 456ms/step - loss: 0.0601 - val_loss: 0.0763\n",
            "Epoch 2/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0599 - val_loss: 0.0763\n",
            "Epoch 3/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0601 - val_loss: 0.0763\n",
            "Epoch 4/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0600 - val_loss: 0.0765\n",
            "Epoch 5/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0598 - val_loss: 0.0764\n",
            "Epoch 6/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0599 - val_loss: 0.0763\n",
            "Epoch 7/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0599 - val_loss: 0.0762\n",
            "Epoch 8/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0598 - val_loss: 0.0762\n",
            "Epoch 9/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0597 - val_loss: 0.0764\n",
            "Epoch 10/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0598 - val_loss: 0.0763\n",
            "Epoch 11/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0598 - val_loss: 0.0763\n",
            "Epoch 12/14\n",
            "51/51 [==============================] - 23s 451ms/step - loss: 0.0595 - val_loss: 0.0762\n",
            "Epoch 13/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0597 - val_loss: 0.0764\n",
            "Epoch 14/14\n",
            "51/51 [==============================] - 23s 450ms/step - loss: 0.0597 - val_loss: 0.0762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [1:18:00<00:00, 334.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 96.95%\n",
            ".... explained variance AE (Tt)  : 95.29%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYGiJA8lvpZ-"
      },
      "source": [
        "### Prédiction / Interpolation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl3eUXPVvpZ_"
      },
      "source": [
        "Pred_GM = global_model_FP.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "Pred_AE = model_AE.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "\n",
        "#.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gdJ9AVuvpaD"
      },
      "source": [
        "#gt_pred_norm = stdsc.inverse_transform(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)))\n",
        "#Pred_AE_norm = np.full(gt_pred.shape,np.nan)\n",
        "#Pred_GM_norm = np.full(gt_pred.shape,np.nan)\n",
        "#Pred_AE_norm[np.where(~np.isnan(gt_pred))] = stdsc.inverse_transform(Pred_AE.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[np.where(~np.isnan(gt_pred))].reshape(len(Pred_AE),-1)).ravel() \n",
        "#Pred_GM_norm[np.where(~np.isnan(gt_pred))] = stdsc.inverse_transform(Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[np.where(~np.isnan(gt_pred))].reshape(len(Pred_GM),-1)).ravel()\n",
        "#Pred_AE_norm = Pred_AE_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O46naj1sfJ9m"
      },
      "source": [
        "Pred_AE_norm = stdsc.inverse_transform(Pred_AE.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = stdsc.inverse_transform(Pred_GM.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fZum6PJXi25"
      },
      "source": [
        "Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+medabs) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+medabs).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEF-7BCz6n9M"
      },
      "source": [
        "Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+mean_Tr) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqM26-Gjuw3y"
      },
      "source": [
        "Pred_AE_norm[np.where(Pred_AE_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n",
        "Pred_GM_norm[np.where(Pred_GM_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n",
        "Pred_AE_norm[np.where(Pred_AE_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n",
        "Pred_GM_norm[np.where(Pred_GM_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDg6dGDgu8Ip"
      },
      "source": [
        "Pred_AE_norm=Pred_AE_norm+0.5\n",
        "Pred_GM_norm=Pred_GM_norm+0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAqH_TH7pjLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "db516ea6-a170-4403-9c4e-37760a5e9b58"
      },
      "source": [
        "i=0\n",
        "plt.subplot(221)\n",
        "plt.imshow(Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n",
        "plt.colorbar()\n",
        "plt.subplot(222)\n",
        "plt.imshow(Pred_GM_norm.reshape(Pred_GM_norm.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[50])\n",
        "plt.colorbar()\n",
        "\n",
        "print(np.nanmax(Pred_GM_norm),np.nanmax(Pred_AE_norm),np.nanmax(gt_pred))\n",
        "print(np.nanmin(Pred_GM_norm),np.nanmin(Pred_AE_norm),np.nanmin(gt_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.2584940195083618 -1.2851287412643433 -0.5334281921386719\n",
            "-4.255948436260224 -4.160966049432755 -4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_MDhszraM69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "a0144e28-c831-4e4d-da6e-c12035bc2486"
      },
      "source": [
        "print(gt_pred.shape)\n",
        "plt.imshow(Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[5]-Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 64, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f2deb431860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIf6haKOSsX"
      },
      "source": [
        "# Some metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP9Syz_KvpaH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "19fad17a-8928-49e9-fbe8-ff4c0ee4fe1d"
      },
      "source": [
        "'''if flagPred :\n",
        "  Pred_GM_norm = Pred_GM_norm[len(mask_pred)//2:]\n",
        "  Pred_AE_norm = Pred_AE_norm[len(mask_pred)//2:]\n",
        "  gt_pred      = gt_pred[len(mask_pred)//2:]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-845a08e14edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mPred_GM_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_GM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mPred_AE_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgt_pred_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.         0.         0.         ... 1.4135437  1.43219256 1.42513895].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbOIMlSGURRi",
        "outputId": "f90db0e7-54f1-4584-bea9-a7873131bdf2"
      },
      "source": [
        "#from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.nanmean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def RMSE(a,b):\n",
        "    \"\"\" Compute the Root Mean Square Error between 2 n-dimensional vectors. \"\"\" \n",
        "    return np.sqrt(np.nanmean((a-b)**2))\n",
        "\n",
        "\n",
        "def Getmetrics(Target,Pred):\n",
        "    Target_value = Target.reshape(Target.shape)[np.where(~np.isnan(Target))]\n",
        "    Pred_value   = Pred.reshape(Target.shape)[np.where(~np.isnan(Target))]\n",
        "    Target_flat  = Target_value.flatten()\n",
        "    Pred_flat    = Pred_value.flatten()\n",
        "    Metrics=dict()\n",
        "\n",
        "    return {'EVS':explained_variance_score(Target_flat,Pred_flat),'RMSE':RMSE(Target_flat,Pred_flat),'NRMSE':RMSE(Target_flat,Pred_flat)/np.nanmean(Target_flat),'MAbsEr%':mean_absolute_percentage_error(Target_flat,Pred_flat),'MaxEr':max_error(Target_flat,Pred_flat),'MAbsEr':median_absolute_error(Target_flat,Pred_flat),'R²':r2_score(Target_flat,Pred_flat)}\n",
        "\n",
        "   #lissage donnée entrée flatn + nan\n",
        "#Metric=Getmetrics(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)),Pred_GM )\n",
        "testAE=np.copy(Pred_AE_norm)\n",
        "testAE[np.where(testAE<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n",
        "#print(np.nanmin(testAE))\n",
        "MetricGM=Getmetrics(gt_pred,Pred_GM_norm)\n",
        "MetricAE=Getmetrics(gt_pred,Pred_AE_norm)\n",
        "#print(MetricGM,MetricAE)\n",
        "print(Getmetrics(gt_pred,testAE),Getmetrics(gt_pred,Pred_AE_norm),MetricGM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'EVS': 0.9295114972342475, 'RMSE': 0.15054470517156637, 'NRMSE': -0.040436363673683653, 'MAbsEr%': 2.1366100574712097, 'MaxEr': 1.719615694284439, 'MAbsEr': 2.1971322894387413e-07, 'R²': 0.929415707268427} {'EVS': 0.9293987444563663, 'RMSE': 0.1506752488719855, 'NRMSE': -0.0404714277600588, 'MAbsEr%': 2.143586867179459, 'MaxEr': 1.719615694284439, 'MAbsEr': 1.2950685231771786e-05, 'R²': 0.9292932409243012}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Unvvl9mB2Bm"
      },
      "source": [
        "np.save('/content/drive/MyDrive/Pred_AE_normbestRMSE',testAE)\n",
        "np.save('/content/drive/MyDrive/Pred_GM_norm2',Pred_GM_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaQwDECHhn8u",
        "outputId": "b7757167-c7cd-490d-ab3b-8e7878e2fe82"
      },
      "source": [
        "global_model_FP.save(\"/content/drive/MyDrive/model121.h5\")\n",
        "model_AE.save(\"/content/drive/MyDrive/model221.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Hhd6tSXCt8"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq06kb4Pjoe_",
        "outputId": "0694721c-e7de-48d0-ae0a-347e9beb316d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
