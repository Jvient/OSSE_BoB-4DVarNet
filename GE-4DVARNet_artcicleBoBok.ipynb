{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"GENN-Dec.ipynb","provenance":[{"file_id":"1Vjn9BIJHgR1zctAUBI2s3ADmzSMDq5Jq","timestamp":1608122797975},{"file_id":"1GQIMp6sD21eL9UNUQqyr0vQZ7Qy03ow_","timestamp":1607607804514}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RNHzBS8nvpZB"},"source":["# Init "]},{"cell_type":"code","metadata":{"id":"I5iO50AvvpZD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615217520478,"user_tz":-60,"elapsed":29008,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"4792202b-1a29-4bdb-d194-919d9b93a7c3"},"source":["#Import data \n","from tqdm import tqdm\n","import numpy as np\n","import time\n","from sklearn.decomposition import PCA\n","from tqdm import tqdm\n","from random import randrange\n","import sklearn\n","from sklearn import decomposition\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from scipy.sparse import diags\n","from scipy.stats import multivariate_normal\n","from scipy.ndimage.morphology import distance_transform_edt as bwdist\n","import scipy.ndimage as nd\n","from scipy.interpolate import RegularGridInterpolator\n","import tensorflow as tf\n","import keras\n","import scipy.stats as ss \n","from keras.constraints import Constraint\n","from keras import backend as K\n","from datetime import date, datetime, timedelta\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 2417112855465611824\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15703311680\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 1922738279955809365\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kg2QP-hPvpZM"},"source":["# Parameters "]},{"cell_type":"code","metadata":{"id":"6EB_5VAtvpZP","executionInfo":{"status":"ok","timestamp":1615217539810,"user_tz":-60,"elapsed":409,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["DirSAVE                     = '/'\n","flagTrWMissingData          = 0  # Training phase with or without missing data\n","flagloadOIData              = 0    # load OI: work on rough variable or anomaly\n","lname_cov                   = [\"ssh_mod\"]\n","lid_cov                     = [\"OI\"]\n","size_tw                     = 1   # Length of the 4th dimension          \n","Wsquare                     = 4     # half-width of holes\n","Nsquare                     = 3     # number of holes\n","DimAE                       = 20  # Dimension of the latent space\n","flagLoadModel               = 0     # load pre-defined AE model or not\n","sigNoise                    = 1e-1\n","flagTrOuputWOMissingData    = 1\n","stdMask                     = 0.\n","dropout                     = 0.03 #[0.6,0.7,0.8]0.03\n","wl2                         = 0.0000\n","batch_size                  = 16# monter un peu \n","NbEpoc                      = 6\n","Niter                       = 6*3\n","thrMisData                  = 0\n","flagPred                    = True #1 pour prediction, sinon interp\n","FlagextendTr                = False #true pour depasser la taille de train de base\n","N_cov                       = 0\n","flagUseMaskinEncoder        = 0\n","\n","def createGlobParams(params):\n","    return dict(((k, eval(k)) for k in params))\n","list_globParams=[\n","    'flagTrOuputWOMissingData','flagTrWMissingData',\\\n","    'flagloadOIData','size_tw','Wsquare',\\\n","    'Nsquare','DimAE','flagLoadModel',\\\n","    'sigNoise',\\\n","    'stdMask',\\\n","    'dropout','wl2','batch_size',\\\n","    'NbEpoc','Niter','DirSAVE','flagPred','FlagextendTr','N_cov']\n","globParams = createGlobParams(list_globParams)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ovPNEb-vpZV"},"source":["# Import data"]},{"cell_type":"code","metadata":{"id":"PTnPawODvpZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615217550336,"user_tz":-60,"elapsed":8685,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"445c10ac-1061-431b-912a-439d0f93f698"},"source":["dataset= np.load(\"/content/drive/My Drive/DATA/TheÌ€se/ZOI/Dataset_64_ZOI.npy\",allow_pickle='TRUE').item()\n","dataH=dataset['CSED_Hourly']\n","mask=dataset['Cloud_Daily']\n","lat_grid=dataset['Lat_ZOI']\n","lon_grid=dataset['Lon_ZOI']\n","#corr lalpaciens var exp des norm\n","# =============================================================================\n","# Creation of the test and training dataset\n","# =============================================================================\n","def prepdata(xH,mask,N_Catalog=0):\n","    if N_Catalog!=0:\n","        test=np.zeros(mask[-365:].shape)\n","        for i in range(0,len(test)):\n","            test[i]=xH[26304+i*24+12].reshape(test.shape[1],test.shape[2])\n","\n","        train=np.zeros((N_Catalog*365,xH.shape[1],xH.shape[2]))\n","\n","        for i in range(N_Catalog):\n","            for j in range(len(test)):\n","                h=randrange(0,24)\n","                train[i*365+j]=xH[i*365+j*24+h]\n","    else:\n","        xD=np.empty((xH.shape[0]//24,xH.shape[1],xH.shape[2]))\n","        for i in range(len(xD)):\n","            xD[i]=xH[12+i*24]\n","    mask_train = mask[:-100]\n","    mask_pred  = mask[-100:]\n","    x_train    = xD[:len(mask_train)]\n","    #y_pred     = xD[len(mask_train)-100:len(mask_train)]\n","    y_pred     = xD[len(mask_train):len(mask_train)+len(mask_pred)]\n","    return mask_train,mask_pred,x_train,y_pred\n","\n","\n","mask[np.where(mask==0)]=1;mask[np.where(np.isnan(mask))]=0 # O for missing data\n","mask_train,mask_pred,x_train,y_pred = prepdata(dataH,mask)\n","\n","x_train,x_test,mask_train,mask_test=sklearn.model_selection.train_test_split(x_train,mask_train,test_size=0.33)\n","# list of test dates\n","indN_Tt = np.arange(len(x_train),len(x_train)+len(x_test))\n","indN_Tr = np.arange(len(x_train))\n","lday_test=[ datetime.strftime(datetime.strptime(\"2001-1-01\",'%Y-%m-%d')\\\n","                      + timedelta(days=np.float64(i)),\"%Y-%m-%d\") for i in indN_Tt ]\n","indLat     = np.arange(0,64)\n","indLon     = np.arange(0,64)      \n","print(indLat.shape,indLon.shape,indN_Tr.shape,indN_Tt.shape)\n","print(x_train.shape,x_test.shape,y_pred.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(64,) (64,) (895,) (441,)\n","(895, 64, 64) (441, 64, 64) (100, 64, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pa-gXMCZvpZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615217550338,"user_tz":-60,"elapsed":7952,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"8fa5b8ce-3631-479c-c004-30aab78edd88"},"source":["import matplotlib.pyplot as plt\n","plt.imshow(mask_pred[7].reshape(64,64))\n","plt.colorbar()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.colorbar.Colorbar at 0x7f21c00f26d0>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_1WOy6QyvpZi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615217551459,"user_tz":-60,"elapsed":8123,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"3c883ee5-8376-440a-c387-1e558b8e1882"},"source":["gt_train= x_train\n","gt_test = x_test\n","gt_pred = np.copy(y_pred)\n","err_train = np.random.normal(0,thrMisData*np.nanvar(x_train),(x_train.shape))\n","err_test = np.random.normal(0,thrMisData*np.nanvar(x_test),(x_test.shape))\n","err_pred = np.random.normal(0,thrMisData*np.nanvar(y_pred),(y_pred.shape))\n","\n","stdsc=sklearn.preprocessing.StandardScaler()\n","stdsc.fit(y_pred.reshape(y_pred.shape[0],-1))\n","mean_Tr = stdsc.mean_\n","medabs  = np.copy(mean_Tr)\n","med     = np.copy(mean_Tr)\n","\n","for i in range(len(medabs)):\n","  med[i]    =np.nanmedian(gt_train.reshape(gt_train.shape[0],-1)[:,i])\n","  medabs[i] =np.nanmedian(np.absolute(gt_train.reshape(gt_train.shape[0],-1)[:,i]-med[i]))\n","  \n","\n","print('MEAN',mean_Tr.shape)\n","std_Tr = stdsc.var_\n","\n","gt_train        = gt_train.reshape(x_train.shape[0],-1)-mean_Tr\n","x_train         = x_train.reshape(x_train.shape[0],-1)-mean_Tr\n","#x_train_missing = stdsc.fit_transform(x_train_missing.reshape(x_train_missing.shape[0],-1))\n","gt_test         = gt_test.reshape(len(x_test),-1)-mean_Tr                       \n","x_test          = x_test.reshape(len(x_test),-1)-mean_Tr\n","#x_test_missing  = stdsc.fit_transform(x_test_missing.reshape(x_test_missing.shape[0],-1))\n","#y_pred_missing  = stdsc.fit_transform(y_pred_missing.reshape(len(y_pred),-1))\n","y_pred          = y_pred.reshape(len(y_pred),-1)-mean_Tr\n","#gt_pred         = stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1))\n","\n","if flagTrWMissingData == 1 :\n","    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n","else :\n","    mask_train[:]=1\n","    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n","\n","x_test_missing=x_test.reshape(x_test.shape[0],indLat.shape[0],indLon.shape[0])*mask_test\n","if flagPred:\n","  mask_pred[15:,:,:] = 0\n","y_pred_missing=y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0])*mask_pred\n","\n","#Dimensionning                           \n","gt_train        = gt_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_train         = x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_train_missing = x_train_missing.reshape(x_train_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n","mask_train      = mask_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n","\n","gt_test         = gt_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_test          = x_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_test_missing  = x_test_missing.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)   \n","mask_test       = mask_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n","\n","#gt_pred         = gt_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n","y_pred          = y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n","y_pred_missing  = y_pred_missing.reshape(y_pred_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n","mask_pred       = mask_pred.reshape(mask_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n","\n","#Change Nan to 0 Check isany Nan/inf \n","def isany(x):\n","    x[np.where(np.isnan(x))]=0\n","    print(np.any(np.isnan(x)))\n","    print(np.any(np.isinf(x)))\n","    print(x.shape)\n","\n","isany(x_train)\n","isany(x_test)\n","isany(x_train_missing)\n","isany(x_test_missing)\n","isany(mask_test)\n","isany(mask_train)\n","isany(y_pred)\n","isany(y_pred_missing)\n","isany(x_train)\n","isany(gt_test)\n","isany(gt_train)\n","#isany(gt_pred)\n","\n","\n","print(\"... (after normalization) mean Tr = %f\"%(np.mean(gt_train)))\n","print(\"... (after normalization) mean Tt = %f\"%(np.mean(gt_test)))\n","#print(\"... (after normalization) mean Pred = %f\"%(np.mean(gt_pred)))\n","print(\"... (after normalization) mean x_train = %f\"%(np.mean(x_train)))\n","print(\"... (after normalization) mean x_train_missing = %f\"%(np.mean(x_train_missing)))\n","print(\"... (after normalization) mean x_test = %f\"%(np.mean(x_test)))\n","print(\"... (after normalization) mean x_test_missing = %f\"%(np.mean(x_test_missing)))\n","print(\"... (after normalization) mean y_pred = %f\"%(np.mean(y_pred)))\n","print(\"... (after normalization) mean y_pred_missing = %f\"%(np.mean(y_pred_missing)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n","  updated_mean = (last_sum + new_sum) / updated_sample_count\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n","  result = op(x, *args, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered\n","  overwrite_input=overwrite_input)\n"],"name":"stderr"},{"output_type":"stream","text":["MEAN (4096,)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(100, 64, 64, 1)\n","False\n","False\n","(100, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","... (after normalization) mean Tr = 0.095261\n","... (after normalization) mean Tt = 0.094365\n","... (after normalization) mean x_train = 0.095261\n","... (after normalization) mean x_train_missing = 0.095261\n","... (after normalization) mean x_test = 0.094365\n","... (after normalization) mean x_test_missing = 0.014594\n","... (after normalization) mean y_pred = -0.000000\n","... (after normalization) mean y_pred_missing = -0.002209\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"93mvfED-vpZn"},"source":["### Define GENN"]},{"cell_type":"code","metadata":{"id":"m0NuuUoBvpZo","executionInfo":{"status":"ok","timestamp":1615217552114,"user_tz":-60,"elapsed":7675,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["# Constraints on kernel to to zeros\n","# a specific position\n","class Constraint_Zero(Constraint):\n","    def __init__(self, position,kernel_shape,dw):\n","        self.position = position\n","        mask_array    = np.ones((kernel_shape))\n","        mask_array[position[0]-dw:position[0]+dw+1,position[1]-dw:position[1]+dw+1,:,:] = 0.0\n","\n","        self.mask = K.variable(value=mask_array, dtype='float32', name='mask')\n","\n","        print(self.mask.shape)\n","    def __call__(self, w):\n","        print(self.mask.shape)\n","        new_w = w * self.mask\n","\n","        return new_w\n","\n","def fl27(dict_global_Params,x_data,mask_data):\n","\n","    # import Global Parameters\n","    for key,val in dict_global_Params.items():\n","        exec(\"globals()['\"+key+\"']=val\")\n","\n","    WFilter       = 11#\n","    NbResUnit     = 10#3#\n","    dW            = 0\n","    flagdownScale = 1 #: 0: only HR scale, 1 : only LR, 2 : HR + LR , 2 : MR, HR + LR annd LR,\n","    scaleLR       = 2**2\n","    NbFilter      = 1*DimAE\n","    flagSRResNet  = 0\n","     \n","    input_layer = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n","    mask       = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n","    \n","    if flagUseMaskinEncoder == 1:\n","        dmask   = keras.layers.Lambda(lambda x: 0.2*x - 0.1)(mask)\n","        \n","        for jj in range(0,6):\n","            dx    = keras.layers.Conv2D(10,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dmask)            \n","            dx    = keras.layers.Conv2D(1,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)            \n","            dmask = keras.layers.Add()([dmask,dx])\n","            \n","        x0       = keras.layers.Concatenate(axis=-1)([input_layer,dmask])\n","    else:\n","        x0  = keras.layers.Lambda(lambda x: 1. * x)(input_layer)\n","\n","    # coarse scale\n","    if flagdownScale > 0 :\n","        if flagUseMaskinEncoder == 1:\n","            x = keras.layers.AveragePooling2D((scaleLR,scaleLR), padding='valid')(x0)\n","            \n","            x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n","                padding='same',use_bias=False,\n","                kernel_regularizer=keras.regularizers.l2(wl2),\n","                kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,2*x_train.shape[3],NbFilter),dW))(x)\n","        else:\n","            x = keras.layers.AveragePooling2D((scaleLR,scaleLR), padding='valid')(x0)\n","\n","            x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n","            padding='same',use_bias=False,\n","            kernel_regularizer=keras.regularizers.l2(wl2),\n","            kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,x_train.shape[3],NbFilter),dW))(x)\n","        x  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","  \n","        # registration/evolution in feature space\n","        scale = 0.1\n","        for kk in range(0,NbResUnit):\n","            if 1*1 :\n","                dx = keras.layers.Conv2D(5*DimAE,(1,1),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","            else:\n","                dx = keras.layers.Lambda(lambda x: scale * x)(x)\n","      \n","            dx_lin  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","            dx1 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","            dx2 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","      \n","            dx1 = keras.layers.Multiply()([dx1,dx2])\n","            \n","            dx  = keras.layers.Add()([dx1,dx_lin])\n","            dx  = keras.layers.Activation('tanh')(dx)\n","            x  = keras.layers.Add()([x,dx])\n","        x  = keras.layers.Conv2D(int(x_train.shape[3]/(N_cov+1)),(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","        x1 = keras.layers.Conv2DTranspose(int(x_train.shape[3]/(N_cov+1)),(scaleLR,scaleLR),strides=(scaleLR,scaleLR),use_bias=False,activation='linear',padding='same',output_padding=None,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","        \n","        if flagSRResNet == 1: ## postprocessing: super-resolution-like block\n","            x1  = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)               \n","            \n","            scale = 0.1\n","            for kk in range(0,NbResUnit):\n","                if 1*1 :\n","                    dx = keras.layers.Conv2D(2*DimAE,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)\n","                else:\n","                    dx = keras.layers.Lambda(lambda x: scale * x)(x1)\n","          \n","                dx_lin  = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","                dx1 = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","                dx2 = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","          \n","                dx1 = keras.layers.Multiply()([dx1,dx2])\n","        \n","                dx  = keras.layers.Add()([dx1,dx_lin])\n","                dx  = keras.layers.Activation('tanh')(dx_lin)\n","                x1  = keras.layers.Add()([x1,dx])\n","            x1  = keras.layers.Conv2D(x_train.shape[3]/(N_cov+1),(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)\n","        else:\n","            x1  = keras.layers.Conv2D(2*DimAE,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1) \n","            x1  = keras.layers.Conv2D(int(x_train.shape[3]/(N_cov+1)),(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)          \n","     \n","    # fine scale\n","    if flagUseMaskinEncoder == 1:\n","        x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n","            padding='same',use_bias=False,\n","            kernel_regularizer=keras.regularizers.l2(wl2),\n","            kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,2*x_train.shape[3],NbFilter),dW))(x0)\n","    else:\n","        x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n","            padding='same',use_bias=False,\n","            kernel_regularizer=keras.regularizers.l2(wl2),\n","            kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,x_train.shape[3],NbFilter),dW))(x0)\n","\n","    if flagdownScale > 0 :\n","        x  = keras.layers.Concatenate(axis=-1)([x,x1])\n","    x  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","\n","    for kk in range(0,NbResUnit):\n","        if 1*1 :\n","            dx      = keras.layers.Conv2D(5*DimAE,(1,1),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","        else:\n","            dx  = keras.layers.Lambda(lambda x: scale * x)(x)\n","          \n","        dx_lin  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","        dx1 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","        dx2 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","          \n","        dx1 = keras.layers.Multiply()([dx1,dx2])\n","        \n","        dx  = keras.layers.Add()([dx1,dx_lin])\n","        dx  = keras.layers.Activation('tanh')(dx)\n","        x  = keras.layers.Add()([x,dx])\n","\n","    x  = keras.layers.Conv2D(int(x_train.shape[3]/(N_cov+1)),(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","\n","    if flagdownScale == 0:\n","        encoder    = keras.models.Model([input_layer,mask],x)\n","    elif flagdownScale == 1:\n","        encoder    = keras.models.Model([input_layer,mask],x1)\n","    elif flagdownScale == 2:\n","        x          = keras.layers.Add()([x,x1]) \n","        encoder    = keras.models.Model([input_layer,mask],x)\n","    elif flagdownScale == 3:\n","        x          = keras.layers.Add()([x,x1]) \n","        encoder    = keras.models.Model([input_layer,mask],[x1,x])\n","   \n","    if flagdownScale == 3:\n","        decoder_input1 = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))    \n","        decoder_input2 = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))    \n","        x1  = keras.layers.Lambda(lambda x: 1. * x)(decoder_input1)\n","        x2  = keras.layers.Lambda(lambda x: 1. * x)(decoder_input2)\n","        decoder       = keras.models.Model([decoder_input1,decoder_input2],[x1,x2])\n","    else:\n","        decoder_input = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))    \n","        x  = keras.layers.Lambda(lambda x: 1. * x)(decoder_input)\n","        decoder       = keras.models.Model(decoder_input,x)\n","      \n","    encoder.summary()\n","    decoder.summary()\n","\n","    if flagdownScale < 3:\n","        input_data = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n","        mask       = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n","  \n","        x          = decoder(encoder([input_data,mask]))\n","        model_AE   = keras.models.Model([input_data,mask],x)      \n","    elif flagdownScale == 3:\n","        \n","        input_data = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n","        mask       = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n","        x,xLR      = encoder([input_data,mask])\n","        \n","        model_AE    = keras.models.Model([input_data,mask],x)\n","        model_AE_MR = keras.models.Model([input_data,mask],[x,xLR])\n","\n","    size_tw = int(x_train.shape[3]/(N_cov+1))\n","    #model_AE.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=1e-3))\n","    model_AE.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=1e-3))\n","    model_AE.summary()\n","\n","    DimCAE = DimAE\n","\n","    return encoder, decoder, model_AE, DimCAE"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"jg0RKrt2vpZx"},"source":["def define_DINConvAE(NiterProjection,model_AE,shape,\\\n","                    size_tw,N_cov=0):\n","                     \n","\n","    # encoder-decoder with masked data\n","    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    \n","    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n","    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n","\n","    # Iterations of fixed-point projection\n","    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n","    for kk in range(0,NiterProjection):\n","        x_proj   = model_AE([x,mask])\n","        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n","        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n","        x        = keras.layers.Add()([x,x_proj])\n","\n","    x_proj = model_AE([x,mask]) \n","    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n","\n","    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n","\n","    maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n","      \n","    x_proj = global_model_FP([x_input,maskg])\n","\n","  \n","    # AE error with x_proj\n","    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj2 = model_AE([x_proj,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n","    err2    = error(x_proj,x_proj2,mask,size_tw,shape,0,N_cov)\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj3 = model_AE([x_proj,keras.layers.Lambda(lambda x:0.*x)(mask)])\n","    err3    = error(x_proj3,x_proj,mask,size_tw,shape,0,N_cov)\n","    # add all errors\n","    err    = keras.layers.Add()([err1,err2])\n","    err    = keras.layers.Add()([err,err3])\n","\n","    # return global model\n","    global_model_FP_Masked  = keras.models.Model([x_input,mask],err)\n","    global_model_FP.summary()\n","    global_model_FP_Masked.summary()\n","  \n","    return global_model_FP,global_model_FP_Masked\n","\n","def slice_layer(index):\n","    def func(x_input):\n","        return tf.gather(x_input, index, axis=3)\n","    return keras.layers.Lambda(func)\n","\n","def assign_sliced_layer(size_tw,N_cov,x_output):\n","    def func(x_input,x_output):\n","        for i in range(1,(N_cov+1)):\n","            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n","            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n","        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n","                           for i in range(0,N_cov+1)]).T.flatten()\n","        x_proj = slice_layer(index)(x_output)\n","        return x_proj\n","    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n","\n","def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n","    if x1.shape[3]>x2.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    elif x2.shape[3]>x1.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    else:\n","        err   = keras.layers.Subtract()([x1,x2])\n","        err   = keras.layers.Multiply()([err,mask])\n","    err   = keras.layers.Multiply()([err,err])\n","    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n","    err   = keras.layers.GlobalAveragePooling3D()(err)\n","    err   = keras.layers.Reshape((1,))(err)\n","    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n","    return err\n","\n","def keras_custom_loss_function(size_tw):\n","    def insert_Sobel(size_tw,dir=\"x\"):\n","        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","        if dir==\"x\":\n","            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","        if dir==\"y\":\n","            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","        for i in range(size_tw):\n","            kernel_weights[:,:,i,i]=sobel\n","        return kernel_weights\n","    def lossFunction(y_true,y_pred):\n","        mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n","        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","        Gx_true = K.conv2d(y_true, filter_gx, padding=\"same\")\n","        Gy_true = K.conv2d(y_true, filter_gy, padding=\"same\")\n","        Grad_true = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_true,Gx_true]),\\\n","                                       keras.layers.Multiply()([Gy_true,Gy_true])]))\n","        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n","        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n","        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","        mae_grad = tf.keras.losses.mean_absolute_error(Grad_true, Grad_pred)\n","        alpha= 0.5\n","        loss = ((1.-alpha)*mae) + (alpha*mae_grad)\n","        return loss\n","    return lossFunction\n","\n","def root_mean_squared_error(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n","\n","    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n","    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n","    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n","   \n","    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n","    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n","    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n","           \n","    return exp_var_AE_Tr,exp_var_AE_Tt\n","\n","# functions for the evaluation of interpolation and auto-encoding performance\n","def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n","\n","    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n","    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n","    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n","    \n","    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n","    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n","    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n","            \n","    return exp_var_AE_Tr,exp_var_AE_Tt\n","\n","def eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\n","                           mask_test,x_test,x_test_missing,x_test_pred):\n","    mse_train      = np.zeros((2))\n","    mse_train[0]   = np.sum( mask_train * (x_train_pred - x_train_missing)**2 ) / np.sum( mask_train )\n","    mse_train[1]   = np.mean( (x_train_pred - x_train)**2 )\n","    exp_var_train  = 1. - mse_train #/ var_Tr\n","            \n","    mse_test        = np.zeros((2))\n","    mse_test[0]     = np.sum( mask_test * (x_test_pred - x_test_missing)**2 ) / np.sum( mask_test )\n","    mse_test[1]     = np.mean( (x_test_pred - x_test)**2 ) \n","    exp_var_test = 1. - mse_test #/ var_Tt\n","\n","    mse_train_interp        = np.sum( (1.-mask_train) * (x_train_pred - x_train)**2 ) / np.sum( 1. - mask_train )\n","    exp_var_train_interp    = 1. - mse_train_interp \n","    \n","    mse_test_interp        = np.sum( (1.-mask_test) * (x_test_pred - x_test)**2 ) / np.sum( 1. - mask_test )\n","    exp_var_test_interp    = 1. - mse_test_interp\n","            \n","    return mse_train,exp_var_train,mse_test,exp_var_test,mse_train_interp,exp_var_train_interp,mse_test_interp,exp_var_test_interp\n","\n","# function to create recursive paths\n","def mk_dir_recursive(dir_path):\n","    if os.path.isdir(dir_path):\n","        return\n","    h, t = os.path.split(dir_path)  # head/tail\n","    if not os.path.isdir(h):\n","        mk_dir_recursive(h)\n","\n","    new_path = join_paths(h, t)\n","    if not os.path.isdir(new_path):\n","        os.mkdir(new_path)\n","\n","def Gradient(img, order):\n","    \"\"\" calculate x, y gradient and magnitude \"\"\" \n","    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n","    sobelx = sobelx/8.0\n","    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n","    sobely = sobely/8.0\n","    sobel_norm = np.sqrt(sobelx*sobelx+sobely*sobely)\n","    if (order==0):\n","        return sobelx\n","    elif (order==1):\n","        return sobely\n","    else:\n","        return sobel_norm\n","\n","def insert_Sobel(size_tw,dir=\"x\"):\n","    kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","    if dir==\"x\":\n","        sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","    if dir==\"y\":\n","        sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","    for i in range(size_tw):\n","        kernel_weights[:,:,i,i]=sobel\n","    return kernel_weights\n","\n","# New loss function for unsupervised setting:\n","# L = MAE + ||Grad||^2\n","def keras_custom_loss_function2(size_tw):\n","    def insert_Sobel(size_tw,dir=\"x\"):\n","        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","        if dir==\"x\":\n","            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","        if dir==\"y\":\n","            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","        for i in range(size_tw):\n","            kernel_weights[:,:,i,i]=sobel\n","        return kernel_weights\n","    def lossFunction(y_true,y_pred):\n","        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n","        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n","        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","        loss = K.mean(keras.layers.Multiply()([Grad_pred,Grad_pred]))\n","        return loss\n","    return lossFunction\n","\n","def thresholding(x,thr):\n","    greater = K.greater_equal(x,thr) #will return boolean values\n","    greater = K.cast(greater, dtype=K.floatx()) #will convert bool to 0 and 1    \n","    return greater\n","\n","def slice_layer(index):\n","    def func(x_input):\n","        return tf.gather(x_input, index, axis=3)\n","    return keras.layers.Lambda(func)\n","\n","def assign_sliced_layer(size_tw,N_cov,x_output):\n","    def func(x_input,x_output):\n","        for i in range(1,(N_cov+1)):\n","            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n","            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n","        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n","                           for i in range(0,N_cov+1)]).T.flatten()\n","        x_proj = slice_layer(index)(x_output)\n","        return x_proj\n","    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n","\n","def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n","    if x1.shape[3]>x2.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    elif x2.shape[3]>x1.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    else:\n","        err   = keras.layers.Subtract()([x1,x2])\n","        err   = keras.layers.Multiply()([err,mask])\n","    err   = keras.layers.Multiply()([err,err])\n","    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n","    # normalize err\n","    err   = keras.layers.GlobalAveragePooling3D()(err)\n","    err   = keras.layers.Reshape((1,))(err)\n","    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n","    return err\n","\n","def regularize_Gradient(x_proj,size_tw):\n","    filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","    filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","    def Gradient(tensors):\n","        tensor = tensors[0]\n","        filter = tensors[1]\n","        return K.conv2d(tensor, filter, padding=\"same\")\n","    Gx_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gx])\n","    Gy_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gy])\n","    #Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","    #                                    keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","    Grad_pred = keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                        keras.layers.Multiply()([Gy_pred,Gy_pred])])\n","    reg_Gradient   = keras.layers.Reshape((Grad_pred.shape[-3],Grad_pred.shape[-2],Grad_pred.shape[-1],1))(Grad_pred)\n","    reg_Gradient   = keras.layers.GlobalAveragePooling3D()(reg_Gradient)\n","    reg_Gradient   = keras.layers.Reshape((1,))(reg_Gradient)\n","    reg_Gradient   = keras.layers.Lambda(lambda x: 1*x)(reg_Gradient)\n","    return reg_Gradient\n","\n","def define_DINConvAE(NiterProjection,model_AE,shape,\\\n","                     flagUseMaskinEncoder,\\\n","                     size_tw,include_covariates,N_cov=0):\n","\n","    # encoder-decoder with masked data\n","    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    \n","    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n","    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n","\n","    # Iterations of fixed-point projection\n","    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n","    for kk in range(0,NiterProjection):\n","        x_proj   = model_AE([x,mask])\n","        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n","        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n","        x        = keras.layers.Add()([x,x_proj])\n","\n","\n","    x_proj = model_AE([x,mask]) \n","    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n","\n","    # randomly sample an additionnal missing data mask\n","    # additive noise + spatial smoothing\n","    if flagUseMaskinEncoder == 1:\n","        WAvFilter     = 3\n","        NIterAvFilter = 3\n","        thrNoise      = 1.5 * stdMask + 1e-7\n","        maskg   = keras.layers.GaussianNoise(stdMask)(mask)\n","        avFilter       = 1./(WAvFilter**3)*np.ones((WAvFilter,WAvFilter,WAvFilter,1,1))\n","        spatialAvLayer = keras.layers.Conv3D(1,(WAvFilter,WAvFilter,WAvFilter),weights=[avFilter],\\\n","                           padding='same',activation='linear',use_bias=False,name='SpatialAverage')\n","        spatialAvLayer.trainable = False\n","        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,3,1,2)))(maskg) \n","        maskg  = keras.layers.Reshape((shape[3],shape[1],shape[2],1))(maskg)\n","        for nn in range(0,NIterAvFilter):\n","            maskg  = spatialAvLayer(maskg) \n","        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,2,3,1,4)))(maskg) \n","        maskg = keras.layers.Reshape((shape[1],shape[2],shape[3]))(maskg)\n","        maskg = keras.layers.Lambda(lambda x: thresholding(x,thrNoise))(maskg)    \n","        maskg  = keras.layers.Multiply()([mask,maskg])\n","        maskg  = keras.layers.Subtract()([mask,maskg])       \n","    else:\n","        maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n","\n","    x_proj = global_model_FP([x_input,maskg])\n","    # AE error with x_proj\n","    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n","    # AE error with x_proj\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj_ = x_proj\n","    \n","    x_proj2 = model_AE([x_proj_,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n","    err2    = error(x_proj_,x_proj2,mask,size_tw,shape,0,N_cov)\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj3 = model_AE([x_proj_,keras.layers.Lambda(lambda x:0.*x)(mask)])\n","    err3    = error(x_proj3,x_proj_,mask,size_tw,shape,0,N_cov)\n","    # add all errors\n","    err    = keras.layers.Add()([err1,err2])\n","    err    = keras.layers.Add()([err,err3])\n","\n","    # return global model\n","    global_model_FP_Masked  = keras.models.Model([x_input,mask],[err,x_proj])\n","\n","    global_model_FP.summary()\n","    global_model_FP_Masked.summary()\n","    return global_model_FP,global_model_FP_Masked"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gcs8QZ4uvpZs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614841073805,"user_tz":-60,"elapsed":1212,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"fdbfec8d-9896-4f21-ad89-a118f6162067"},"source":["#Apply model     \n","encoder, decoder, model_AE, DimCAE = fl27(globParams,x_train,mask_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(11, 11, 1, 20)\n","(11, 11, 1, 20)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 64, 64, 1)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 16, 16, 1)    0           lambda[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 16, 16, 20)   2420        average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 16, 16, 20)   400         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 16, 16, 100)  2000        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 16, 16, 20)   0           conv2d_4[0][0]                   \n","                                                                 conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 16, 16, 20)   0           multiply[0][0]                   \n","                                                                 conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 16, 16, 20)   0           add[0][0]                        \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 16, 16, 20)   0           conv2d_1[0][0]                   \n","                                                                 activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 16, 16, 100)  2000        add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 16, 16, 20)   0           conv2d_8[0][0]                   \n","                                                                 conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 16, 16, 20)   0           multiply_1[0][0]                 \n","                                                                 conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 16, 16, 20)   0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 16, 16, 20)   0           add_1[0][0]                      \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 16, 16, 100)  2000        add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_2 (Multiply)           (None, 16, 16, 20)   0           conv2d_12[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 16, 16, 20)   0           multiply_2[0][0]                 \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 16, 16, 20)   0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 16, 16, 20)   0           add_3[0][0]                      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 16, 16, 100)  2000        add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_3 (Multiply)           (None, 16, 16, 20)   0           conv2d_16[0][0]                  \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 16, 16, 20)   0           multiply_3[0][0]                 \n","                                                                 conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 16, 16, 20)   0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 16, 16, 20)   0           add_5[0][0]                      \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 100)  2000        add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_4 (Multiply)           (None, 16, 16, 20)   0           conv2d_20[0][0]                  \n","                                                                 conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 16, 16, 20)   0           multiply_4[0][0]                 \n","                                                                 conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 16, 16, 20)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 16, 16, 20)   0           add_7[0][0]                      \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 100)  2000        add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_5 (Multiply)           (None, 16, 16, 20)   0           conv2d_24[0][0]                  \n","                                                                 conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 16, 16, 20)   0           multiply_5[0][0]                 \n","                                                                 conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 16, 16, 20)   0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 16, 16, 20)   0           add_9[0][0]                      \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 16, 16, 100)  2000        add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_6 (Multiply)           (None, 16, 16, 20)   0           conv2d_28[0][0]                  \n","                                                                 conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 16, 16, 20)   0           multiply_6[0][0]                 \n","                                                                 conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 16, 16, 20)   0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 16, 16, 20)   0           add_11[0][0]                     \n","                                                                 activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 16, 16, 100)  2000        add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_7 (Multiply)           (None, 16, 16, 20)   0           conv2d_32[0][0]                  \n","                                                                 conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 16, 16, 20)   0           multiply_7[0][0]                 \n","                                                                 conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 16, 16, 20)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 16, 16, 20)   0           add_13[0][0]                     \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 16, 16, 100)  2000        add_15[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_8 (Multiply)           (None, 16, 16, 20)   0           conv2d_36[0][0]                  \n","                                                                 conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 16, 16, 20)   0           multiply_8[0][0]                 \n","                                                                 conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 16, 16, 20)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 16, 16, 20)   0           add_15[0][0]                     \n","                                                                 activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 16, 16, 100)  2000        add_17[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_9 (Multiply)           (None, 16, 16, 20)   0           conv2d_40[0][0]                  \n","                                                                 conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 16, 16, 20)   0           multiply_9[0][0]                 \n","                                                                 conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 16, 16, 20)   0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 16, 16, 20)   0           add_17[0][0]                     \n","                                                                 activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 16, 16, 1)    20          add_19[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 64, 64, 1)    16          conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 64, 64, 40)   360         conv2d_transpose[0][0]           \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 64, 64, 1)    360         conv2d_43[0][0]                  \n","==================================================================================================\n","Total params: 83,576\n","Trainable params: 83,576\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 64, 64, 1)]       0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 64, 64, 1)         0         \n","=================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","model (Functional)              (None, 64, 64, 1)    83576       input_4[0][0]                    \n","                                                                 input_5[0][0]                    \n","__________________________________________________________________________________________________\n","model_1 (Functional)            (None, 64, 64, 1)    0           model[0][0]                      \n","==================================================================================================\n","Total params: 83,576\n","Trainable params: 83,576\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eOLreoecvpZw"},"source":["### Train-Model - FP - Iterated projection"]},{"cell_type":"code","metadata":{"id":"JEbLPGz_vpZ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614841077126,"user_tz":-60,"elapsed":521,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"7b445232-3fb6-4058-f6f1-f8c9d27de163"},"source":["def flagProcess4_Optim0(dict_global_Params,x_train,x_train_missing,mask_train,gt_train,\\\n","                    x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE):\n","\n","    for key,val in dict_global_Params.items():\n","        exec(\"globals()['\"+key+\"']=val\")\n","\n","    meanTr = stdsc.mean_\n","    stdTr = np.mean(stdsc.var_)\n","    # ***************** #\n","    # model compilation #\n","    # ***************** #\n","\n","    # model fit\n","    NbProjection   = [0,0,2,2,5,5,10,15,14]\n","    NbProjection   = [5,5,5,5]\n","    lrUpdate       = [1e-3,1e-4,1e-5,1e-5,1e-5,1e-6,1e-6,1e-5,1e-6]\n","    if flagTrOuputWOMissingData==0:\n","        lrUpdate   = [1e-4,1e-5,1e-6,1e-7]\n","    else:\n","        lrUpdate   = [1e-3,1e-4,1e-5,1e-6]\n","    IterUpdate     = [0,3,10,15,20,25,30,35,40]\n","    #IterUpdate     = [0,6,15,20]\n","    val_split      = 0.1\n","    \n","    iterInit = 0\n","    IterTrainAE = 0\n","    IterUpdateInit = 10000\n","    \n","    ## initialization\n","    x_train_init = np.copy(x_train_missing)\n","    x_test_init  = np.copy(x_test_missing)\n","\n","    comptUpdate = 0\n","\n","    # ******************** #\n","    # Start Learning model #\n","    # ******************** #\n","        \n","    print(\"..... Start learning AE model\")\n","    for iter in tqdm(range(iterInit,Niter)):\n","        if iter == IterUpdate[comptUpdate]:\n","            # update DINConvAE model\n","            NBProjCurrent = NbProjection[comptUpdate]\n","            print(\"..... Update/initialize number of projections in DINCOnvAE model # %d\"%(NbProjection[comptUpdate]))\n","            global_model_FP,global_model_FP_Masked = define_DINConvAE(NbProjection[comptUpdate],model_AE,x_train.shape,\\\n","                                                                          flagUseMaskinEncoder,\\\n","                                                                          size_tw,N_cov)\n","            if flagTrOuputWOMissingData == 1:\n","                global_model_FP.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","                #global_model_FP.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","            else:\n","                #global_model_FP_Masked.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","                global_model_FP_Masked.compile(loss=['mean_squared_error',keras_custom_loss_function2(size_tw)],loss_weights=[1.0,1e-10],optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","            if comptUpdate < len(NbProjection)-1:\n","                comptUpdate += 1\n","        \n","        # gradient descent iteration            \n","        if flagTrOuputWOMissingData == 1:\n","            history = global_model_FP.fit([x_train_init,mask_train],gt_train,\n","                  batch_size=batch_size,\n","                  epochs = NbEpoc,\n","                  verbose = 1, \n","                  validation_split=val_split)\n","        else:\n","            history = global_model_FP_Masked.fit([x_train_init,mask_train],[np.zeros((x_train_init.shape[0],1)),gt_train],\n","                  batch_size=batch_size,\n","                  epochs = NbEpoc,\n","                  verbose = 1, \n","                  validation_split=val_split)\n","\n","        # *********************** #\n","        # Prediction on test data #\n","        # *********************** #\n","\n","        # trained full-model\n","        x_train_pred    = global_model_FP.predict([x_train_init,mask_train])\n","        x_test_pred     = global_model_FP.predict([x_test_init,mask_test])\n","\n","        # trained AE applied to gap-free data\n","        if flagUseMaskinEncoder == 1:\n","          rec_AE_Tr     = model_AE.predict([x_train,np.zeros((mask_train.shape))])\n","          rec_AE_Tt     = model_AE.predict([x_test,np.zeros((mask_train.shape))])\n","        else:\n","          rec_AE_Tr     = model_AE.predict([x_train,np.ones((mask_train.shape))])\n","          rec_AE_Tt     = model_AE.predict([x_test,np.ones((mask_test.shape))])\n","\n","\n","        mse_train,exp_var_train,\\\n","        mse_test,exp_var_test,\\\n","        mse_train_interp,exp_var_train_interp,\\\n","        mse_test_interp,exp_var_test_interp =\\\n","        eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\\\n","                               mask_test,x_test,x_test_missing,x_test_pred)\n","        \n","        # interpolation and reconstruction score for the center image\n","        # when dealing with time series\n","        if x_train_init.shape[3] > 0 :\n","            \n","            dWCenter    = 32  \n","            \n","            dT = np.floor( x_train_init.shape[3] / 2 ).astype(int)\n","            mse_train_center        = np.mean( (x_train_pred[:,:,:,dT] - x_train[:,:,:,dT] )**2 )\n","            mse_train_center_interp = np.sum( (x_train_pred[:,:,:,dT]  - x_train[:,:,:,dT] )**2 * (1.-mask_train[:,:,:,dT])  ) / np.sum( (1.-mask_train[:,:,:,dT]) )\n","            \n","            mse_test_center         = np.mean( (x_test_pred[:,:,:,dT] - x_test[:,:,:,dT] )**2 )\n","            mse_test_center_interp  = np.sum( (x_test_pred[:,:,:,dT]  - x_test[:,:,:,dT] )**2 * (1.-mask_test[:,:,:,dT])  ) / np.sum( (1-mask_test[:,:,:,dT]) )\n","            \n","            var_train_center        = np.var(  x_train[:,:,:,dT] )\n","            var_test_center         = np.var(  x_test[:,:,:,dT] )\n","            \n","            exp_var_train_center         = 1.0 - mse_train_center / var_train_center\n","            exp_var_train_interp_center  = 1.0 - mse_train_center_interp / var_train_center\n","            exp_var_test_center          = 1.0 - mse_test_center  / var_test_center\n","            exp_var_test_interp_center   = 1.0 - mse_test_center_interp/ var_test_center\n","        # AE performance of the trained AE applied to gap-free data\n","        exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n","        \n","        print(\".......... Auto-encoder performance when applied to gap-free data\")\n","        print('.... explained variance AE (Tr)  : %.2f%%'%(100.*exp_var_AE_Tr))\n","        print('.... explained variance AE (Tt)  : %.2f%%'%(100.*exp_var_AE_Tt))\n","        \n","        if flagUseMaskinEncoder == 1:\n","        \n","            exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n","        \n","            print('.... explained variance AE (Tr) with mask  : %.2f%%'%(100.*exp_var_AE_Tr))\n","            print('.... explained variance AE (Tt) with mask  : %.2f%%'%(100.*exp_var_AE_Tt))\n","\n","\n","\n","        # update training data\n","        if iter > IterUpdateInit:\n","            # mask = 0(missing data) ; 1(data)\n","          x_train_init = mask_train * x_train_missing + (1.-mask_train) * x_train_pred\n","          x_test_init  = mask_test  * x_test_missing  + (1.-mask_test)  * x_test_pred\n","    return global_model_FP,global_model_FP_Masked\n","print('ready')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ready\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWWtqOlmvpZ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614841976094,"user_tz":-60,"elapsed":163496,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"f13a3c12-1283-4a9b-c0b9-05145e62ea13"},"source":["global_model_FP,global_model_FP_Masked=flagProcess4_Optim0(globParams,x_train,x_train_missing,mask_train,gt_train,x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["..... Start learning AE model\n","..... Update/initialize number of projections in DINCOnvAE model # 5\n","Model: \"model_11\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_14 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_15 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_94 (Lambda)              (None, 64, 64, 1)    0           input_14[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_95 (Lambda)              (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","model_2 (Functional)            (None, 64, 64, 1)    83576       lambda_94[0][0]                  \n","                                                                 input_15[0][0]                   \n","                                                                 add_68[0][0]                     \n","                                                                 input_15[0][0]                   \n","                                                                 add_69[0][0]                     \n","                                                                 input_15[0][0]                   \n","                                                                 add_70[0][0]                     \n","                                                                 input_15[0][0]                   \n","                                                                 add_71[0][0]                     \n","                                                                 input_15[0][0]                   \n","                                                                 add_72[0][0]                     \n","                                                                 input_15[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_97 (Lambda)              (None, 64, 64, 1)    0           lambda_94[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_98 (Lambda)              (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_96 (Lambda)              (None, 64, 64, 1)    0           lambda_95[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_85 (Multiply)          (None, 64, 64, 1)    0           lambda_97[0][0]                  \n","                                                                 lambda_98[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_84 (Multiply)          (None, 64, 64, 1)    0           model_2[32][0]                   \n","                                                                 lambda_96[0][0]                  \n","__________________________________________________________________________________________________\n","add_68 (Add)                    (None, 64, 64, 1)    0           multiply_85[0][0]                \n","                                                                 multiply_84[0][0]                \n","__________________________________________________________________________________________________\n","lambda_100 (Lambda)             (None, 64, 64, 1)    0           add_68[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_101 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_99 (Lambda)              (None, 64, 64, 1)    0           lambda_95[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_87 (Multiply)          (None, 64, 64, 1)    0           lambda_100[0][0]                 \n","                                                                 lambda_101[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_86 (Multiply)          (None, 64, 64, 1)    0           model_2[33][0]                   \n","                                                                 lambda_99[0][0]                  \n","__________________________________________________________________________________________________\n","add_69 (Add)                    (None, 64, 64, 1)    0           multiply_87[0][0]                \n","                                                                 multiply_86[0][0]                \n","__________________________________________________________________________________________________\n","lambda_103 (Lambda)             (None, 64, 64, 1)    0           add_69[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_104 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_102 (Lambda)             (None, 64, 64, 1)    0           lambda_95[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_89 (Multiply)          (None, 64, 64, 1)    0           lambda_103[0][0]                 \n","                                                                 lambda_104[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_88 (Multiply)          (None, 64, 64, 1)    0           model_2[34][0]                   \n","                                                                 lambda_102[0][0]                 \n","__________________________________________________________________________________________________\n","add_70 (Add)                    (None, 64, 64, 1)    0           multiply_89[0][0]                \n","                                                                 multiply_88[0][0]                \n","__________________________________________________________________________________________________\n","lambda_106 (Lambda)             (None, 64, 64, 1)    0           add_70[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_107 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_105 (Lambda)             (None, 64, 64, 1)    0           lambda_95[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_91 (Multiply)          (None, 64, 64, 1)    0           lambda_106[0][0]                 \n","                                                                 lambda_107[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_90 (Multiply)          (None, 64, 64, 1)    0           model_2[35][0]                   \n","                                                                 lambda_105[0][0]                 \n","__________________________________________________________________________________________________\n","add_71 (Add)                    (None, 64, 64, 1)    0           multiply_91[0][0]                \n","                                                                 multiply_90[0][0]                \n","__________________________________________________________________________________________________\n","lambda_109 (Lambda)             (None, 64, 64, 1)    0           add_71[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_110 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_108 (Lambda)             (None, 64, 64, 1)    0           lambda_95[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_93 (Multiply)          (None, 64, 64, 1)    0           lambda_109[0][0]                 \n","                                                                 lambda_110[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_92 (Multiply)          (None, 64, 64, 1)    0           model_2[36][0]                   \n","                                                                 lambda_108[0][0]                 \n","__________________________________________________________________________________________________\n","add_72 (Add)                    (None, 64, 64, 1)    0           multiply_93[0][0]                \n","                                                                 multiply_92[0][0]                \n","==================================================================================================\n","Total params: 83,576\n","Trainable params: 83,576\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_12\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_15 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_14 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_111 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","model_11 (Functional)           (None, 64, 64, 1)    83576       input_14[0][0]                   \n","                                                                 lambda_111[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_113 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","model_2 (Functional)            (None, 64, 64, 1)    83576       model_11[0][0]                   \n","                                                                 lambda_113[0][0]                 \n","                                                                 model_11[0][0]                   \n","                                                                 lambda_115[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_115 (Lambda)             (None, 64, 64, 1)    0           input_15[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_12 (Subtract)          (None, 64, 64, 1)    0           model_11[0][0]                   \n","                                                                 input_14[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_13 (Subtract)          (None, 64, 64, 1)    0           model_11[0][0]                   \n","                                                                 model_2[38][0]                   \n","__________________________________________________________________________________________________\n","multiply_94 (Multiply)          (None, 64, 64, 1)    0           subtract_12[0][0]                \n","                                                                 input_15[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_96 (Multiply)          (None, 64, 64, 1)    0           subtract_13[0][0]                \n","                                                                 input_15[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_14 (Subtract)          (None, 64, 64, 1)    0           model_2[39][0]                   \n","                                                                 model_11[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_95 (Multiply)          (None, 64, 64, 1)    0           multiply_94[0][0]                \n","                                                                 multiply_94[0][0]                \n","__________________________________________________________________________________________________\n","multiply_97 (Multiply)          (None, 64, 64, 1)    0           multiply_96[0][0]                \n","                                                                 multiply_96[0][0]                \n","__________________________________________________________________________________________________\n","multiply_98 (Multiply)          (None, 64, 64, 1)    0           subtract_14[0][0]                \n","                                                                 input_15[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_24 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_95[0][0]                \n","__________________________________________________________________________________________________\n","reshape_26 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_97[0][0]                \n","__________________________________________________________________________________________________\n","multiply_99 (Multiply)          (None, 64, 64, 1)    0           multiply_98[0][0]                \n","                                                                 multiply_98[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling3d_12 (Gl (None, 1)            0           reshape_24[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling3d_13 (Gl (None, 1)            0           reshape_26[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_28 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_99[0][0]                \n","__________________________________________________________________________________________________\n","reshape_25 (Reshape)            (None, 1)            0           global_average_pooling3d_12[0][0]\n","__________________________________________________________________________________________________\n","reshape_27 (Reshape)            (None, 1)            0           global_average_pooling3d_13[0][0]\n","__________________________________________________________________________________________________\n","global_average_pooling3d_14 (Gl (None, 1)            0           reshape_28[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_112 (Lambda)             (None, 1)            0           reshape_25[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_114 (Lambda)             (None, 1)            0           reshape_27[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_29 (Reshape)            (None, 1)            0           global_average_pooling3d_14[0][0]\n","__________________________________________________________________________________________________\n","add_73 (Add)                    (None, 1)            0           lambda_112[0][0]                 \n","                                                                 lambda_114[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_116 (Lambda)             (None, 1)            0           reshape_29[0][0]                 \n","__________________________________________________________________________________________________\n","add_74 (Add)                    (None, 1)            0           add_73[0][0]                     \n","                                                                 lambda_116[0][0]                 \n","==================================================================================================\n","Total params: 83,576\n","Trainable params: 83,576\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/6\n","(11, 11, 1, 20)\n","(11, 11, 1, 20)\n","51/51 [==============================] - 13s 97ms/step - loss: 0.0220 - val_loss: 0.0118\n","Epoch 2/6\n","51/51 [==============================] - 4s 73ms/step - loss: 0.0113 - val_loss: 0.0110\n","Epoch 3/6\n","51/51 [==============================] - 4s 74ms/step - loss: 0.0107 - val_loss: 0.0109\n","Epoch 4/6\n","51/51 [==============================] - 3s 68ms/step - loss: 0.0106 - val_loss: 0.0108\n","Epoch 5/6\n","51/51 [==============================] - 4s 74ms/step - loss: 0.0107 - val_loss: 0.0109\n","Epoch 6/6\n","51/51 [==============================] - 4s 71ms/step - loss: 0.0108 - val_loss: 0.0116\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: RuntimeWarning: invalid value encountered in double_scalars\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in double_scalars\n","\r 17%|â–ˆâ–‹        | 1/6 [00:36<03:01, 36.28s/it]"],"name":"stderr"},{"output_type":"stream","text":[".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 91.42%\n",".... explained variance AE (Tt)  : 91.14%\n","Epoch 1/6\n","51/51 [==============================] - 4s 71ms/step - loss: 0.0120 - val_loss: 0.0110\n","Epoch 2/6\n","51/51 [==============================] - 4s 78ms/step - loss: 0.0107 - val_loss: 0.0110\n","Epoch 3/6\n","51/51 [==============================] - 3s 67ms/step - loss: 0.0112 - val_loss: 0.0136\n","Epoch 4/6\n","51/51 [==============================] - 4s 71ms/step - loss: 0.0119 - val_loss: 0.0109\n","Epoch 5/6\n","51/51 [==============================] - 3s 66ms/step - loss: 0.0106 - val_loss: 0.0111\n","Epoch 6/6\n","51/51 [==============================] - 3s 67ms/step - loss: 0.0107 - val_loss: 0.0118\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:59<02:09, 32.30s/it]"],"name":"stderr"},{"output_type":"stream","text":[".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 91.42%\n",".... explained variance AE (Tt)  : 91.16%\n","Epoch 1/6\n","51/51 [==============================] - 4s 69ms/step - loss: 0.0123 - val_loss: 0.0111\n","Epoch 2/6\n","51/51 [==============================] - 3s 66ms/step - loss: 0.0106 - val_loss: 0.0107\n","Epoch 3/6\n","51/51 [==============================] - 3s 67ms/step - loss: 0.0105 - val_loss: 0.0114\n","Epoch 4/6\n","51/51 [==============================] - 3s 65ms/step - loss: 0.0112 - val_loss: 0.0117\n","Epoch 5/6\n","51/51 [==============================] - 4s 69ms/step - loss: 0.0107 - val_loss: 0.0107\n","Epoch 6/6\n","51/51 [==============================] - 4s 71ms/step - loss: 0.0104 - val_loss: 0.0106\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [01:21<01:28, 29.37s/it]"],"name":"stderr"},{"output_type":"stream","text":[".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 92.16%\n",".... explained variance AE (Tt)  : 91.86%\n","..... Update/initialize number of projections in DINCOnvAE model # 5\n","Model: \"model_13\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_16 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_17 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_117 (Lambda)             (None, 64, 64, 1)    0           input_16[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_118 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","model_2 (Functional)            (None, 64, 64, 1)    83576       lambda_117[0][0]                 \n","                                                                 input_17[0][0]                   \n","                                                                 add_75[0][0]                     \n","                                                                 input_17[0][0]                   \n","                                                                 add_76[0][0]                     \n","                                                                 input_17[0][0]                   \n","                                                                 add_77[0][0]                     \n","                                                                 input_17[0][0]                   \n","                                                                 add_78[0][0]                     \n","                                                                 input_17[0][0]                   \n","                                                                 add_79[0][0]                     \n","                                                                 input_17[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_120 (Lambda)             (None, 64, 64, 1)    0           lambda_117[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_121 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_119 (Lambda)             (None, 64, 64, 1)    0           lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_101 (Multiply)         (None, 64, 64, 1)    0           lambda_120[0][0]                 \n","                                                                 lambda_121[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_100 (Multiply)         (None, 64, 64, 1)    0           model_2[40][0]                   \n","                                                                 lambda_119[0][0]                 \n","__________________________________________________________________________________________________\n","add_75 (Add)                    (None, 64, 64, 1)    0           multiply_101[0][0]               \n","                                                                 multiply_100[0][0]               \n","__________________________________________________________________________________________________\n","lambda_123 (Lambda)             (None, 64, 64, 1)    0           add_75[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_124 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_122 (Lambda)             (None, 64, 64, 1)    0           lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_103 (Multiply)         (None, 64, 64, 1)    0           lambda_123[0][0]                 \n","                                                                 lambda_124[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_102 (Multiply)         (None, 64, 64, 1)    0           model_2[41][0]                   \n","                                                                 lambda_122[0][0]                 \n","__________________________________________________________________________________________________\n","add_76 (Add)                    (None, 64, 64, 1)    0           multiply_103[0][0]               \n","                                                                 multiply_102[0][0]               \n","__________________________________________________________________________________________________\n","lambda_126 (Lambda)             (None, 64, 64, 1)    0           add_76[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_127 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_125 (Lambda)             (None, 64, 64, 1)    0           lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_105 (Multiply)         (None, 64, 64, 1)    0           lambda_126[0][0]                 \n","                                                                 lambda_127[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_104 (Multiply)         (None, 64, 64, 1)    0           model_2[42][0]                   \n","                                                                 lambda_125[0][0]                 \n","__________________________________________________________________________________________________\n","add_77 (Add)                    (None, 64, 64, 1)    0           multiply_105[0][0]               \n","                                                                 multiply_104[0][0]               \n","__________________________________________________________________________________________________\n","lambda_129 (Lambda)             (None, 64, 64, 1)    0           add_77[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_130 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_128 (Lambda)             (None, 64, 64, 1)    0           lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_107 (Multiply)         (None, 64, 64, 1)    0           lambda_129[0][0]                 \n","                                                                 lambda_130[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_106 (Multiply)         (None, 64, 64, 1)    0           model_2[43][0]                   \n","                                                                 lambda_128[0][0]                 \n","__________________________________________________________________________________________________\n","add_78 (Add)                    (None, 64, 64, 1)    0           multiply_107[0][0]               \n","                                                                 multiply_106[0][0]               \n","__________________________________________________________________________________________________\n","lambda_132 (Lambda)             (None, 64, 64, 1)    0           add_78[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_133 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_131 (Lambda)             (None, 64, 64, 1)    0           lambda_118[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_109 (Multiply)         (None, 64, 64, 1)    0           lambda_132[0][0]                 \n","                                                                 lambda_133[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_108 (Multiply)         (None, 64, 64, 1)    0           model_2[44][0]                   \n","                                                                 lambda_131[0][0]                 \n","__________________________________________________________________________________________________\n","add_79 (Add)                    (None, 64, 64, 1)    0           multiply_109[0][0]               \n","                                                                 multiply_108[0][0]               \n","==================================================================================================\n","Total params: 83,576\n","Trainable params: 83,576\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_14\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_17 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_16 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_134 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","model_13 (Functional)           (None, 64, 64, 1)    83576       input_16[0][0]                   \n","                                                                 lambda_134[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_136 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","model_2 (Functional)            (None, 64, 64, 1)    83576       model_13[0][0]                   \n","                                                                 lambda_136[0][0]                 \n","                                                                 model_13[0][0]                   \n","                                                                 lambda_138[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_138 (Lambda)             (None, 64, 64, 1)    0           input_17[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_15 (Subtract)          (None, 64, 64, 1)    0           model_13[0][0]                   \n","                                                                 input_16[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_16 (Subtract)          (None, 64, 64, 1)    0           model_13[0][0]                   \n","                                                                 model_2[46][0]                   \n","__________________________________________________________________________________________________\n","multiply_110 (Multiply)         (None, 64, 64, 1)    0           subtract_15[0][0]                \n","                                                                 input_17[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_112 (Multiply)         (None, 64, 64, 1)    0           subtract_16[0][0]                \n","                                                                 input_17[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_17 (Subtract)          (None, 64, 64, 1)    0           model_2[47][0]                   \n","                                                                 model_13[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_111 (Multiply)         (None, 64, 64, 1)    0           multiply_110[0][0]               \n","                                                                 multiply_110[0][0]               \n","__________________________________________________________________________________________________\n","multiply_113 (Multiply)         (None, 64, 64, 1)    0           multiply_112[0][0]               \n","                                                                 multiply_112[0][0]               \n","__________________________________________________________________________________________________\n","multiply_114 (Multiply)         (None, 64, 64, 1)    0           subtract_17[0][0]                \n","                                                                 input_17[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_30 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_111[0][0]               \n","__________________________________________________________________________________________________\n","reshape_32 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_113[0][0]               \n","__________________________________________________________________________________________________\n","multiply_115 (Multiply)         (None, 64, 64, 1)    0           multiply_114[0][0]               \n","                                                                 multiply_114[0][0]               \n","__________________________________________________________________________________________________\n","global_average_pooling3d_15 (Gl (None, 1)            0           reshape_30[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling3d_16 (Gl (None, 1)            0           reshape_32[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_34 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_115[0][0]               \n","__________________________________________________________________________________________________\n","reshape_31 (Reshape)            (None, 1)            0           global_average_pooling3d_15[0][0]\n","__________________________________________________________________________________________________\n","reshape_33 (Reshape)            (None, 1)            0           global_average_pooling3d_16[0][0]\n","__________________________________________________________________________________________________\n","global_average_pooling3d_17 (Gl (None, 1)            0           reshape_34[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_135 (Lambda)             (None, 1)            0           reshape_31[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_137 (Lambda)             (None, 1)            0           reshape_33[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_35 (Reshape)            (None, 1)            0           global_average_pooling3d_17[0][0]\n","__________________________________________________________________________________________________\n","add_80 (Add)                    (None, 1)            0           lambda_135[0][0]                 \n","                                                                 lambda_137[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_139 (Lambda)             (None, 1)            0           reshape_35[0][0]                 \n","__________________________________________________________________________________________________\n","add_81 (Add)                    (None, 1)            0           add_80[0][0]                     \n","                                                                 lambda_139[0][0]                 \n","==================================================================================================\n","Total params: 83,576\n","Trainable params: 83,576\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/6\n","(11, 11, 1, 20)\n","(11, 11, 1, 20)\n","51/51 [==============================] - 13s 95ms/step - loss: 0.0105 - val_loss: 0.0106\n","Epoch 2/6\n","51/51 [==============================] - 4s 73ms/step - loss: 0.0104 - val_loss: 0.0106\n","Epoch 3/6\n","51/51 [==============================] - 3s 68ms/step - loss: 0.0103 - val_loss: 0.0106\n","Epoch 4/6\n","51/51 [==============================] - 3s 66ms/step - loss: 0.0102 - val_loss: 0.0106\n","Epoch 5/6\n","51/51 [==============================] - 3s 67ms/step - loss: 0.0104 - val_loss: 0.0106\n","Epoch 6/6\n","51/51 [==============================] - 3s 66ms/step - loss: 0.0103 - val_loss: 0.0106\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [01:56<01:02, 31.05s/it]"],"name":"stderr"},{"output_type":"stream","text":[".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 92.23%\n",".... explained variance AE (Tt)  : 91.91%\n","Epoch 1/6\n","51/51 [==============================] - 4s 71ms/step - loss: 0.0103 - val_loss: 0.0105\n","Epoch 2/6\n","51/51 [==============================] - 4s 74ms/step - loss: 0.0103 - val_loss: 0.0106\n","Epoch 3/6\n","51/51 [==============================] - 4s 75ms/step - loss: 0.0103 - val_loss: 0.0105\n","Epoch 4/6\n","51/51 [==============================] - 4s 69ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 5/6\n","51/51 [==============================] - 3s 66ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 6/6\n","51/51 [==============================] - 3s 67ms/step - loss: 0.0102 - val_loss: 0.0105\n"],"name":"stdout"},{"output_type":"stream","text":["\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [02:19<00:28, 28.69s/it]"],"name":"stderr"},{"output_type":"stream","text":[".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 92.27%\n",".... explained variance AE (Tt)  : 91.95%\n","Epoch 1/6\n","51/51 [==============================] - 4s 74ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 2/6\n","51/51 [==============================] - 4s 73ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 3/6\n","51/51 [==============================] - 3s 67ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 4/6\n","51/51 [==============================] - 4s 70ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 5/6\n","51/51 [==============================] - 4s 69ms/step - loss: 0.0102 - val_loss: 0.0105\n","Epoch 6/6\n","51/51 [==============================] - 3s 66ms/step - loss: 0.0102 - val_loss: 0.0104\n"],"name":"stdout"},{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [02:42<00:00, 27.17s/it]"],"name":"stderr"},{"output_type":"stream","text":[".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 92.31%\n",".... explained variance AE (Tt)  : 91.99%\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"nYGiJA8lvpZ-"},"source":["### PrÃ©diction / Interpolation "]},{"cell_type":"code","metadata":{"id":"Kl3eUXPVvpZ_"},"source":["Pred_GM = global_model_FP.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n","Pred_AE = model_AE.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n","\n","#.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gdJ9AVuvpaD"},"source":["#gt_pred_norm = stdsc.inverse_transform(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)))\n","#Pred_AE_norm = np.full(gt_pred.shape,np.nan)\n","#Pred_GM_norm = np.full(gt_pred.shape,np.nan)\n","#Pred_AE_norm[np.where(~np.isnan(gt_pred))] = stdsc.inverse_transform(Pred_AE.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[np.where(~np.isnan(gt_pred))].reshape(len(Pred_AE),-1)).ravel() \n","#Pred_GM_norm[np.where(~np.isnan(gt_pred))] = stdsc.inverse_transform(Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[np.where(~np.isnan(gt_pred))].reshape(len(Pred_GM),-1)).ravel()\n","#Pred_AE_norm = Pred_AE_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O46naj1sfJ9m"},"source":["Pred_AE_norm = stdsc.inverse_transform(Pred_AE.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = stdsc.inverse_transform(Pred_GM.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fZum6PJXi25"},"source":["Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+medabs) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+medabs).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEF-7BCz6n9M"},"source":["Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+mean_Tr) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqM26-Gjuw3y"},"source":["Pred_AE_norm[np.where(Pred_AE_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n","Pred_GM_norm[np.where(Pred_GM_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n","Pred_AE_norm[np.where(Pred_AE_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n","Pred_GM_norm[np.where(Pred_GM_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDg6dGDgu8Ip"},"source":["Pred_AE_norm=Pred_AE_norm+0.5\n","Pred_GM_norm=Pred_GM_norm+0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pAqH_TH7pjLR","colab":{"base_uri":"https://localhost:8080/","height":184},"executionInfo":{"status":"ok","timestamp":1614842314343,"user_tz":-60,"elapsed":968,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"8341e591-9dfe-4925-cb96-2f7efd589283"},"source":["i=0\n","plt.subplot(221)\n","plt.imshow(Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n","plt.colorbar()\n","plt.subplot(222)\n","plt.imshow(Pred_GM_norm.reshape(Pred_GM_norm.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[50])\n","plt.colorbar()\n","\n","print(np.nanmax(Pred_GM_norm),np.nanmax(Pred_AE_norm),np.nanmax(gt_pred))\n","print(np.nanmin(Pred_GM_norm),np.nanmin(Pred_AE_norm),np.nanmin(gt_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-1.4548914003372193 -1.2586553859710694 -0.5334281921386719\n","-4.504833295345307 -4.459451920986176 -4.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"i_MDhszraM69","colab":{"base_uri":"https://localhost:8080/","height":285},"executionInfo":{"status":"ok","timestamp":1614842417972,"user_tz":-60,"elapsed":470,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"78d565df-9165-4f5e-d218-4ee69e493bbe"},"source":["\"\"\"print(gt_pred.shape)\n","plt.imshow(Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[5]-Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n","plt.colorbar()\"\"\"\n","plt.imshow(y_pred_missing[30].reshape(64,64))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa690780b10>"]},"metadata":{"tags":[]},"execution_count":20},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ObIf6haKOSsX"},"source":["# Some metrics\n"]},{"cell_type":"code","metadata":{"id":"lP9Syz_KvpaH","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1607078418056,"user_tz":-60,"elapsed":533,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"19fad17a-8928-49e9-fbe8-ff4c0ee4fe1d"},"source":["'''if flagPred :\n","  Pred_GM_norm = Pred_GM_norm[len(mask_pred)//2:]\n","  Pred_AE_norm = Pred_AE_norm[len(mask_pred)//2:]\n","  gt_pred      = gt_pred[len(mask_pred)//2:]\n","'''"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-845a08e14edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mPred_GM_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_GM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mPred_AE_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgt_pred_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.         0.         0.         ... 1.4135437  1.43219256 1.42513895].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DbOIMlSGURRi","executionInfo":{"status":"ok","timestamp":1614842323149,"user_tz":-60,"elapsed":439,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"602fd401-79b2-4894-e4af-d94709d0367d"},"source":["#from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","import numpy as np\n","from sklearn.metrics import explained_variance_score\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import max_error\n","from sklearn.metrics import median_absolute_error\n","import datetime as dt\n","import matplotlib.pyplot as plt\n","\n","def mean_absolute_percentage_error(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.nanmean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","def RMSE(a,b):\n","    \"\"\" Compute the Root Mean Square Error between 2 n-dimensional vectors. \"\"\" \n","    return np.sqrt(np.nanmean((a-b)**2))\n","\n","\n","def Getmetrics(Target,Pred):\n","    Target_value = Target.reshape(Target.shape)[np.where(~np.isnan(Target))]\n","    Pred_value   = Pred.reshape(Target.shape)[np.where(~np.isnan(Target))]\n","    Target_flat  = Target_value.flatten()\n","    Pred_flat    = Pred_value.flatten()\n","    Metrics=dict()\n","\n","    return {'EVS':explained_variance_score(Target_flat,Pred_flat),'RMSE':RMSE(Target_flat,Pred_flat),'NRMSE':RMSE(Target_flat,Pred_flat)/np.nanmean(Target_flat),'MAbsEr%':mean_absolute_percentage_error(Target_flat,Pred_flat),'MaxEr':max_error(Target_flat,Pred_flat),'MAbsEr':median_absolute_error(Target_flat,Pred_flat),'RÂ²':r2_score(Target_flat,Pred_flat)}\n","\n","   #lissage donnÃ©e entrÃ©e flatn + nan\n","#Metric=Getmetrics(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)),Pred_GM )\n","testAE=np.copy(Pred_AE_norm)\n","testAE[np.where(testAE<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n","#print(np.nanmin(testAE))\n","MetricGM=Getmetrics(gt_pred,Pred_GM_norm)\n","MetricAE=Getmetrics(gt_pred,Pred_AE_norm)\n","print(MetricGM,MetricAE)\n","print(Getmetrics(gt_pred,testAE),Getmetrics(gt_pred,Pred_AE_norm),MetricGM)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'EVS': 0.9504256427614494, 'RMSE': 0.12629229049962115, 'NRMSE': -0.03392215609313714, 'MAbsEr%': 1.973055102032464, 'MaxEr': 1.5878864467702805, 'MAbsEr': 0.003409719793125987, 'RÂ²': 0.9503258120518892} {'EVS': 0.9657846878409643, 'RMSE': 0.10483878622165772, 'NRMSE': -0.028159736883042567, 'MAbsEr%': 1.6352918187037824, 'MaxEr': 1.600932371020317, 'MAbsEr': 0.005255662966519692, 'RÂ²': 0.9657688834767162}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Unvvl9mB2Bm"},"source":["np.save('/content/drive/MyDrive/GENN_pred_normbestRMSE',testAE)\n","np.save('/content/drive/MyDrive/GENN_GM_norm2',Pred_GM_norm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UaQwDECHhn8u","executionInfo":{"status":"ok","timestamp":1613641621891,"user_tz":-60,"elapsed":938,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"49c7fd8a-5218-4fa2-e117-7d52e5e0d5b1"},"source":["global_model_FP.save(\"/content/drive/MyDrive/modelGENN1.h5\")\n","model_AE.save(\"/content/drive/MyDrive/modelGENN.h5\")\n","print(\"Saved model to disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T8Hhd6tSXCt8","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1613641577395,"user_tz":-60,"elapsed":668,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"df2df602-d1fc-4347-9635-07658c25c4cf"},"source":["model.save(\"/content/drive/MyDrive/modelGENN.h5\")\n","print(\"Saved model to disk\")\n","from numpy import loadtxt\n","from keras.models import load_model\n"," \n","# load model\n","model = load_model('modelGENN.h5')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7600f359cd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/modelGENN.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloadtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gq06kb4Pjoe_","executionInfo":{"status":"ok","timestamp":1606998221352,"user_tz":-60,"elapsed":19028,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"0694721c-e7de-48d0-ae0a-347e9beb316d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]}]}
