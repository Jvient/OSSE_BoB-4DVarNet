{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"DinAEDec.ipynb","provenance":[{"file_id":"1GQIMp6sD21eL9UNUQqyr0vQZ7Qy03ow_","timestamp":1607607804514}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RNHzBS8nvpZB"},"source":["# Init "]},{"cell_type":"code","metadata":{"id":"I5iO50AvvpZD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608306433075,"user_tz":-60,"elapsed":1169,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"f59db7a8-eb00-4571-954d-6f643d26c34a"},"source":["#Import data \n","import numpy as np\n","import time\n","from sklearn.decomposition import PCA\n","from tqdm import tqdm\n","from random import randrange\n","import sklearn\n","from sklearn import decomposition\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from scipy.sparse import diags\n","from scipy.stats import multivariate_normal\n","from scipy.ndimage.morphology import distance_transform_edt as bwdist\n","import scipy.ndimage as nd\n","from scipy.interpolate import RegularGridInterpolator\n","import tensorflow as tf\n","import keras\n","import scipy.stats as ss \n","from keras.constraints import Constraint\n","from keras import backend as K\n","from datetime import date, datetime, timedelta\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 17732701525026928289\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15692777408\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 18275458539236365939\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kg2QP-hPvpZM"},"source":["# Parameters "]},{"cell_type":"code","metadata":{"id":"6EB_5VAtvpZP","executionInfo":{"status":"ok","timestamp":1608306433783,"user_tz":-60,"elapsed":370,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["DirSAVE                     = '/'\n","flagTrWMissingData          = 0  # Training phase with or without missing data\n","flagloadOIData              = 0    # load OI: work on rough variable or anomaly\n","lname_cov                   = [\"ssh_mod\"]\n","lid_cov                     = [\"OI\"]\n","size_tw                     = 1   # Length of the 4th dimension          \n","Wsquare                     = 4     # half-width of holes\n","Nsquare                     = 3     # number of holes\n","DimAE                       = 20  # Dimension of the latent space\n","flagLoadModel               = 0     # load pre-defined AE model or not\n","sigNoise                    = 1e-1\n","flagTrOuputWOMissingData    = 1\n","stdMask                     = 0.\n","dropout                     = 0 #[0.6,0.7,0.8]\n","wl2                         = 0.0000\n","batch_size                  = 16# monter un peu \n","NbEpoc                      = 14\n","Niter                       = 14\n","thrMisData                  = 0\n","flagPred                    = False #1 pour prediction, sinon interp\n","FlagextendTr                = False #true pour depasser la taille de train de base\n","N_cov                       = 0\n","flagUseMaskinEncoder        = 0\n","\n","def createGlobParams(params):\n","    return dict(((k, eval(k)) for k in params))\n","list_globParams=[\n","    'flagTrOuputWOMissingData','flagTrWMissingData',\\\n","    'flagloadOIData','size_tw','Wsquare',\\\n","    'Nsquare','DimAE','flagLoadModel',\\\n","    'sigNoise',\\\n","    'stdMask',\\\n","    'dropout','wl2','batch_size',\\\n","    'NbEpoc','Niter','DirSAVE','flagPred','FlagextendTr','N_cov']\n","globParams = createGlobParams(list_globParams)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ovPNEb-vpZV"},"source":["# Import data"]},{"cell_type":"code","metadata":{"id":"PTnPawODvpZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608306436534,"user_tz":-60,"elapsed":2152,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"95b0e7b8-55b7-4647-8ae9-64eadd550dfe"},"source":["dataset= np.load(\"/content/drive/My Drive/DATA/TheÌ€se/ZOI/Dataset_64_ZOI.npy\",allow_pickle='TRUE').item()\n","dataH=dataset['CSED_Hourly']\n","mask=dataset['Cloud_Daily']\n","lat_grid=dataset['Lat_ZOI']\n","lon_grid=dataset['Lon_ZOI']\n","#corr lalpaciens var exp des norm\n","# =============================================================================\n","# Creation of the test and training dataset\n","# =============================================================================\n","def prepdata(xH,mask,N_Catalog=0):\n","    if N_Catalog!=0:\n","        test=np.zeros(mask[-365:].shape)\n","        for i in range(0,len(test)):\n","            test[i]=xH[26304+i*24+12].reshape(test.shape[1],test.shape[2])\n","\n","        train=np.zeros((N_Catalog*365,xH.shape[1],xH.shape[2]))\n","\n","        for i in range(N_Catalog):\n","            for j in range(len(test)):\n","                h=randrange(0,24)\n","                train[i*365+j]=xH[i*365+j*24+h]\n","    else:\n","        xD=np.empty((xH.shape[0]//24,xH.shape[1],xH.shape[2]))\n","        for i in range(len(xD)):\n","            xD[i]=xH[12+i*24]\n","    mask_train = mask[:-100]\n","    mask_pred  = mask[-100:]\n","    x_train    = xD[:len(mask_train)]\n","    #y_pred     = xD[len(mask_train)-100:len(mask_train)]\n","    y_pred     = xD[len(mask_train):len(mask_train)+len(mask_pred)]\n","    return mask_train,mask_pred,x_train,y_pred\n","\n","\n","mask[np.where(mask==0)]=1;mask[np.where(np.isnan(mask))]=0 # O for missing data\n","mask_train,mask_pred,x_train,y_pred = prepdata(dataH,mask)\n","\n","\n","'''    \n","if flagPred:\n","    mask_train = mask[:-365]\n","    mask_test  = mask[-365:-30]\n","    mask_pred  = mask[-30:]\n","    x_train    = data[:len(mask_train)]\n","    x_test     = data[len(mask_train):len(mask_train)+len(mask_test)]\n","    y_pred     = data[len(mask_train)+len(mask_test) : len(mask_train)+len(mask_test)+len(mask_pred)]\n","else :\n","    mask_train = mask[:-365]\n","    mask_test  = mask[-365:-100]\n","    mask_pred  = mask[-100:]  \n","    x_train    = data[:len(mask_train)]\n","    x_test     = data[len(mask_train):len(mask_train)+len(mask_test)]\n","    y_pred     = data[len(mask_train)+len(mask_test) : len(mask_train)+len(mask_test)+len(mask_pred)]\n","'''\n","x_train,x_test,mask_train,mask_test=sklearn.model_selection.train_test_split(x_train,mask_train,test_size=0.33)\n","# list of test dates\n","indN_Tt = np.arange(len(x_train),len(x_train)+len(x_test))\n","indN_Tr = np.arange(len(x_train))\n","lday_test=[ datetime.strftime(datetime.strptime(\"2001-1-01\",'%Y-%m-%d')\\\n","                      + timedelta(days=np.float64(i)),\"%Y-%m-%d\") for i in indN_Tt ]\n","indLat     = np.arange(0,64)\n","indLon     = np.arange(0,64)      \n","print(indLat.shape,indLon.shape,indN_Tr.shape,indN_Tt.shape)\n","print(x_train.shape,x_test.shape,y_pred.shape)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["(64,) (64,) (895,) (441,)\n","(895, 64, 64) (441, 64, 64) (100, 64, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pa-gXMCZvpZc","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1608306436536,"user_tz":-60,"elapsed":1659,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"9585f6e0-a9c1-4aaf-945f-43b95f75aabe"},"source":["import matplotlib.pyplot as plt\n","plt.imshow(mask_pred[7].reshape(64,64))\n","plt.colorbar()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.colorbar.Colorbar at 0x7fe6e4a29320>"]},"metadata":{"tags":[]},"execution_count":25},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_1WOy6QyvpZi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608306437681,"user_tz":-60,"elapsed":2255,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"b6539354-f4e0-490e-f44d-b0811cc7014f"},"source":["'''x_train = x_train[:(N_Catalog-1)*365]\n","print(x_train.shape)\n","x_test = x_train[-365:]\n","print(x_test.shape)\n","y_pred = y_test[-365:]\n","print(y_pred.shape)\n","mask_train = mask_orig[:(N_Catalog-1)*365]\n","mask_test = mask_orig[:(N_Catalog-1)*365:-365]\n","mask_pred = mask_orig[-365:]'''\n","\n","gt_train= x_train\n","gt_test = x_test\n","gt_pred = np.copy(y_pred)\n","err_train = np.random.normal(0,thrMisData*np.nanvar(x_train),(x_train.shape))\n","err_test = np.random.normal(0,thrMisData*np.nanvar(x_test),(x_test.shape))\n","err_pred = np.random.normal(0,thrMisData*np.nanvar(y_pred),(y_pred.shape))\n","\n","stdsc=sklearn.preprocessing.StandardScaler()\n","stdsc.fit(y_pred.reshape(y_pred.shape[0],-1))\n","mean_Tr = stdsc.mean_\n","medabs  = np.copy(mean_Tr)\n","med     = np.copy(mean_Tr)\n","for i in range(len(medabs)):\n","  med[i]    =np.nanmedian(gt_train.reshape(gt_train.shape[0],-1)[:,i])\n","  medabs[i] =np.nanmedian(np.absolute(gt_train.reshape(gt_train.shape[0],-1)[:,i]-med[i]))\n","  \n","\n","print('MEAN',mean_Tr.shape)\n","std_Tr = stdsc.var_\n","\n","'''gt_train        = stdsc.transform(gt_train.reshape(x_train.shape[0],-1))\n","x_train         = stdsc.transform(x_train.reshape(x_train.shape[0],-1))\n","#x_train_missing = stdsc.fit_transform(x_train_missing.reshape(x_train_missing.shape[0],-1))\n","gt_test         = stdsc.transform(gt_test.reshape(len(x_test),-1))                          \n","x_test          = stdsc.transform(x_test.reshape(len(x_test),-1))\n","#x_test_missing  = stdsc.fit_transform(x_test_missing.reshape(x_test_missing.shape[0],-1))\n","#y_pred_missing  = stdsc.fit_transform(y_pred_missing.reshape(len(y_pred),-1))\n","y_pred          = stdsc.transform(y_pred.reshape(len(y_pred),-1))\n","#gt_pred         = stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)) '''\n","\n","gt_train        = gt_train.reshape(x_train.shape[0],-1)-mean_Tr\n","x_train         = x_train.reshape(x_train.shape[0],-1)-mean_Tr\n","#x_train_missing = stdsc.fit_transform(x_train_missing.reshape(x_train_missing.shape[0],-1))\n","gt_test         = gt_test.reshape(len(x_test),-1)-mean_Tr                       \n","x_test          = x_test.reshape(len(x_test),-1)-mean_Tr\n","#x_test_missing  = stdsc.fit_transform(x_test_missing.reshape(x_test_missing.shape[0],-1))\n","#y_pred_missing  = stdsc.fit_transform(y_pred_missing.reshape(len(y_pred),-1))\n","y_pred          = y_pred.reshape(len(y_pred),-1)-mean_Tr\n","#gt_pred         = stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1))\n","\n","'''gt_train        = gt_train.reshape(x_train.shape[0],-1)-medabs\n","x_train         = x_train.reshape(x_train.shape[0],-1)-medabs\n","#x_train_missing = stdsc.fit_transform(x_train_missing.reshape(x_train_missing.shape[0],-1))\n","gt_test         = gt_test.reshape(len(x_test),-1)-medabs                      \n","x_test          = x_test.reshape(len(x_test),-1)-medabs\n","#x_test_missing  = stdsc.fit_transform(x_test_missing.reshape(x_test_missing.shape[0],-1))\n","#y_pred_missing  = stdsc.fit_transform(y_pred_missing.reshape(len(y_pred),-1))\n","y_pred          = y_pred.reshape(len(y_pred),-1)-medabs\n","#gt_pred         = stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)) \n","'''\n","if flagTrWMissingData == 1 :\n","    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n","else :\n","    mask_train[:]=1\n","    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n","\n","x_test_missing=x_test.reshape(x_test.shape[0],indLat.shape[0],indLon.shape[0])*mask_test\n","if flagPred:\n","  mask_pred[len(mask_pred)//2:,:,:] = 0\n","y_pred_missing=y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0])*mask_pred\n","\n","#Dimensionning                           \n","gt_train        = gt_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_train         = x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_train_missing = x_train_missing.reshape(x_train_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n","mask_train      = mask_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n","\n","gt_test         = gt_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_test          = x_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n","x_test_missing  = x_test_missing.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)   \n","mask_test       = mask_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n","\n","#gt_pred         = gt_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n","y_pred          = y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n","y_pred_missing  = y_pred_missing.reshape(y_pred_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n","mask_pred       = mask_pred.reshape(mask_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n","\n","\n","'''x_train_missing[np.where(np.isnan(x_train_missing))]=0\n","x_train[np.where(np.isnan(x_train))]=0\n","x_test[np.where(np.isnan(x_test))]=0\n","x_test_missing[np.where(np.isnan(x_test_missing))]=0\n","gt_train[np.where(np.isnan(gt_train))]=0\n","gt_test[np.where(np.isnan(gt_test))]=0'''\n","\n","#Change Nan to 0 Check isany Nan/inf \n","def isany(x):\n","    x[np.where(np.isnan(x))]=0\n","    print(np.any(np.isnan(x)))\n","    print(np.any(np.isinf(x)))\n","    print(x.shape)\n","\n","isany(x_train)\n","isany(x_test)\n","isany(x_train_missing)\n","isany(x_test_missing)\n","isany(mask_test)\n","isany(mask_train)\n","isany(y_pred)\n","isany(y_pred_missing)\n","isany(x_train)\n","isany(gt_test)\n","isany(gt_train)\n","#isany(gt_pred)\n","\n","\n","print(\"... (after normalization) mean Tr = %f\"%(np.mean(gt_train)))\n","print(\"... (after normalization) mean Tt = %f\"%(np.mean(gt_test)))\n","#print(\"... (after normalization) mean Pred = %f\"%(np.mean(gt_pred)))\n","print(\"... (after normalization) mean x_train = %f\"%(np.mean(x_train)))\n","print(\"... (after normalization) mean x_train_missing = %f\"%(np.mean(x_train_missing)))\n","print(\"... (after normalization) mean x_test = %f\"%(np.mean(x_test)))\n","print(\"... (after normalization) mean x_test_missing = %f\"%(np.mean(x_test_missing)))\n","print(\"... (after normalization) mean y_pred = %f\"%(np.mean(y_pred)))\n","print(\"... (after normalization) mean y_pred_missing = %f\"%(np.mean(y_pred_missing)))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n","  updated_mean = (last_sum + new_sum) / updated_sample_count\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n","  result = op(x, *args, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered\n","  overwrite_input=overwrite_input)\n"],"name":"stderr"},{"output_type":"stream","text":["MEAN (4096,)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(100, 64, 64, 1)\n","False\n","False\n","(100, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","False\n","False\n","(441, 64, 64, 1)\n","False\n","False\n","(895, 64, 64, 1)\n","... (after normalization) mean Tr = 0.098465\n","... (after normalization) mean Tt = 0.087862\n","... (after normalization) mean x_train = 0.098465\n","... (after normalization) mean x_train_missing = 0.098465\n","... (after normalization) mean x_test = 0.087862\n","... (after normalization) mean x_test_missing = 0.010527\n","... (after normalization) mean y_pred = -0.000000\n","... (after normalization) mean y_pred_missing = -0.004867\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"93mvfED-vpZn"},"source":["### Define AE"]},{"cell_type":"code","metadata":{"id":"m0NuuUoBvpZo","executionInfo":{"status":"ok","timestamp":1608306437684,"user_tz":-60,"elapsed":1198,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["def fl24(dict_global_Params,x_data,mask_data):\n","\n","     # import Global Parameters\n","    for key,val in dict_global_Params.items():\n","        exec(\"globals()['\"+key+\"']=val\")\n","\n","    DimCAE = DimAE\n","\n","    input_layer = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n","    mask       = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n","\n","    x = keras.layers.Conv2D(DimAE,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(input_layer)            \n","    x = keras.layers.Dropout(dropout)(x)\n","    x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n","    x = keras.layers.Conv2D(2*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    x = keras.layers.Dropout(dropout)(x)\n","    x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n","    x = keras.layers.Conv2D(4*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    x = keras.layers.Dropout(dropout)(x)\n","    x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n","    x = keras.layers.Conv2D(8*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    #x = keras.layers.Dropout(dropout)(x)\n","    #x = keras.layers.AveragePooling2D((2,2), padding='valid')(x)\n","    #x = keras.layers.Conv2D(16*DimAE,(3,3),activation='relu', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    x = keras.layers.Dropout(dropout)(x)\n","    x = keras.layers.AveragePooling2D((5,5), padding='valid')(x)\n","    x = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    \n","    encoder    = keras.models.Model([input_layer,mask],x)\n","                 \n","    decoder_input = keras.layers.Input(shape=(int(np.floor(x_data.shape[1]/40)),int(np.floor(x_data.shape[2]/40)),DimAE))    \n","    x = keras.layers.Conv2DTranspose(256,(32,32),strides=(32,32),use_bias=False,activation='relu',padding='same',output_padding=None,kernel_regularizer=keras.regularizers.l2(wl2))(decoder_input)\n","    x = keras.layers.Dropout(dropout)(x)\n","    x = keras.layers.Conv2DTranspose(128,(3,3),strides=(2,2),use_bias=False,activation='relu',padding='same',output_padding=None,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    x = keras.layers.Dropout(dropout)(x)\n","    x = keras.layers.Conv2D(64,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    \n","    for kk in range(0,2):\n","        dx = keras.layers.Conv2D(128,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","        dx = keras.layers.Dropout(dropout)(dx)\n","        dx = keras.layers.Conv2D(64,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n","        dx = keras.layers.Dropout(dropout)(dx)\n","        x  = keras.layers.Add()([x,dx])\n","\n","    x = keras.layers.Conv2D(int(x_data.shape[3]/(N_cov+1)),(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n","    decoder       = keras.models.Model(decoder_input,x)\n","      \n","    encoder.summary()\n","    decoder.summary()\n","\n","    input_data = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n","    mask       = keras.layers.Input(shape=(x_data.shape[1],x_data.shape[2],x_data.shape[3]))\n","    x          = decoder(encoder([input_data,mask]))\n","    model_AE   = keras.models.Model([input_data,mask],x)\n","  \n","    #model_AE.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=1e-3))\n","    size_tw = int(x_data.shape[3]/(N_cov+1))\n","    model_AE.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=1e-3))\n","    model_AE.summary()\n","\n","    if DimCAE > x_data.shape[0] :\n","        DimCAE = DimAE\n","\n","    return  encoder, decoder, model_AE, DimCAE\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"jg0RKrt2vpZx","executionInfo":{"status":"ok","timestamp":1608306439283,"user_tz":-60,"elapsed":2221,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["def define_DINConvAE(NiterProjection,model_AE,shape,\\\n","                    size_tw,N_cov=0):\n","                     \n","\n","    # encoder-decoder with masked data\n","    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    \n","    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n","    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n","\n","    # Iterations of fixed-point projection\n","    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n","    for kk in range(0,NiterProjection):\n","        x_proj   = model_AE([x,mask])\n","        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n","        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n","        x        = keras.layers.Add()([x,x_proj])\n","\n","    x_proj = model_AE([x,mask]) \n","    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n","\n","    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n","\n","    maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n","      \n","    x_proj = global_model_FP([x_input,maskg])\n","\n","  \n","    # AE error with x_proj\n","    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj2 = model_AE([x_proj,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n","    err2    = error(x_proj,x_proj2,mask,size_tw,shape,0,N_cov)\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj3 = model_AE([x_proj,keras.layers.Lambda(lambda x:0.*x)(mask)])\n","    err3    = error(x_proj3,x_proj,mask,size_tw,shape,0,N_cov)\n","    # add all errors\n","    err    = keras.layers.Add()([err1,err2])\n","    err    = keras.layers.Add()([err,err3])\n","\n","    # return global model\n","    global_model_FP_Masked  = keras.models.Model([x_input,mask],err)\n","    global_model_FP.summary()\n","    global_model_FP_Masked.summary()\n","  \n","    return global_model_FP,global_model_FP_Masked\n","\n","def slice_layer(index):\n","    def func(x_input):\n","        return tf.gather(x_input, index, axis=3)\n","    return keras.layers.Lambda(func)\n","\n","def assign_sliced_layer(size_tw,N_cov,x_output):\n","    def func(x_input,x_output):\n","        for i in range(1,(N_cov+1)):\n","            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n","            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n","        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n","                           for i in range(0,N_cov+1)]).T.flatten()\n","        x_proj = slice_layer(index)(x_output)\n","        return x_proj\n","    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n","\n","def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n","    if x1.shape[3]>x2.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    elif x2.shape[3]>x1.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    else:\n","        err   = keras.layers.Subtract()([x1,x2])\n","        err   = keras.layers.Multiply()([err,mask])\n","    err   = keras.layers.Multiply()([err,err])\n","    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n","    err   = keras.layers.GlobalAveragePooling3D()(err)\n","    err   = keras.layers.Reshape((1,))(err)\n","    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n","    return err\n","\n","def keras_custom_loss_function(size_tw):\n","    def insert_Sobel(size_tw,dir=\"x\"):\n","        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","        if dir==\"x\":\n","            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","        if dir==\"y\":\n","            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","        for i in range(size_tw):\n","            kernel_weights[:,:,i,i]=sobel\n","        return kernel_weights\n","    def lossFunction(y_true,y_pred):\n","        mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n","        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","        Gx_true = K.conv2d(y_true, filter_gx, padding=\"same\")\n","        Gy_true = K.conv2d(y_true, filter_gy, padding=\"same\")\n","        Grad_true = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_true,Gx_true]),\\\n","                                       keras.layers.Multiply()([Gy_true,Gy_true])]))\n","        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n","        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n","        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","        mae_grad = tf.keras.losses.mean_absolute_error(Grad_true, Grad_pred)\n","        alpha= 0.5\n","        loss = ((1.-alpha)*mae) + (alpha*mae_grad)\n","        return loss\n","    return lossFunction\n","\n","def root_mean_squared_error(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n","\n","def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n","\n","    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n","    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n","    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n","   \n","    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n","    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n","    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n","           \n","    return exp_var_AE_Tr,exp_var_AE_Tt\n","\n","# functions for the evaluation of interpolation and auto-encoding performance\n","def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n","\n","    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n","    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n","    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n","    \n","    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n","    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n","    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n","            \n","    return exp_var_AE_Tr,exp_var_AE_Tt\n","\n","def eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\n","                           mask_test,x_test,x_test_missing,x_test_pred):\n","    mse_train      = np.zeros((2))\n","    mse_train[0]   = np.sum( mask_train * (x_train_pred - x_train_missing)**2 ) / np.sum( mask_train )\n","    mse_train[1]   = np.mean( (x_train_pred - x_train)**2 )\n","    exp_var_train  = 1. - mse_train #/ var_Tr\n","            \n","    mse_test        = np.zeros((2))\n","    mse_test[0]     = np.sum( mask_test * (x_test_pred - x_test_missing)**2 ) / np.sum( mask_test )\n","    mse_test[1]     = np.mean( (x_test_pred - x_test)**2 ) \n","    exp_var_test = 1. - mse_test #/ var_Tt\n","\n","    mse_train_interp        = np.sum( (1.-mask_train) * (x_train_pred - x_train)**2 ) / np.sum( 1. - mask_train )\n","    exp_var_train_interp    = 1. - mse_train_interp \n","    \n","    mse_test_interp        = np.sum( (1.-mask_test) * (x_test_pred - x_test)**2 ) / np.sum( 1. - mask_test )\n","    exp_var_test_interp    = 1. - mse_test_interp\n","            \n","    return mse_train,exp_var_train,mse_test,exp_var_test,mse_train_interp,exp_var_train_interp,mse_test_interp,exp_var_test_interp\n","\n","# function to create recursive paths\n","def mk_dir_recursive(dir_path):\n","    if os.path.isdir(dir_path):\n","        return\n","    h, t = os.path.split(dir_path)  # head/tail\n","    if not os.path.isdir(h):\n","        mk_dir_recursive(h)\n","\n","    new_path = join_paths(h, t)\n","    if not os.path.isdir(new_path):\n","        os.mkdir(new_path)\n","\n","def Gradient(img, order):\n","    \"\"\" calculate x, y gradient and magnitude \"\"\" \n","    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n","    sobelx = sobelx/8.0\n","    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n","    sobely = sobely/8.0\n","    sobel_norm = np.sqrt(sobelx*sobelx+sobely*sobely)\n","    if (order==0):\n","        return sobelx\n","    elif (order==1):\n","        return sobely\n","    else:\n","        return sobel_norm\n","\n","def insert_Sobel(size_tw,dir=\"x\"):\n","    kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","    if dir==\"x\":\n","        sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","    if dir==\"y\":\n","        sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","    for i in range(size_tw):\n","        kernel_weights[:,:,i,i]=sobel\n","    return kernel_weights\n","\n","'''def keras_custom_loss_function(size_tw):\n","    def insert_Sobel(size_tw,dir=\"x\"):\n","        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","        if dir==\"x\":\n","            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","        if dir==\"y\":\n","            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","        for i in range(size_tw):\n","            kernel_weights[:,:,i,i]=sobel\n","        return kernel_weights\n","    def lossFunction(y_true,y_pred):\n","        mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n","        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","        Gx_true = K.conv2d(y_true, filter_gx, padding=\"same\")\n","        Gy_true = K.conv2d(y_true, filter_gy, padding=\"same\")\n","        Grad_true = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_true,Gx_true]),\\\n","                                       keras.layers.Multiply()([Gy_true,Gy_true])]))\n","        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n","        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n","        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","        mae_grad = tf.keras.losses.mean_absolute_error(Grad_true, Grad_pred)\n","        alpha= 0.5\n","        loss = ((1.-alpha)*mae) + (alpha*mae_grad)\n","        return loss\n","    return lossFunction'''\n","\n","# New loss function for unsupervised setting:\n","# L = MAE + ||Grad||^2\n","def keras_custom_loss_function2(size_tw):\n","    def insert_Sobel(size_tw,dir=\"x\"):\n","        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n","        if dir==\"x\":\n","            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n","        if dir==\"y\":\n","            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n","        for i in range(size_tw):\n","            kernel_weights[:,:,i,i]=sobel\n","        return kernel_weights\n","    def lossFunction(y_true,y_pred):\n","        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n","        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n","        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","        loss = K.mean(keras.layers.Multiply()([Grad_pred,Grad_pred]))\n","        return loss\n","    return lossFunction\n","\n","def thresholding(x,thr):\n","    greater = K.greater_equal(x,thr) #will return boolean values\n","    greater = K.cast(greater, dtype=K.floatx()) #will convert bool to 0 and 1    \n","    return greater\n","\n","def slice_layer(index):\n","    def func(x_input):\n","        return tf.gather(x_input, index, axis=3)\n","    return keras.layers.Lambda(func)\n","\n","def assign_sliced_layer(size_tw,N_cov,x_output):\n","    def func(x_input,x_output):\n","        for i in range(1,(N_cov+1)):\n","            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n","            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n","        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n","                           for i in range(0,N_cov+1)]).T.flatten()\n","        x_proj = slice_layer(index)(x_output)\n","        return x_proj\n","    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n","\n","def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n","    if x1.shape[3]>x2.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    elif x2.shape[3]>x1.shape[3]:\n","        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n","        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n","        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n","    else:\n","        err   = keras.layers.Subtract()([x1,x2])\n","        err   = keras.layers.Multiply()([err,mask])\n","    err   = keras.layers.Multiply()([err,err])\n","    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n","    # normalize err\n","    err   = keras.layers.GlobalAveragePooling3D()(err)\n","    err   = keras.layers.Reshape((1,))(err)\n","    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n","    return err\n","\n","def regularize_Gradient(x_proj,size_tw):\n","    filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n","    filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n","    def Gradient(tensors):\n","        tensor = tensors[0]\n","        filter = tensors[1]\n","        return K.conv2d(tensor, filter, padding=\"same\")\n","    Gx_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gx])\n","    Gy_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gy])\n","    #Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","    #                                    keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n","    Grad_pred = keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n","                                        keras.layers.Multiply()([Gy_pred,Gy_pred])])\n","    reg_Gradient   = keras.layers.Reshape((Grad_pred.shape[-3],Grad_pred.shape[-2],Grad_pred.shape[-1],1))(Grad_pred)\n","    reg_Gradient   = keras.layers.GlobalAveragePooling3D()(reg_Gradient)\n","    reg_Gradient   = keras.layers.Reshape((1,))(reg_Gradient)\n","    reg_Gradient   = keras.layers.Lambda(lambda x: 1*x)(reg_Gradient)\n","    return reg_Gradient\n","\n","def define_DINConvAE(NiterProjection,model_AE,shape,\\\n","                     flagUseMaskinEncoder,\\\n","                     size_tw,include_covariates,N_cov=0):\n","\n","    # encoder-decoder with masked data\n","    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n","    \n","    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n","    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n","\n","    # Iterations of fixed-point projection\n","    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n","    for kk in range(0,NiterProjection):\n","        x_proj   = model_AE([x,mask])\n","        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n","        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n","        x        = keras.layers.Add()([x,x_proj])\n","\n","\n","    x_proj = model_AE([x,mask]) \n","    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n","\n","    # randomly sample an additionnal missing data mask\n","    # additive noise + spatial smoothing\n","    if flagUseMaskinEncoder == 1:\n","        WAvFilter     = 3\n","        NIterAvFilter = 3\n","        thrNoise      = 1.5 * stdMask + 1e-7\n","        maskg   = keras.layers.GaussianNoise(stdMask)(mask)\n","        avFilter       = 1./(WAvFilter**3)*np.ones((WAvFilter,WAvFilter,WAvFilter,1,1))\n","        spatialAvLayer = keras.layers.Conv3D(1,(WAvFilter,WAvFilter,WAvFilter),weights=[avFilter],\\\n","                           padding='same',activation='linear',use_bias=False,name='SpatialAverage')\n","        spatialAvLayer.trainable = False\n","        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,3,1,2)))(maskg) \n","        maskg  = keras.layers.Reshape((shape[3],shape[1],shape[2],1))(maskg)\n","        for nn in range(0,NIterAvFilter):\n","            maskg  = spatialAvLayer(maskg) \n","        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,2,3,1,4)))(maskg) \n","        maskg = keras.layers.Reshape((shape[1],shape[2],shape[3]))(maskg)\n","        maskg = keras.layers.Lambda(lambda x: thresholding(x,thrNoise))(maskg)    \n","        maskg  = keras.layers.Multiply()([mask,maskg])\n","        maskg  = keras.layers.Subtract()([mask,maskg])       \n","    else:\n","        maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n","\n","    x_proj = global_model_FP([x_input,maskg])\n","    # AE error with x_proj\n","    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n","    # AE error with x_proj\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj_ = x_proj\n","    \n","    x_proj2 = model_AE([x_proj_,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n","    err2    = error(x_proj_,x_proj2,mask,size_tw,shape,0,N_cov)\n","    # compute error (x_proj-x_input)**2 with full-1 mask\n","    x_proj3 = model_AE([x_proj_,keras.layers.Lambda(lambda x:0.*x)(mask)])\n","    err3    = error(x_proj3,x_proj_,mask,size_tw,shape,0,N_cov)\n","    # add all errors\n","    err    = keras.layers.Add()([err1,err2])\n","    err    = keras.layers.Add()([err,err3])\n","\n","    # return global model\n","    global_model_FP_Masked  = keras.models.Model([x_input,mask],[err,x_proj])\n","\n","    global_model_FP.summary()\n","    global_model_FP_Masked.summary()\n","    return global_model_FP,global_model_FP_Masked"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gcs8QZ4uvpZs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608306439285,"user_tz":-60,"elapsed":1637,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"d78b946f-1da0-4839-b2a1-38d01e1153c2"},"source":["#Apply model     \n","encoder, decoder, model_AE, DimCAE = fl24(globParams,x_train,mask_train)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"model_13\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_20 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 64, 64, 20)   180         input_20[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 64, 64, 20)   0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_12 (AveragePo (None, 32, 32, 20)   0           dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 32, 32, 40)   7240        average_pooling2d_12[0][0]       \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 32, 32, 40)   0           conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_13 (AveragePo (None, 16, 16, 40)   0           dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 16, 16, 80)   28880       average_pooling2d_13[0][0]       \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 16, 16, 80)   0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_14 (AveragePo (None, 8, 8, 80)     0           dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 8, 8, 160)    115360      average_pooling2d_14[0][0]       \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 8, 8, 160)    0           conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_15 (AveragePo (None, 1, 1, 160)    0           dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","input_21 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 1, 1, 20)     3220        average_pooling2d_15[0][0]       \n","==================================================================================================\n","Total params: 154,880\n","Trainable params: 154,880\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_14\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_22 (InputLayer)           [(None, 1, 1, 20)]   0                                            \n","__________________________________________________________________________________________________\n","conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 256)  5242880     input_22[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 32, 32, 256)  0           conv2d_transpose_6[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_transpose_7 (Conv2DTrans (None, 64, 64, 128)  294912      dropout_34[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 64, 64, 128)  0           conv2d_transpose_7[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 64, 64, 64)   73728       dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 64, 64, 128)  73728       conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 64, 64, 128)  0           conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 64, 64, 64)   73728       dropout_36[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 64, 64, 64)   0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 64, 64, 64)   0           conv2d_38[0][0]                  \n","                                                                 dropout_37[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 64, 64, 128)  73728       add_20[0][0]                     \n","__________________________________________________________________________________________________\n","dropout_38 (Dropout)            (None, 64, 64, 128)  0           conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 64, 64, 64)   73728       dropout_38[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_39 (Dropout)            (None, 64, 64, 64)   0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 64, 64, 64)   0           add_20[0][0]                     \n","                                                                 dropout_39[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 64, 64, 1)    576         add_21[0][0]                     \n","==================================================================================================\n","Total params: 5,907,008\n","Trainable params: 5,907,008\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_15\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_23 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_24 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","model_13 (Functional)           (None, 1, 1, 20)     154880      input_23[0][0]                   \n","                                                                 input_24[0][0]                   \n","__________________________________________________________________________________________________\n","model_14 (Functional)           (None, 64, 64, 1)    5907008     model_13[0][0]                   \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eOLreoecvpZw"},"source":["### Train-Model - FP - Iterated projection"]},{"cell_type":"code","metadata":{"id":"JEbLPGz_vpZ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608306467355,"user_tz":-60,"elapsed":577,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"f5c7a30e-f10f-4197-b2d5-c05dfa9f1a4d"},"source":["def flagProcess4_Optim0(dict_global_Params,x_train,x_train_missing,mask_train,gt_train,\\\n","                    x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE):\n","\n","    for key,val in dict_global_Params.items():\n","        exec(\"globals()['\"+key+\"']=val\")\n","\n","    meanTr = stdsc.mean_\n","    stdTr = np.mean(stdsc.var_)\n","    # ***************** #\n","    # model compilation #\n","    # ***************** #\n","\n","    # model fit\n","    NbProjection   = [0,0,2,2,5,5,10,15,14]\n","    NbProjection   = [5,5,5,5]\n","    lrUpdate       = [1e-3,1e-4,1e-5,1e-5,1e-5,1e-6,1e-6,1e-5,1e-6]\n","    if flagTrOuputWOMissingData==0:\n","        lrUpdate   = [1e-4,1e-5,1e-6,1e-7]\n","    else:\n","        lrUpdate   = [1e-3,1e-4,1e-5,1e-6]\n","    IterUpdate     = [0,3,10,15,20,25,30,35,40]\n","    #IterUpdate     = [0,6,15,20]\n","    val_split      = 0.1\n","    \n","    iterInit = 0\n","    IterTrainAE = 0\n","    IterUpdateInit = 10000\n","    \n","    ## initialization\n","    x_train_init = np.copy(x_train_missing)\n","    x_test_init  = np.copy(x_test_missing)\n","\n","    comptUpdate = 0\n","\n","    # ******************** #\n","    # Start Learning model #\n","    # ******************** #\n","        \n","    print(\"..... Start learning AE model\")\n","    for iter in range(iterInit,Niter):\n","        if iter == IterUpdate[comptUpdate]:\n","            # update DINConvAE model\n","            NBProjCurrent = NbProjection[comptUpdate]\n","            print(\"..... Update/initialize number of projections in DINCOnvAE model # %d\"%(NbProjection[comptUpdate]))\n","            global_model_FP,global_model_FP_Masked = define_DINConvAE(NbProjection[comptUpdate],model_AE,x_train.shape,\\\n","                                                                          flagUseMaskinEncoder,\\\n","                                                                          size_tw,N_cov)\n","            if flagTrOuputWOMissingData == 1:\n","                #global_model_FP.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","                global_model_FP.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","            else:\n","                #global_model_FP_Masked.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","                global_model_FP_Masked.compile(loss=['mean_squared_error',keras_custom_loss_function2(size_tw)],loss_weights=[1.0,1e-10],optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n","            if comptUpdate < len(NbProjection)-1:\n","                comptUpdate += 1\n","        \n","        # gradient descent iteration            \n","        if flagTrOuputWOMissingData == 1:\n","            history = global_model_FP.fit([x_train_init,mask_train],gt_train,\n","                  batch_size=batch_size,\n","                  epochs = NbEpoc,\n","                  verbose = 1, \n","                  validation_split=val_split)\n","        else:\n","            history = global_model_FP_Masked.fit([x_train_init,mask_train],[np.zeros((x_train_init.shape[0],1)),gt_train],\n","                  batch_size=batch_size,\n","                  epochs = NbEpoc,\n","                  verbose = 1, \n","                  validation_split=val_split)\n","\n","        # *********************** #\n","        # Prediction on test data #\n","        # *********************** #\n","\n","        # trained full-model\n","        x_train_pred    = global_model_FP.predict([x_train_init,mask_train])\n","        x_test_pred     = global_model_FP.predict([x_test_init,mask_test])\n","\n","        # trained AE applied to gap-free data\n","        if flagUseMaskinEncoder == 1:\n","          rec_AE_Tr     = model_AE.predict([x_train,np.zeros((mask_train.shape))])\n","          rec_AE_Tt     = model_AE.predict([x_test,np.zeros((mask_train.shape))])\n","        else:\n","          rec_AE_Tr     = model_AE.predict([x_train,np.ones((mask_train.shape))])\n","          rec_AE_Tt     = model_AE.predict([x_test,np.ones((mask_test.shape))])\n","\n","\n","        mse_train,exp_var_train,\\\n","        mse_test,exp_var_test,\\\n","        mse_train_interp,exp_var_train_interp,\\\n","        mse_test_interp,exp_var_test_interp =\\\n","        eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\\\n","                               mask_test,x_test,x_test_missing,x_test_pred)\n","        \n","        print(\".......... iter %d\"%(iter))\n","        print('.... Error for all data (Tr)        : %.2e %.2f%%'%(mse_train[1]*stdTr**2,100.*exp_var_train[1]))\n","        print('.... Error for all data (Tt)        : %.2e %.2f%%'%(mse_test[1]*stdTr**2,100.*exp_var_test[1]))\n","        print('....')\n","        print('.... Error for observed data (Tr)  : %.2e %.2f%%'%(mse_train[0]*stdTr**2,100.*exp_var_train[0]))\n","        print('.... Error for observed data (Tt)  : %.2e %.2f%%'%(mse_test[0]*stdTr**2,100.*exp_var_test[0]))\n","        print('....')\n","        print('.... Error for masked data (Tr)  : %.2e %.2f%%'%(mse_train_interp*stdTr**2,100.*exp_var_train_interp))\n","        print('.... Error for masked data (Tt)  : %.2e %.2f%%'%(mse_test_interp*stdTr**2,100.*exp_var_test_interp))\n","\n","        # interpolation and reconstruction score for the center image\n","        # when dealing with time series\n","        if x_train_init.shape[3] > 0 :\n","            \n","            dWCenter    = 32  \n","            \n","            dT = np.floor( x_train_init.shape[3] / 2 ).astype(int)\n","            mse_train_center        = np.mean( (x_train_pred[:,:,:,dT] - x_train[:,:,:,dT] )**2 )\n","            mse_train_center_interp = np.sum( (x_train_pred[:,:,:,dT]  - x_train[:,:,:,dT] )**2 * (1.-mask_train[:,:,:,dT])  ) / np.sum( (1.-mask_train[:,:,:,dT]) )\n","            \n","            mse_test_center         = np.mean( (x_test_pred[:,:,:,dT] - x_test[:,:,:,dT] )**2 )\n","            mse_test_center_interp  = np.sum( (x_test_pred[:,:,:,dT]  - x_test[:,:,:,dT] )**2 * (1.-mask_test[:,:,:,dT])  ) / np.sum( (1-mask_test[:,:,:,dT]) )\n","            \n","            var_train_center        = np.var(  x_train[:,:,:,dT] )\n","            var_test_center         = np.var(  x_test[:,:,:,dT] )\n","            \n","            exp_var_train_center         = 1.0 - mse_train_center / var_train_center\n","            exp_var_train_interp_center  = 1.0 - mse_train_center_interp / var_train_center\n","            exp_var_test_center          = 1.0 - mse_test_center  / var_test_center\n","            exp_var_test_interp_center   = 1.0 - mse_test_center_interp/ var_test_center\n","        print('.... Performance for \"center\" image')\n","        print('.... Image center variance (Tr)  : %.2f'%var_train_center)\n","        print('.... Image center variance (Tt)  : %.2f'%var_test_center)\n","        print('.... Error for all data (Tr)     : %.2e %.2f%%'%(mse_train_center*stdTr**2,100.*exp_var_train_center))\n","        print('.... Error for all data (Tt)     : %.2e %.2f%%'%(mse_test_center*stdTr**2,100.*exp_var_test_center))\n","        print('.... Error for masked data (Tr)  : %.2e %.2f%%'%(mse_train_center_interp*stdTr**2,100.*exp_var_train_interp_center))\n","        print('.... Error for masked data (Tt)  : %.2e %.2f%%'%(mse_test_center_interp*stdTr**2 ,100.*exp_var_test_interp_center))            \n","        print('   ')\n","        \n","        # AE performance of the trained AE applied to gap-free data\n","        exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n","        \n","        print(\".......... Auto-encoder performance when applied to gap-free data\")\n","        print('.... explained variance AE (Tr)  : %.2f%%'%(100.*exp_var_AE_Tr))\n","        print('.... explained variance AE (Tt)  : %.2f%%'%(100.*exp_var_AE_Tt))\n","        \n","        if flagUseMaskinEncoder == 1:\n","        \n","            exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n","        \n","            print('.... explained variance AE (Tr) with mask  : %.2f%%'%(100.*exp_var_AE_Tr))\n","            print('.... explained variance AE (Tt) with mask  : %.2f%%'%(100.*exp_var_AE_Tt))\n","\n","\n","\n","        # update training data\n","        if iter > IterUpdateInit:\n","            # mask = 0(missing data) ; 1(data)\n","          x_train_init = mask_train * x_train_missing + (1.-mask_train) * x_train_pred\n","          x_test_init  = mask_test  * x_test_missing  + (1.-mask_test)  * x_test_pred\n","    return global_model_FP,global_model_FP_Masked\n","print('ready')\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["ready\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWWtqOlmvpZ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608309718877,"user_tz":-60,"elapsed":3250584,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"15e515c2-cc25-4ff9-f1d6-1a7126a62d40"},"source":["global_model_FP,global_model_FP_Masked=flagProcess4_Optim0(globParams,x_train,x_train_missing,mask_train,gt_train,x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["..... Start learning AE model\n","..... Update/initialize number of projections in DINCOnvAE model # 5\n","Model: \"model_16\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_25 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_26 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_46 (Lambda)              (None, 64, 64, 1)    0           input_25[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_47 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","model_15 (Functional)           (None, 64, 64, 1)    6061888     lambda_46[0][0]                  \n","                                                                 input_26[0][0]                   \n","                                                                 add_22[0][0]                     \n","                                                                 input_26[0][0]                   \n","                                                                 add_23[0][0]                     \n","                                                                 input_26[0][0]                   \n","                                                                 add_24[0][0]                     \n","                                                                 input_26[0][0]                   \n","                                                                 add_25[0][0]                     \n","                                                                 input_26[0][0]                   \n","                                                                 add_26[0][0]                     \n","                                                                 input_26[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_49 (Lambda)              (None, 64, 64, 1)    0           lambda_46[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_50 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_48 (Lambda)              (None, 64, 64, 1)    0           lambda_47[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_33 (Multiply)          (None, 64, 64, 1)    0           lambda_49[0][0]                  \n","                                                                 lambda_50[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_32 (Multiply)          (None, 64, 64, 1)    0           model_15[0][0]                   \n","                                                                 lambda_48[0][0]                  \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 64, 64, 1)    0           multiply_33[0][0]                \n","                                                                 multiply_32[0][0]                \n","__________________________________________________________________________________________________\n","lambda_52 (Lambda)              (None, 64, 64, 1)    0           add_22[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_53 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_51 (Lambda)              (None, 64, 64, 1)    0           lambda_47[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_35 (Multiply)          (None, 64, 64, 1)    0           lambda_52[0][0]                  \n","                                                                 lambda_53[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_34 (Multiply)          (None, 64, 64, 1)    0           model_15[1][0]                   \n","                                                                 lambda_51[0][0]                  \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 64, 64, 1)    0           multiply_35[0][0]                \n","                                                                 multiply_34[0][0]                \n","__________________________________________________________________________________________________\n","lambda_55 (Lambda)              (None, 64, 64, 1)    0           add_23[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_56 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_54 (Lambda)              (None, 64, 64, 1)    0           lambda_47[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_37 (Multiply)          (None, 64, 64, 1)    0           lambda_55[0][0]                  \n","                                                                 lambda_56[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_36 (Multiply)          (None, 64, 64, 1)    0           model_15[2][0]                   \n","                                                                 lambda_54[0][0]                  \n","__________________________________________________________________________________________________\n","add_24 (Add)                    (None, 64, 64, 1)    0           multiply_37[0][0]                \n","                                                                 multiply_36[0][0]                \n","__________________________________________________________________________________________________\n","lambda_58 (Lambda)              (None, 64, 64, 1)    0           add_24[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_59 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_57 (Lambda)              (None, 64, 64, 1)    0           lambda_47[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_39 (Multiply)          (None, 64, 64, 1)    0           lambda_58[0][0]                  \n","                                                                 lambda_59[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_38 (Multiply)          (None, 64, 64, 1)    0           model_15[3][0]                   \n","                                                                 lambda_57[0][0]                  \n","__________________________________________________________________________________________________\n","add_25 (Add)                    (None, 64, 64, 1)    0           multiply_39[0][0]                \n","                                                                 multiply_38[0][0]                \n","__________________________________________________________________________________________________\n","lambda_61 (Lambda)              (None, 64, 64, 1)    0           add_25[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_62 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_60 (Lambda)              (None, 64, 64, 1)    0           lambda_47[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_41 (Multiply)          (None, 64, 64, 1)    0           lambda_61[0][0]                  \n","                                                                 lambda_62[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_40 (Multiply)          (None, 64, 64, 1)    0           model_15[4][0]                   \n","                                                                 lambda_60[0][0]                  \n","__________________________________________________________________________________________________\n","add_26 (Add)                    (None, 64, 64, 1)    0           multiply_41[0][0]                \n","                                                                 multiply_40[0][0]                \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_17\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_26 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_25 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_63 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","model_16 (Functional)           (None, 64, 64, 1)    6061888     input_25[0][0]                   \n","                                                                 lambda_63[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_65 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","model_15 (Functional)           (None, 64, 64, 1)    6061888     model_16[0][0]                   \n","                                                                 lambda_65[0][0]                  \n","                                                                 model_16[0][0]                   \n","                                                                 lambda_67[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_67 (Lambda)              (None, 64, 64, 1)    0           input_26[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_6 (Subtract)           (None, 64, 64, 1)    0           model_16[0][0]                   \n","                                                                 input_25[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_7 (Subtract)           (None, 64, 64, 1)    0           model_16[0][0]                   \n","                                                                 model_15[6][0]                   \n","__________________________________________________________________________________________________\n","multiply_42 (Multiply)          (None, 64, 64, 1)    0           subtract_6[0][0]                 \n","                                                                 input_26[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_44 (Multiply)          (None, 64, 64, 1)    0           subtract_7[0][0]                 \n","                                                                 input_26[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_8 (Subtract)           (None, 64, 64, 1)    0           model_15[7][0]                   \n","                                                                 model_16[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_43 (Multiply)          (None, 64, 64, 1)    0           multiply_42[0][0]                \n","                                                                 multiply_42[0][0]                \n","__________________________________________________________________________________________________\n","multiply_45 (Multiply)          (None, 64, 64, 1)    0           multiply_44[0][0]                \n","                                                                 multiply_44[0][0]                \n","__________________________________________________________________________________________________\n","multiply_46 (Multiply)          (None, 64, 64, 1)    0           subtract_8[0][0]                 \n","                                                                 input_26[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_12 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_43[0][0]                \n","__________________________________________________________________________________________________\n","reshape_14 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_45[0][0]                \n","__________________________________________________________________________________________________\n","multiply_47 (Multiply)          (None, 64, 64, 1)    0           multiply_46[0][0]                \n","                                                                 multiply_46[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling3d_6 (Glo (None, 1)            0           reshape_12[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling3d_7 (Glo (None, 1)            0           reshape_14[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_16 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_47[0][0]                \n","__________________________________________________________________________________________________\n","reshape_13 (Reshape)            (None, 1)            0           global_average_pooling3d_6[0][0] \n","__________________________________________________________________________________________________\n","reshape_15 (Reshape)            (None, 1)            0           global_average_pooling3d_7[0][0] \n","__________________________________________________________________________________________________\n","global_average_pooling3d_8 (Glo (None, 1)            0           reshape_16[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_64 (Lambda)              (None, 1)            0           reshape_13[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_66 (Lambda)              (None, 1)            0           reshape_15[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_17 (Reshape)            (None, 1)            0           global_average_pooling3d_8[0][0] \n","__________________________________________________________________________________________________\n","add_27 (Add)                    (None, 1)            0           lambda_64[0][0]                  \n","                                                                 lambda_66[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_68 (Lambda)              (None, 1)            0           reshape_17[0][0]                 \n","__________________________________________________________________________________________________\n","add_28 (Add)                    (None, 1)            0           add_27[0][0]                     \n","                                                                 lambda_68[0][0]                  \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/14\n","51/51 [==============================] - 21s 328ms/step - loss: 0.2774 - val_loss: 0.2009\n","Epoch 2/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1893 - val_loss: 0.1608\n","Epoch 3/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1589 - val_loss: 0.1533\n","Epoch 4/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1445 - val_loss: 0.1418\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1388 - val_loss: 0.1355\n","Epoch 6/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1435 - val_loss: 0.1384\n","Epoch 7/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1310 - val_loss: 0.1219\n","Epoch 8/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1216 - val_loss: 0.1205\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1195 - val_loss: 0.1145\n","Epoch 10/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1186 - val_loss: 0.1169\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1187 - val_loss: 0.1126\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1105 - val_loss: 0.1114\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1139 - val_loss: 0.1127\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1167 - val_loss: 0.1103\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:149: RuntimeWarning: invalid value encountered in double_scalars\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:105: RuntimeWarning: invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":[".......... iter 0\n",".... Error for all data (Tr)        : nan 98.49%\n",".... Error for all data (Tt)        : nan 84.58%\n","....\n",".... Error for observed data (Tr)  : nan 98.49%\n",".... Error for observed data (Tt)  : nan 97.48%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan 80.39%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 91.31%\n",".... Error for all data (Tt)     : nan 7.96%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -17.04%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 88.57%\n",".... explained variance AE (Tt)  : 88.27%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1101 - val_loss: 0.1087\n","Epoch 2/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.1076 - val_loss: 0.1190\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1105 - val_loss: 0.1062\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1058 - val_loss: 0.1082\n","Epoch 5/14\n","51/51 [==============================] - 16s 318ms/step - loss: 0.1066 - val_loss: 0.1053\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1037 - val_loss: 0.1029\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1010 - val_loss: 0.1035\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1010 - val_loss: 0.1022\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0988 - val_loss: 0.1028\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.1006 - val_loss: 0.1100\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0996 - val_loss: 0.1006\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0953 - val_loss: 0.0982\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0947 - val_loss: 0.0998\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0968 - val_loss: 0.0977\n",".......... iter 1\n",".... Error for all data (Tr)        : nan 98.94%\n",".... Error for all data (Tt)        : nan 86.06%\n","....\n",".... Error for observed data (Tr)  : nan 98.94%\n",".... Error for observed data (Tt)  : nan 98.30%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan 82.08%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 93.88%\n",".... Error for all data (Tt)     : nan 16.78%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -6.95%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 91.95%\n",".... explained variance AE (Tt)  : 91.26%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0902 - val_loss: 0.0950\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0901 - val_loss: 0.0978\n","Epoch 3/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0913 - val_loss: 0.0945\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0886 - val_loss: 0.0946\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0875 - val_loss: 0.0935\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0851 - val_loss: 0.0926\n","Epoch 7/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0855 - val_loss: 0.0933\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0856 - val_loss: 0.0921\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0843 - val_loss: 0.0920\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0847 - val_loss: 0.0952\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0801 - val_loss: 0.0896\n","Epoch 12/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0791 - val_loss: 0.0903\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0775 - val_loss: 0.0885\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0780 - val_loss: 0.0895\n",".......... iter 2\n",".... Error for all data (Tr)        : nan 99.25%\n",".... Error for all data (Tt)        : nan 78.39%\n","....\n",".... Error for observed data (Tr)  : nan 99.25%\n",".... Error for observed data (Tt)  : nan 87.13%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan 75.55%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 95.71%\n",".... Error for all data (Tt)     : nan -28.99%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -45.94%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 94.35%\n",".... explained variance AE (Tt)  : 93.21%\n","..... Update/initialize number of projections in DINCOnvAE model # 5\n","Model: \"model_18\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_27 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_28 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_69 (Lambda)              (None, 64, 64, 1)    0           input_27[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_70 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","model_15 (Functional)           (None, 64, 64, 1)    6061888     lambda_69[0][0]                  \n","                                                                 input_28[0][0]                   \n","                                                                 add_29[0][0]                     \n","                                                                 input_28[0][0]                   \n","                                                                 add_30[0][0]                     \n","                                                                 input_28[0][0]                   \n","                                                                 add_31[0][0]                     \n","                                                                 input_28[0][0]                   \n","                                                                 add_32[0][0]                     \n","                                                                 input_28[0][0]                   \n","                                                                 add_33[0][0]                     \n","                                                                 input_28[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_72 (Lambda)              (None, 64, 64, 1)    0           lambda_69[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_73 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_71 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_49 (Multiply)          (None, 64, 64, 1)    0           lambda_72[0][0]                  \n","                                                                 lambda_73[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_48 (Multiply)          (None, 64, 64, 1)    0           model_15[8][0]                   \n","                                                                 lambda_71[0][0]                  \n","__________________________________________________________________________________________________\n","add_29 (Add)                    (None, 64, 64, 1)    0           multiply_49[0][0]                \n","                                                                 multiply_48[0][0]                \n","__________________________________________________________________________________________________\n","lambda_75 (Lambda)              (None, 64, 64, 1)    0           add_29[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_76 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_74 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_51 (Multiply)          (None, 64, 64, 1)    0           lambda_75[0][0]                  \n","                                                                 lambda_76[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_50 (Multiply)          (None, 64, 64, 1)    0           model_15[9][0]                   \n","                                                                 lambda_74[0][0]                  \n","__________________________________________________________________________________________________\n","add_30 (Add)                    (None, 64, 64, 1)    0           multiply_51[0][0]                \n","                                                                 multiply_50[0][0]                \n","__________________________________________________________________________________________________\n","lambda_78 (Lambda)              (None, 64, 64, 1)    0           add_30[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_79 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_77 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_53 (Multiply)          (None, 64, 64, 1)    0           lambda_78[0][0]                  \n","                                                                 lambda_79[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_52 (Multiply)          (None, 64, 64, 1)    0           model_15[10][0]                  \n","                                                                 lambda_77[0][0]                  \n","__________________________________________________________________________________________________\n","add_31 (Add)                    (None, 64, 64, 1)    0           multiply_53[0][0]                \n","                                                                 multiply_52[0][0]                \n","__________________________________________________________________________________________________\n","lambda_81 (Lambda)              (None, 64, 64, 1)    0           add_31[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_82 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_80 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_55 (Multiply)          (None, 64, 64, 1)    0           lambda_81[0][0]                  \n","                                                                 lambda_82[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_54 (Multiply)          (None, 64, 64, 1)    0           model_15[11][0]                  \n","                                                                 lambda_80[0][0]                  \n","__________________________________________________________________________________________________\n","add_32 (Add)                    (None, 64, 64, 1)    0           multiply_55[0][0]                \n","                                                                 multiply_54[0][0]                \n","__________________________________________________________________________________________________\n","lambda_84 (Lambda)              (None, 64, 64, 1)    0           add_32[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_85 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_83 (Lambda)              (None, 64, 64, 1)    0           lambda_70[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_57 (Multiply)          (None, 64, 64, 1)    0           lambda_84[0][0]                  \n","                                                                 lambda_85[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_56 (Multiply)          (None, 64, 64, 1)    0           model_15[12][0]                  \n","                                                                 lambda_83[0][0]                  \n","__________________________________________________________________________________________________\n","add_33 (Add)                    (None, 64, 64, 1)    0           multiply_57[0][0]                \n","                                                                 multiply_56[0][0]                \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_19\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_28 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_27 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_86 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","model_18 (Functional)           (None, 64, 64, 1)    6061888     input_27[0][0]                   \n","                                                                 lambda_86[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_88 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","model_15 (Functional)           (None, 64, 64, 1)    6061888     model_18[0][0]                   \n","                                                                 lambda_88[0][0]                  \n","                                                                 model_18[0][0]                   \n","                                                                 lambda_90[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_90 (Lambda)              (None, 64, 64, 1)    0           input_28[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_9 (Subtract)           (None, 64, 64, 1)    0           model_18[0][0]                   \n","                                                                 input_27[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_10 (Subtract)          (None, 64, 64, 1)    0           model_18[0][0]                   \n","                                                                 model_15[14][0]                  \n","__________________________________________________________________________________________________\n","multiply_58 (Multiply)          (None, 64, 64, 1)    0           subtract_9[0][0]                 \n","                                                                 input_28[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_60 (Multiply)          (None, 64, 64, 1)    0           subtract_10[0][0]                \n","                                                                 input_28[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_11 (Subtract)          (None, 64, 64, 1)    0           model_15[15][0]                  \n","                                                                 model_18[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_59 (Multiply)          (None, 64, 64, 1)    0           multiply_58[0][0]                \n","                                                                 multiply_58[0][0]                \n","__________________________________________________________________________________________________\n","multiply_61 (Multiply)          (None, 64, 64, 1)    0           multiply_60[0][0]                \n","                                                                 multiply_60[0][0]                \n","__________________________________________________________________________________________________\n","multiply_62 (Multiply)          (None, 64, 64, 1)    0           subtract_11[0][0]                \n","                                                                 input_28[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_18 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_59[0][0]                \n","__________________________________________________________________________________________________\n","reshape_20 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_61[0][0]                \n","__________________________________________________________________________________________________\n","multiply_63 (Multiply)          (None, 64, 64, 1)    0           multiply_62[0][0]                \n","                                                                 multiply_62[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling3d_9 (Glo (None, 1)            0           reshape_18[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling3d_10 (Gl (None, 1)            0           reshape_20[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_22 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_63[0][0]                \n","__________________________________________________________________________________________________\n","reshape_19 (Reshape)            (None, 1)            0           global_average_pooling3d_9[0][0] \n","__________________________________________________________________________________________________\n","reshape_21 (Reshape)            (None, 1)            0           global_average_pooling3d_10[0][0]\n","__________________________________________________________________________________________________\n","global_average_pooling3d_11 (Gl (None, 1)            0           reshape_22[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_87 (Lambda)              (None, 1)            0           reshape_19[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_89 (Lambda)              (None, 1)            0           reshape_21[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_23 (Reshape)            (None, 1)            0           global_average_pooling3d_11[0][0]\n","__________________________________________________________________________________________________\n","add_34 (Add)                    (None, 1)            0           lambda_87[0][0]                  \n","                                                                 lambda_89[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_91 (Lambda)              (None, 1)            0           reshape_23[0][0]                 \n","__________________________________________________________________________________________________\n","add_35 (Add)                    (None, 1)            0           add_34[0][0]                     \n","                                                                 lambda_91[0][0]                  \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/14\n","51/51 [==============================] - 21s 328ms/step - loss: 0.0703 - val_loss: 0.0829\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0672 - val_loss: 0.0821\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0654 - val_loss: 0.0820\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0637 - val_loss: 0.0815\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0649 - val_loss: 0.0810\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0635 - val_loss: 0.0810\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0625 - val_loss: 0.0807\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0623 - val_loss: 0.0804\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0627 - val_loss: 0.0803\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0622 - val_loss: 0.0801\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0617 - val_loss: 0.0799\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0605 - val_loss: 0.0804\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0607 - val_loss: 0.0798\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0609 - val_loss: 0.0795\n",".......... iter 3\n",".... Error for all data (Tr)        : nan 99.47%\n",".... Error for all data (Tt)        : nan 35.72%\n","....\n",".... Error for observed data (Tr)  : nan 99.47%\n",".... Error for observed data (Tt)  : nan 32.44%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan 36.79%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 96.98%\n",".... Error for all data (Tt)     : nan -283.67%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -277.31%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 96.02%\n",".... explained variance AE (Tt)  : 94.68%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0597 - val_loss: 0.0795\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0593 - val_loss: 0.0794\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0588 - val_loss: 0.0794\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0587 - val_loss: 0.0790\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0581 - val_loss: 0.0789\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0577 - val_loss: 0.0789\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0576 - val_loss: 0.0787\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0570 - val_loss: 0.0787\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0566 - val_loss: 0.0783\n","Epoch 10/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0562 - val_loss: 0.0782\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0561 - val_loss: 0.0782\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0556 - val_loss: 0.0782\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0555 - val_loss: 0.0780\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0549 - val_loss: 0.0780\n",".......... iter 4\n",".... Error for all data (Tr)        : nan 99.54%\n",".... Error for all data (Tt)        : nan -66.55%\n","....\n",".... Error for observed data (Tr)  : nan 99.54%\n",".... Error for observed data (Tt)  : nan -108.33%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -52.98%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 97.33%\n",".... Error for all data (Tt)     : nan -894.12%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -813.11%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 96.49%\n",".... explained variance AE (Tt)  : 95.03%\n","Epoch 1/14\n","51/51 [==============================] - 16s 320ms/step - loss: 0.0546 - val_loss: 0.0779\n","Epoch 2/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0542 - val_loss: 0.0778\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0539 - val_loss: 0.0780\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0536 - val_loss: 0.0775\n","Epoch 5/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0530 - val_loss: 0.0774\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0527 - val_loss: 0.0771\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0525 - val_loss: 0.0774\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0523 - val_loss: 0.0773\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0521 - val_loss: 0.0770\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0518 - val_loss: 0.0772\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0513 - val_loss: 0.0769\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0513 - val_loss: 0.0772\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0508 - val_loss: 0.0766\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0504 - val_loss: 0.0764\n",".......... iter 5\n",".... Error for all data (Tr)        : nan 99.59%\n",".... Error for all data (Tt)        : nan -104.60%\n","....\n",".... Error for observed data (Tr)  : nan 99.59%\n",".... Error for observed data (Tt)  : nan -168.04%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -84.00%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 97.64%\n",".... Error for all data (Tt)     : nan -1121.27%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -998.29%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 96.89%\n",".... explained variance AE (Tt)  : 95.29%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0501 - val_loss: 0.0763\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0498 - val_loss: 0.0762\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0495 - val_loss: 0.0763\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0493 - val_loss: 0.0761\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0489 - val_loss: 0.0761\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0486 - val_loss: 0.0760\n","Epoch 7/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0483 - val_loss: 0.0767\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0480 - val_loss: 0.0759\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0479 - val_loss: 0.0758\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0475 - val_loss: 0.0757\n","Epoch 11/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0473 - val_loss: 0.0755\n","Epoch 12/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0471 - val_loss: 0.0759\n","Epoch 13/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0476 - val_loss: 0.0757\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0467 - val_loss: 0.0757\n",".......... iter 6\n",".... Error for all data (Tr)        : nan 99.63%\n",".... Error for all data (Tt)        : nan -166.53%\n","....\n",".... Error for observed data (Tr)  : nan 99.63%\n",".... Error for observed data (Tt)  : nan -250.98%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -139.11%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 97.88%\n",".... Error for all data (Tt)     : nan -1490.94%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -1327.24%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.21%\n",".... explained variance AE (Tt)  : 95.50%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0465 - val_loss: 0.0754\n","Epoch 2/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0458 - val_loss: 0.0752\n","Epoch 3/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0458 - val_loss: 0.0753\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0457 - val_loss: 0.0753\n","Epoch 5/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0454 - val_loss: 0.0755\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0455 - val_loss: 0.0754\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0447 - val_loss: 0.0750\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0444 - val_loss: 0.0751\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0443 - val_loss: 0.0750\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0440 - val_loss: 0.0750\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0438 - val_loss: 0.0748\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0435 - val_loss: 0.0750\n","Epoch 13/14\n","51/51 [==============================] - 16s 319ms/step - loss: 0.0438 - val_loss: 0.0751\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0433 - val_loss: 0.0746\n",".......... iter 7\n",".... Error for all data (Tr)        : nan 99.66%\n",".... Error for all data (Tt)        : nan -365.13%\n","....\n",".... Error for observed data (Tr)  : nan 99.66%\n",".... Error for observed data (Tt)  : nan -504.34%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -319.92%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.06%\n",".... Error for all data (Tt)     : nan -2676.39%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -2406.53%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.45%\n",".... explained variance AE (Tt)  : 95.64%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0435 - val_loss: 0.0752\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0429 - val_loss: 0.0745\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0426 - val_loss: 0.0747\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0425 - val_loss: 0.0746\n","Epoch 5/14\n","51/51 [==============================] - 16s 314ms/step - loss: 0.0421 - val_loss: 0.0745\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0421 - val_loss: 0.0745\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0420 - val_loss: 0.0745\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0417 - val_loss: 0.0743\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0416 - val_loss: 0.0744\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0411 - val_loss: 0.0741\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0411 - val_loss: 0.0740\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0408 - val_loss: 0.0741\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0409 - val_loss: 0.0748\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0408 - val_loss: 0.0742\n",".......... iter 8\n",".... Error for all data (Tr)        : nan 99.69%\n",".... Error for all data (Tt)        : nan -365.12%\n","....\n",".... Error for observed data (Tr)  : nan 99.69%\n",".... Error for observed data (Tt)  : nan -545.09%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -306.67%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.24%\n",".... Error for all data (Tt)     : nan -2676.32%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -2327.44%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.68%\n",".... explained variance AE (Tt)  : 95.79%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0405 - val_loss: 0.0740\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0402 - val_loss: 0.0740\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0401 - val_loss: 0.0740\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0405 - val_loss: 0.0742\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0396 - val_loss: 0.0739\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0394 - val_loss: 0.0738\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0394 - val_loss: 0.0742\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0392 - val_loss: 0.0742\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0389 - val_loss: 0.0742\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0398 - val_loss: 0.0747\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0392 - val_loss: 0.0740\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0389 - val_loss: 0.0742\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0382 - val_loss: 0.0736\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0382 - val_loss: 0.0738\n",".......... iter 9\n",".... Error for all data (Tr)        : nan 99.71%\n",".... Error for all data (Tt)        : nan -458.38%\n","....\n",".... Error for observed data (Tr)  : nan 99.71%\n",".... Error for observed data (Tt)  : nan -656.01%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -394.20%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.35%\n",".... Error for all data (Tt)     : nan -3232.99%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -2849.88%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.82%\n",".... explained variance AE (Tt)  : 95.85%\n","..... Update/initialize number of projections in DINCOnvAE model # 5\n","Model: \"model_20\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_29 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_30 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_92 (Lambda)              (None, 64, 64, 1)    0           input_29[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_93 (Lambda)              (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","model_15 (Functional)           (None, 64, 64, 1)    6061888     lambda_92[0][0]                  \n","                                                                 input_30[0][0]                   \n","                                                                 add_36[0][0]                     \n","                                                                 input_30[0][0]                   \n","                                                                 add_37[0][0]                     \n","                                                                 input_30[0][0]                   \n","                                                                 add_38[0][0]                     \n","                                                                 input_30[0][0]                   \n","                                                                 add_39[0][0]                     \n","                                                                 input_30[0][0]                   \n","                                                                 add_40[0][0]                     \n","                                                                 input_30[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_95 (Lambda)              (None, 64, 64, 1)    0           lambda_92[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_96 (Lambda)              (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_94 (Lambda)              (None, 64, 64, 1)    0           lambda_93[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_65 (Multiply)          (None, 64, 64, 1)    0           lambda_95[0][0]                  \n","                                                                 lambda_96[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_64 (Multiply)          (None, 64, 64, 1)    0           model_15[16][0]                  \n","                                                                 lambda_94[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 64, 64, 1)    0           multiply_65[0][0]                \n","                                                                 multiply_64[0][0]                \n","__________________________________________________________________________________________________\n","lambda_98 (Lambda)              (None, 64, 64, 1)    0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_99 (Lambda)              (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_97 (Lambda)              (None, 64, 64, 1)    0           lambda_93[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_67 (Multiply)          (None, 64, 64, 1)    0           lambda_98[0][0]                  \n","                                                                 lambda_99[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_66 (Multiply)          (None, 64, 64, 1)    0           model_15[17][0]                  \n","                                                                 lambda_97[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 64, 64, 1)    0           multiply_67[0][0]                \n","                                                                 multiply_66[0][0]                \n","__________________________________________________________________________________________________\n","lambda_101 (Lambda)             (None, 64, 64, 1)    0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_102 (Lambda)             (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_100 (Lambda)             (None, 64, 64, 1)    0           lambda_93[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_69 (Multiply)          (None, 64, 64, 1)    0           lambda_101[0][0]                 \n","                                                                 lambda_102[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_68 (Multiply)          (None, 64, 64, 1)    0           model_15[18][0]                  \n","                                                                 lambda_100[0][0]                 \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 64, 64, 1)    0           multiply_69[0][0]                \n","                                                                 multiply_68[0][0]                \n","__________________________________________________________________________________________________\n","lambda_104 (Lambda)             (None, 64, 64, 1)    0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_105 (Lambda)             (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_103 (Lambda)             (None, 64, 64, 1)    0           lambda_93[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_71 (Multiply)          (None, 64, 64, 1)    0           lambda_104[0][0]                 \n","                                                                 lambda_105[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_70 (Multiply)          (None, 64, 64, 1)    0           model_15[19][0]                  \n","                                                                 lambda_103[0][0]                 \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 64, 64, 1)    0           multiply_71[0][0]                \n","                                                                 multiply_70[0][0]                \n","__________________________________________________________________________________________________\n","lambda_107 (Lambda)             (None, 64, 64, 1)    0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_108 (Lambda)             (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_106 (Lambda)             (None, 64, 64, 1)    0           lambda_93[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_73 (Multiply)          (None, 64, 64, 1)    0           lambda_107[0][0]                 \n","                                                                 lambda_108[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_72 (Multiply)          (None, 64, 64, 1)    0           model_15[20][0]                  \n","                                                                 lambda_106[0][0]                 \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 64, 64, 1)    0           multiply_73[0][0]                \n","                                                                 multiply_72[0][0]                \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"model_21\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_30 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","input_29 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","lambda_109 (Lambda)             (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","model_20 (Functional)           (None, 64, 64, 1)    6061888     input_29[0][0]                   \n","                                                                 lambda_109[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_111 (Lambda)             (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","model_15 (Functional)           (None, 64, 64, 1)    6061888     model_20[0][0]                   \n","                                                                 lambda_111[0][0]                 \n","                                                                 model_20[0][0]                   \n","                                                                 lambda_113[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_113 (Lambda)             (None, 64, 64, 1)    0           input_30[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_12 (Subtract)          (None, 64, 64, 1)    0           model_20[0][0]                   \n","                                                                 input_29[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_13 (Subtract)          (None, 64, 64, 1)    0           model_20[0][0]                   \n","                                                                 model_15[22][0]                  \n","__________________________________________________________________________________________________\n","multiply_74 (Multiply)          (None, 64, 64, 1)    0           subtract_12[0][0]                \n","                                                                 input_30[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_76 (Multiply)          (None, 64, 64, 1)    0           subtract_13[0][0]                \n","                                                                 input_30[0][0]                   \n","__________________________________________________________________________________________________\n","subtract_14 (Subtract)          (None, 64, 64, 1)    0           model_15[23][0]                  \n","                                                                 model_20[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_75 (Multiply)          (None, 64, 64, 1)    0           multiply_74[0][0]                \n","                                                                 multiply_74[0][0]                \n","__________________________________________________________________________________________________\n","multiply_77 (Multiply)          (None, 64, 64, 1)    0           multiply_76[0][0]                \n","                                                                 multiply_76[0][0]                \n","__________________________________________________________________________________________________\n","multiply_78 (Multiply)          (None, 64, 64, 1)    0           subtract_14[0][0]                \n","                                                                 input_30[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_24 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_75[0][0]                \n","__________________________________________________________________________________________________\n","reshape_26 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_77[0][0]                \n","__________________________________________________________________________________________________\n","multiply_79 (Multiply)          (None, 64, 64, 1)    0           multiply_78[0][0]                \n","                                                                 multiply_78[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling3d_12 (Gl (None, 1)            0           reshape_24[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling3d_13 (Gl (None, 1)            0           reshape_26[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_28 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_79[0][0]                \n","__________________________________________________________________________________________________\n","reshape_25 (Reshape)            (None, 1)            0           global_average_pooling3d_12[0][0]\n","__________________________________________________________________________________________________\n","reshape_27 (Reshape)            (None, 1)            0           global_average_pooling3d_13[0][0]\n","__________________________________________________________________________________________________\n","global_average_pooling3d_14 (Gl (None, 1)            0           reshape_28[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_110 (Lambda)             (None, 1)            0           reshape_25[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_112 (Lambda)             (None, 1)            0           reshape_27[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_29 (Reshape)            (None, 1)            0           global_average_pooling3d_14[0][0]\n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 1)            0           lambda_110[0][0]                 \n","                                                                 lambda_112[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_114 (Lambda)             (None, 1)            0           reshape_29[0][0]                 \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 1)            0           add_41[0][0]                     \n","                                                                 lambda_114[0][0]                 \n","==================================================================================================\n","Total params: 6,061,888\n","Trainable params: 6,061,888\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/14\n","51/51 [==============================] - 21s 328ms/step - loss: 0.0361 - val_loss: 0.0733\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0359 - val_loss: 0.0733\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0356 - val_loss: 0.0732\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0353 - val_loss: 0.0733\n","Epoch 5/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0352 - val_loss: 0.0733\n","Epoch 6/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0353 - val_loss: 0.0733\n","Epoch 7/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0356 - val_loss: 0.0733\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0347 - val_loss: 0.0733\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0350 - val_loss: 0.0733\n","Epoch 10/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0352 - val_loss: 0.0733\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0344 - val_loss: 0.0733\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0350 - val_loss: 0.0733\n","Epoch 13/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0349 - val_loss: 0.0734\n","Epoch 14/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0351 - val_loss: 0.0733\n",".......... iter 10\n",".... Error for all data (Tr)        : nan 99.72%\n",".... Error for all data (Tt)        : nan -433.76%\n","....\n",".... Error for observed data (Tr)  : nan 99.72%\n",".... Error for observed data (Tt)  : nan -622.47%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -372.47%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.41%\n",".... Error for all data (Tt)     : nan -3086.03%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -2720.20%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.91%\n",".... explained variance AE (Tt)  : 95.90%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0349 - val_loss: 0.0733\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0349 - val_loss: 0.0733\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0349 - val_loss: 0.0733\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0348 - val_loss: 0.0733\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0348 - val_loss: 0.0733\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0348 - val_loss: 0.0733\n","Epoch 7/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0347 - val_loss: 0.0733\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0347 - val_loss: 0.0733\n","Epoch 9/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0346 - val_loss: 0.0733\n","Epoch 10/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0346 - val_loss: 0.0734\n","Epoch 11/14\n","51/51 [==============================] - 16s 317ms/step - loss: 0.0346 - val_loss: 0.0733\n","Epoch 12/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0346 - val_loss: 0.0733\n","Epoch 13/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0345 - val_loss: 0.0733\n","Epoch 14/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0345 - val_loss: 0.0733\n",".......... iter 11\n",".... Error for all data (Tr)        : nan 99.73%\n",".... Error for all data (Tt)        : nan -458.30%\n","....\n",".... Error for observed data (Tr)  : nan 99.73%\n",".... Error for observed data (Tt)  : nan -648.82%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -396.42%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.43%\n",".... Error for all data (Tt)     : nan -3232.47%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -2863.14%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.93%\n",".... explained variance AE (Tt)  : 95.91%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0345 - val_loss: 0.0733\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0344 - val_loss: 0.0733\n","Epoch 3/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0344 - val_loss: 0.0733\n","Epoch 4/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0344 - val_loss: 0.0733\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0344 - val_loss: 0.0733\n","Epoch 6/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0343 - val_loss: 0.0733\n","Epoch 7/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0343 - val_loss: 0.0733\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0343 - val_loss: 0.0734\n","Epoch 9/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0342 - val_loss: 0.0733\n","Epoch 10/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0342 - val_loss: 0.0734\n","Epoch 11/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0342 - val_loss: 0.0734\n","Epoch 12/14\n","51/51 [==============================] - 16s 319ms/step - loss: 0.0342 - val_loss: 0.0734\n","Epoch 13/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0341 - val_loss: 0.0733\n","Epoch 14/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0341 - val_loss: 0.0733\n",".......... iter 12\n",".... Error for all data (Tr)        : nan 99.73%\n",".... Error for all data (Tt)        : nan -474.15%\n","....\n",".... Error for observed data (Tr)  : nan 99.73%\n",".... Error for observed data (Tt)  : nan -660.79%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -413.54%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.44%\n",".... Error for all data (Tt)     : nan -3327.12%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -2965.32%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.95%\n",".... explained variance AE (Tt)  : 95.91%\n","Epoch 1/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0341 - val_loss: 0.0734\n","Epoch 2/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0340 - val_loss: 0.0733\n","Epoch 3/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0340 - val_loss: 0.0733\n","Epoch 4/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0340 - val_loss: 0.0733\n","Epoch 5/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0340 - val_loss: 0.0734\n","Epoch 6/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0339 - val_loss: 0.0734\n","Epoch 7/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0339 - val_loss: 0.0734\n","Epoch 8/14\n","51/51 [==============================] - 16s 315ms/step - loss: 0.0339 - val_loss: 0.0733\n","Epoch 9/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0338 - val_loss: 0.0734\n","Epoch 10/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0338 - val_loss: 0.0733\n","Epoch 11/14\n","51/51 [==============================] - 16s 317ms/step - loss: 0.0338 - val_loss: 0.0734\n","Epoch 12/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0338 - val_loss: 0.0733\n","Epoch 13/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0337 - val_loss: 0.0734\n","Epoch 14/14\n","51/51 [==============================] - 16s 316ms/step - loss: 0.0337 - val_loss: 0.0733\n",".......... iter 13\n",".... Error for all data (Tr)        : nan 99.73%\n",".... Error for all data (Tt)        : nan -513.88%\n","....\n",".... Error for observed data (Tr)  : nan 99.73%\n",".... Error for observed data (Tt)  : nan -708.28%\n","....\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -450.74%\n",".... Performance for \"center\" image\n",".... Image center variance (Tr)  : 0.17\n",".... Image center variance (Tt)  : 0.17\n",".... Error for all data (Tr)     : nan 98.46%\n",".... Error for all data (Tt)     : nan -3564.23%\n",".... Error for masked data (Tr)  : nan nan%\n",".... Error for masked data (Tt)  : nan -3187.37%\n","   \n",".......... Auto-encoder performance when applied to gap-free data\n",".... explained variance AE (Tr)  : 97.97%\n",".... explained variance AE (Tt)  : 95.92%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nYGiJA8lvpZ-"},"source":["### PrÃ©diction / Interpolation "]},{"cell_type":"code","metadata":{"id":"Kl3eUXPVvpZ_","executionInfo":{"status":"aborted","timestamp":1608306393347,"user_tz":-60,"elapsed":2929,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["Pred_GM = global_model_FP.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n","Pred_AE = model_AE.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n","\n","#.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gdJ9AVuvpaD","executionInfo":{"status":"aborted","timestamp":1608306393348,"user_tz":-60,"elapsed":2851,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}}},"source":["#gt_pred_norm = stdsc.inverse_transform(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)))\n","#Pred_AE_norm = np.full(gt_pred.shape,np.nan)\n","#Pred_GM_norm = np.full(gt_pred.shape,np.nan)\n","#Pred_AE_norm[np.where(~np.isnan(gt_pred))] = stdsc.inverse_transform(Pred_AE.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[np.where(~np.isnan(gt_pred))].reshape(len(Pred_AE),-1)).ravel() \n","#Pred_GM_norm[np.where(~np.isnan(gt_pred))] = stdsc.inverse_transform(Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[np.where(~np.isnan(gt_pred))].reshape(len(Pred_GM),-1)).ravel()\n","#Pred_AE_norm = Pred_AE_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O46naj1sfJ9m"},"source":["Pred_AE_norm = stdsc.inverse_transform(Pred_AE.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = stdsc.inverse_transform(Pred_GM.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fZum6PJXi25"},"source":["Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+medabs) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+medabs).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEF-7BCz6n9M"},"source":["Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+mean_Tr) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","\n","#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n","#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqM26-Gjuw3y"},"source":["Pred_AE_norm[np.where(Pred_AE_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n","Pred_GM_norm[np.where(Pred_GM_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n","Pred_AE_norm[np.where(Pred_AE_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n","Pred_GM_norm[np.where(Pred_GM_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDg6dGDgu8Ip"},"source":["Pred_AE_norm=Pred_AE_norm+0.5\n","Pred_GM_norm=Pred_GM_norm+0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pAqH_TH7pjLR","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"ok","timestamp":1608141343112,"user_tz":-60,"elapsed":2190,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"805bea52-bc5e-4c14-e6e9-d1a758731b6f"},"source":["i=0\n","plt.subplot(221)\n","plt.imshow(Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n","plt.colorbar()\n","plt.subplot(222)\n","plt.imshow(Pred_GM_norm.reshape(Pred_GM_norm.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[50])\n","plt.colorbar()\n","\n","print(np.nanmax(Pred_GM_norm),np.nanmax(Pred_AE_norm),np.nanmax(gt_pred))\n","print(np.nanmin(Pred_GM_norm),np.nanmin(Pred_AE_norm),np.nanmin(gt_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-1.3431797349452972 -1.331961008310318 -0.5334281921386719\n","-4.156152880191803 -4.1889735603332525 -4.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"i_MDhszraM69","colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"status":"ok","timestamp":1607708641488,"user_tz":-60,"elapsed":623,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"a0144e28-c831-4e4d-da6e-c12035bc2486"},"source":["print(gt_pred.shape)\n","plt.imshow(Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[5]-Pred_GM.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n","plt.colorbar()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(100, 64, 64)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.colorbar.Colorbar at 0x7f2deb431860>"]},"metadata":{"tags":[]},"execution_count":121},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ObIf6haKOSsX"},"source":["# Some metrics\n"]},{"cell_type":"code","metadata":{"id":"lP9Syz_KvpaH","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1607078418056,"user_tz":-60,"elapsed":533,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"19fad17a-8928-49e9-fbe8-ff4c0ee4fe1d"},"source":["'''if flagPred :\n","  Pred_GM_norm = Pred_GM_norm[len(mask_pred)//2:]\n","  Pred_AE_norm = Pred_AE_norm[len(mask_pred)//2:]\n","  gt_pred      = gt_pred[len(mask_pred)//2:]\n","'''"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-845a08e14edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mPred_GM_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_GM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mPred_AE_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPred_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgt_pred_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.         0.         0.         ... 1.4135437  1.43219256 1.42513895].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DbOIMlSGURRi","executionInfo":{"status":"ok","timestamp":1608141343115,"user_tz":-60,"elapsed":2185,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"dbac2f52-41a8-48d8-ffa3-8138498a0bdb"},"source":["#from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","import numpy as np\n","from sklearn.metrics import explained_variance_score\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import max_error\n","from sklearn.metrics import median_absolute_error\n","import datetime as dt\n","import matplotlib.pyplot as plt\n","\n","def mean_absolute_percentage_error(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.nanmean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","def RMSE(a,b):\n","    \"\"\" Compute the Root Mean Square Error between 2 n-dimensional vectors. \"\"\" \n","    return np.sqrt(np.nanmean((a-b)**2))\n","\n","\n","def Getmetrics(Target,Pred):\n","    Target_value = Target.reshape(Target.shape)[np.where(~np.isnan(Target))]\n","    Pred_value   = Pred.reshape(Target.shape)[np.where(~np.isnan(Target))]\n","    Target_flat  = Target_value.flatten()\n","    Pred_flat    = Pred_value.flatten()\n","    Metrics=dict()\n","\n","    return {'EVS':explained_variance_score(Target_flat,Pred_flat),'RMSE':RMSE(Target_flat,Pred_flat),'NRMSE':RMSE(Target_flat,Pred_flat)/np.nanmean(Target_flat),'MAbsEr%':mean_absolute_percentage_error(Target_flat,Pred_flat),'MaxEr':max_error(Target_flat,Pred_flat),'MAbsEr':median_absolute_error(Target_flat,Pred_flat),'RÂ²':r2_score(Target_flat,Pred_flat)}\n","\n","   #lissage donnÃ©e entrÃ©e flatn + nan\n","#Metric=Getmetrics(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)),Pred_GM )\n","#testAE=np.copy(Pred_AE_norm)\n","#testAE[np.where(testAE<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n","#print(np.nanmin(testAE))\n","MetricGM=Getmetrics(gt_pred,Pred_GM_norm)\n","MetricAE=Getmetrics(gt_pred,Pred_AE_norm)\n","print(MetricGM,MetricAE)\n","#print(Getmetrics(gt_pred,testAE),Getmetrics(gt_pred,Pred_AE_norm))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'EVS': 0.896555103660371, 'RMSE': 0.18317086100904728, 'NRMSE': -0.04919976123864717, 'MAbsEr%': 2.768348917303303, 'MaxEr': 1.7751472282409666, 'MAbsEr': 2.4599881726317108e-05, 'RÂ²': 0.8955063570755378} {'EVS': 0.9221762088239761, 'RMSE': 0.15898250251527293, 'NRMSE': -0.042702759171327515, 'MAbsEr%': 2.2438005817701008, 'MaxEr': 1.755337505340576, 'MAbsEr': 2.322977888979949e-05, 'RÂ²': 0.9212816913747315}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pApRZBrQhQR6","executionInfo":{"status":"ok","timestamp":1608141343480,"user_tz":-60,"elapsed":2544,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"84308e17-3f5d-4617-bea5-b652ee448c6f"},"source":["global_model_FP.save(\"/content/drive/MyDrive/model1.h5\")\n","model_AE.save(\"/content/drive/MyDrive/model2.h5\")\n","print(\"Saved model to disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Unvvl9mB2Bm"},"source":["np.save('/content/drive/MyDrive/Pred_AE_normbestRMSE',testAE)\n","np.save('/content/drive/MyDrive/Pred_GM_norm2',Pred_GM_norm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8Hhd6tSXCt8"},"source":["Pred=np.load"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gq06kb4Pjoe_","executionInfo":{"status":"ok","timestamp":1606998221352,"user_tz":-60,"elapsed":19028,"user":{"displayName":"Jean-Marie VIENT","photoUrl":"","userId":"16174505464901920949"}},"outputId":"0694721c-e7de-48d0-ae0a-347e9beb316d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]}]}