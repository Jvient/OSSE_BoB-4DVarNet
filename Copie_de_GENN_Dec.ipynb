{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copie de GENN-Dec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jvient/OSSE_BoB-4DVarNet/blob/main/Copie_de_GENN_Dec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNHzBS8nvpZB"
      },
      "source": [
        "# Init "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5iO50AvvpZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e79a2c1-7446-4703-d4c9-d573d4ee63b6"
      },
      "source": [
        "#Import data \n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "from random import randrange\n",
        "import sklearn\n",
        "from sklearn import decomposition\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse import diags\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.ndimage.morphology import distance_transform_edt as bwdist\n",
        "import scipy.ndimage as nd\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import scipy.stats as ss \n",
        "from keras.constraints import Constraint\n",
        "from keras import backend as K\n",
        "from datetime import date, datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 427707905535309961\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14509932544\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12360450352194424782\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg2QP-hPvpZM"
      },
      "source": [
        "# Parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EB_5VAtvpZP"
      },
      "source": [
        "DirSAVE                     = '/'\n",
        "flagTrWMissingData          = 1  # Training phase with or without missing data\n",
        "flagloadOIData              = 0    # load OI: work on rough variable or anomaly\n",
        "lname_cov                   = [\"ssh_mod\"]\n",
        "lid_cov                     = [\"OI\"]\n",
        "size_tw                     = 1   # Length of the 4th dimension          \n",
        "Wsquare                     = 4     # half-width of holes\n",
        "Nsquare                     = 3     # number of holes\n",
        "DimAE                       = 20  # Dimension of the latent space\n",
        "flagLoadModel               = 0     # load pre-defined AE model or not\n",
        "sigNoise                    = 1e-1\n",
        "flagTrOuputWOMissingData    = 1\n",
        "stdMask                     = 0.\n",
        "dropout                     = 0 #[0.6,0.7,0.8]0.03\n",
        "wl2                         = 0.0000\n",
        "batch_size                  = 16# monter un peu \n",
        "NbEpoc                      = 6\n",
        "Niter                       = 6*3\n",
        "thrMisData                  = 0\n",
        "N_cov                       = 0\n",
        "flagUseMaskinEncoder        = 1\n",
        "\n",
        "def createGlobParams(params):\n",
        "    return dict(((k, eval(k)) for k in params))\n",
        "list_globParams=[\n",
        "    'flagTrOuputWOMissingData','flagTrWMissingData',\\\n",
        "    'flagloadOIData','size_tw','Wsquare',\\\n",
        "    'Nsquare','DimAE','flagLoadModel',\\\n",
        "    'sigNoise',\\\n",
        "    'stdMask',\\\n",
        "    'dropout','wl2','batch_size',\\\n",
        "    'NbEpoc','Niter','DirSAVE','N_cov']\n",
        "globParams = createGlobParams(list_globParams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ovPNEb-vpZV"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTnPawODvpZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf55ba6-241b-4da6-e036-a050c22a19b7"
      },
      "source": [
        "dataset= np.load(\"/content/drive/My Drive/DATA/TheÌ€se/ZOI/Dataset_64_ZOI.npy\",allow_pickle='TRUE').item()\n",
        "dataH=dataset['CSED_Hourly']\n",
        "mask=dataset['Cloud_Daily']\n",
        "lat_grid=dataset['Lat_ZOI']\n",
        "lon_grid=dataset['Lon_ZOI']\n",
        "#corr lalpaciens var exp des norm\n",
        "# =============================================================================\n",
        "# Creation of the test and training dataset\n",
        "# =============================================================================\n",
        "def prepdata(xH,mask,N_Catalog=0):\n",
        "    if N_Catalog!=0:\n",
        "        test=np.zeros(mask[-365:].shape)\n",
        "        for i in range(0,len(test)):\n",
        "            test[i]=xH[26304+i*24+12].reshape(test.shape[1],test.shape[2])\n",
        "\n",
        "        train=np.zeros((N_Catalog*365,xH.shape[1],xH.shape[2]))\n",
        "\n",
        "        for i in range(N_Catalog):\n",
        "            for j in range(len(test)):\n",
        "                h=randrange(0,24)\n",
        "                train[i*365+j]=xH[i*365+j*24+h]\n",
        "    else:\n",
        "        xD=np.empty((xH.shape[0]//24,xH.shape[1],xH.shape[2]))\n",
        "        for i in range(len(xD)):\n",
        "            xD[i]=xH[12+i*24]\n",
        "    mask_train = mask[:-360]\n",
        "    mask_pred  = mask[-360:]\n",
        "    x_train    = xD[:len(mask_train)]\n",
        "    #y_pred     = xD[len(mask_train)-100:len(mask_train)]\n",
        "    y_pred     = xD[len(mask_train):len(mask_train)+len(mask_pred)]\n",
        "    return mask_train,mask_pred,x_train,y_pred\n",
        "\n",
        "\n",
        "mask[np.where(mask==0)]=1;mask[np.where(np.isnan(mask))]=0 # O for missing data\n",
        "mask_train,mask_pred,x_train,y_pred = prepdata(dataH,mask)\n",
        "\n",
        "x_train,x_test,mask_train,mask_test=sklearn.model_selection.train_test_split(x_train,mask_train,test_size=0.33)\n",
        "# list of test dates\n",
        "indN_Tt = np.arange(len(x_train),len(x_train)+len(x_test))\n",
        "indN_Tr = np.arange(len(x_train))\n",
        "lday_test=[ datetime.strftime(datetime.strptime(\"2001-1-01\",'%Y-%m-%d')\\\n",
        "                      + timedelta(days=np.float64(i)),\"%Y-%m-%d\") for i in indN_Tt ]\n",
        "indLat     = np.arange(0,64)\n",
        "indLon     = np.arange(0,64)      \n",
        "print(indLat.shape,indLon.shape,indN_Tr.shape,indN_Tt.shape)\n",
        "print(x_train.shape,x_test.shape,y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64,) (64,) (720,) (356,)\n",
            "(720, 64, 64) (356, 64, 64) (360, 64, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa-gXMCZvpZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ea4f72-e3af-4ba4-cc08-4a08005e536a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(mask_pred[7].reshape(64,64))\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fe6a188a1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1WOy6QyvpZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b970a08f-9197-4586-fa6e-8cc62d23ff71"
      },
      "source": [
        "gt_train= x_train\n",
        "gt_test = x_test\n",
        "gt_pred = np.copy(y_pred)\n",
        "err_train = np.random.normal(0,thrMisData*np.nanvar(x_train),(x_train.shape))\n",
        "err_test = np.random.normal(0,thrMisData*np.nanvar(x_test),(x_test.shape))\n",
        "err_pred = np.random.normal(0,thrMisData*np.nanvar(y_pred),(y_pred.shape))\n",
        "\n",
        "stdsc=sklearn.preprocessing.StandardScaler()\n",
        "stdsc.fit(y_pred.reshape(y_pred.shape[0],-1))\n",
        "mean_Tr = stdsc.mean_\n",
        "medabs  = np.copy(mean_Tr)\n",
        "med     = np.copy(mean_Tr)\n",
        "\n",
        "for i in range(len(medabs)):\n",
        "  med[i]    =np.nanmedian(gt_train.reshape(gt_train.shape[0],-1)[:,i])\n",
        "  medabs[i] =np.nanmedian(np.absolute(gt_train.reshape(gt_train.shape[0],-1)[:,i]-med[i]))\n",
        "  \n",
        "\n",
        "print('MEAN',mean_Tr.shape)\n",
        "std_Tr = stdsc.var_\n",
        "\n",
        "gt_train        = gt_train.reshape(x_train.shape[0],-1)-mean_Tr\n",
        "x_train         = x_train.reshape(x_train.shape[0],-1)-mean_Tr\n",
        "#x_train_missing = stdsc.fit_transform(x_train_missing.reshape(x_train_missing.shape[0],-1))\n",
        "gt_test         = gt_test.reshape(len(x_test),-1)-mean_Tr                       \n",
        "x_test          = x_test.reshape(len(x_test),-1)-mean_Tr\n",
        "#x_test_missing  = stdsc.fit_transform(x_test_missing.reshape(x_test_missing.shape[0],-1))\n",
        "#y_pred_missing  = stdsc.fit_transform(y_pred_missing.reshape(len(y_pred),-1))\n",
        "y_pred          = y_pred.reshape(len(y_pred),-1)-mean_Tr\n",
        "#gt_pred         = stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1))\n",
        "\n",
        "if flagTrWMissingData == 1 :\n",
        "    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n",
        "else :\n",
        "    mask_train[np.where(~np.isnan(x_train))]=1\n",
        "    x_train_missing=x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0])*mask_train\n",
        "\n",
        "x_test_missing=x_test.reshape(x_test.shape[0],indLat.shape[0],indLon.shape[0])*mask_test\n",
        "if flagPred:\n",
        "  mask_pred[15:,:,:] = 0\n",
        "y_pred_missing=y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0])*mask_pred\n",
        "\n",
        "#Dimensionning                           \n",
        "gt_train        = gt_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_train         = x_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_train_missing = x_train_missing.reshape(x_train_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "mask_train      = mask_train.reshape(x_train.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "\n",
        "gt_test         = gt_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_test          = x_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "x_test_missing  = x_test_missing.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)   \n",
        "mask_test       = mask_test.reshape(indN_Tt.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "\n",
        "#gt_pred         = gt_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "y_pred          = y_pred.reshape(y_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "y_pred_missing  = y_pred_missing.reshape(y_pred_missing.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "mask_pred       = mask_pred.reshape(mask_pred.shape[0],indLat.shape[0],indLon.shape[0],1)\n",
        "\n",
        "#Change Nan to 0 Check isany Nan/inf \n",
        "def isany(x):\n",
        "    x[np.where(np.isnan(x))]=0\n",
        "    print(np.any(np.isnan(x)))\n",
        "    print(np.any(np.isinf(x)))\n",
        "    print(x.shape)\n",
        "\n",
        "isany(x_train)\n",
        "isany(x_test)\n",
        "isany(x_train_missing)\n",
        "isany(x_test_missing)\n",
        "isany(mask_test)\n",
        "isany(mask_train)\n",
        "isany(y_pred)\n",
        "isany(y_pred_missing)\n",
        "isany(x_train)\n",
        "isany(gt_test)\n",
        "isany(gt_train)\n",
        "#isany(gt_pred)\n",
        "\n",
        "\n",
        "print(\"... (after normalization) mean Tr = %f\"%(np.mean(gt_train)))\n",
        "print(\"... (after normalization) mean Tt = %f\"%(np.mean(gt_test)))\n",
        "#print(\"... (after normalization) mean Pred = %f\"%(np.mean(gt_pred)))\n",
        "print(\"... (after normalization) mean x_train = %f\"%(np.mean(x_train)))\n",
        "print(\"... (after normalization) mean x_train_missing = %f\"%(np.mean(x_train_missing)))\n",
        "print(\"... (after normalization) mean x_test = %f\"%(np.mean(x_test)))\n",
        "print(\"... (after normalization) mean x_test_missing = %f\"%(np.mean(x_test_missing)))\n",
        "print(\"... (after normalization) mean y_pred = %f\"%(np.mean(y_pred)))\n",
        "print(\"... (after normalization) mean y_pred_missing = %f\"%(np.mean(y_pred_missing)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  result = op(x, *args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered\n",
            "  overwrite_input=overwrite_input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MEAN (4096,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c4580a9e6254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx_train_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindLat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindLon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmask_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mx_train_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindLat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindLon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 1 with size 64"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93mvfED-vpZn"
      },
      "source": [
        "### Define GENN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0NuuUoBvpZo"
      },
      "source": [
        "# Constraints on kernel to to zeros\n",
        "# a specific position\n",
        "class Constraint_Zero(Constraint):\n",
        "    def __init__(self, position,kernel_shape,dw):\n",
        "        self.position = position\n",
        "        mask_array    = np.ones((kernel_shape))\n",
        "        mask_array[position[0]-dw:position[0]+dw+1,position[1]-dw:position[1]+dw+1,:,:] = 0.0\n",
        "\n",
        "        self.mask = K.variable(value=mask_array, dtype='float32', name='mask')\n",
        "\n",
        "        print(self.mask.shape)\n",
        "    def __call__(self, w):\n",
        "        print(self.mask.shape)\n",
        "        new_w = w * self.mask\n",
        "\n",
        "        return new_w\n",
        "\n",
        "def fl27(dict_global_Params,x_data,mask_data):\n",
        "\n",
        "    # import Global Parameters\n",
        "    for key,val in dict_global_Params.items():\n",
        "        exec(\"globals()['\"+key+\"']=val\")\n",
        "\n",
        "    WFilter       = 11#\n",
        "    NbResUnit     = 10#3#\n",
        "    dW            = 0\n",
        "    flagdownScale = 1 #: 0: only HR scale, 1 : only LR, 2 : HR + LR , 2 : MR, HR + LR annd LR,\n",
        "    scaleLR       = 2**2\n",
        "    NbFilter      = 1*DimAE\n",
        "    flagSRResNet  = 0\n",
        "     \n",
        "    input_layer = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "    mask       = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "    \n",
        "    if flagUseMaskinEncoder == 1:\n",
        "        dmask   = keras.layers.Lambda(lambda x: 0.2*x - 0.1)(mask)\n",
        "        \n",
        "        for jj in range(0,6):\n",
        "            dx    = keras.layers.Conv2D(10,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dmask)            \n",
        "            dx    = keras.layers.Conv2D(1,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)            \n",
        "            dmask = keras.layers.Add()([dmask,dx])\n",
        "            \n",
        "        x0       = keras.layers.Concatenate(axis=-1)([input_layer,dmask])\n",
        "    else:\n",
        "        x0  = keras.layers.Lambda(lambda x: 1. * x)(input_layer)\n",
        "\n",
        "    # coarse scale\n",
        "    if flagdownScale > 0 :\n",
        "        if flagUseMaskinEncoder == 1:\n",
        "            x = keras.layers.AveragePooling2D((scaleLR,scaleLR), padding='valid')(x0)\n",
        "            \n",
        "            x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n",
        "                padding='same',use_bias=False,\n",
        "                kernel_regularizer=keras.regularizers.l2(wl2),\n",
        "                kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,2*x_train.shape[3],NbFilter),dW))(x)\n",
        "        else:\n",
        "            x = keras.layers.AveragePooling2D((scaleLR,scaleLR), padding='valid')(x0)\n",
        "\n",
        "            x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n",
        "            padding='same',use_bias=False,\n",
        "            kernel_regularizer=keras.regularizers.l2(wl2),\n",
        "            kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,x_train.shape[3],NbFilter),dW))(x)\n",
        "        x  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "  \n",
        "        # registration/evolution in feature space\n",
        "        scale = 0.1\n",
        "        for kk in range(0,NbResUnit):\n",
        "            if 1*1 :\n",
        "                dx = keras.layers.Conv2D(5*DimAE,(1,1),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "            else:\n",
        "                dx = keras.layers.Lambda(lambda x: scale * x)(x)\n",
        "      \n",
        "            dx_lin  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "            dx1 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "            dx2 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "      \n",
        "            dx1 = keras.layers.Multiply()([dx1,dx2])\n",
        "            \n",
        "            dx  = keras.layers.Add()([dx1,dx_lin])\n",
        "            dx  = keras.layers.Activation('tanh')(dx)\n",
        "            x  = keras.layers.Add()([x,dx])\n",
        "        x  = keras.layers.Conv2D(int(x_train.shape[3]/(N_cov+1)),(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "        x1 = keras.layers.Conv2DTranspose(int(x_train.shape[3]/(N_cov+1)),(scaleLR,scaleLR),strides=(scaleLR,scaleLR),use_bias=False,activation='linear',padding='same',output_padding=None,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "        \n",
        "        if flagSRResNet == 1: ## postprocessing: super-resolution-like block\n",
        "            x1  = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)               \n",
        "            \n",
        "            scale = 0.1\n",
        "            for kk in range(0,NbResUnit):\n",
        "                if 1*1 :\n",
        "                    dx = keras.layers.Conv2D(2*DimAE,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)\n",
        "                else:\n",
        "                    dx = keras.layers.Lambda(lambda x: scale * x)(x1)\n",
        "          \n",
        "                dx_lin  = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "                dx1 = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "                dx2 = keras.layers.Conv2D(DimAE,(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "          \n",
        "                dx1 = keras.layers.Multiply()([dx1,dx2])\n",
        "        \n",
        "                dx  = keras.layers.Add()([dx1,dx_lin])\n",
        "                dx  = keras.layers.Activation('tanh')(dx_lin)\n",
        "                x1  = keras.layers.Add()([x1,dx])\n",
        "            x1  = keras.layers.Conv2D(x_train.shape[3]/(N_cov+1),(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)\n",
        "        else:\n",
        "            x1  = keras.layers.Conv2D(2*DimAE,(3,3),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1) \n",
        "            x1  = keras.layers.Conv2D(int(x_train.shape[3]/(N_cov+1)),(3,3),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x1)          \n",
        "     \n",
        "    # fine scale\n",
        "    if flagUseMaskinEncoder == 1:\n",
        "        x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n",
        "            padding='same',use_bias=False,\n",
        "            kernel_regularizer=keras.regularizers.l2(wl2),\n",
        "            kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,2*x_train.shape[3],NbFilter),dW))(x0)\n",
        "    else:\n",
        "        x = keras.layers.Conv2D(NbFilter,(WFilter,WFilter),activation='relu', \n",
        "            padding='same',use_bias=False,\n",
        "            kernel_regularizer=keras.regularizers.l2(wl2),\n",
        "            kernel_constraint=Constraint_Zero((int(WFilter/2),int(WFilter/2)),(WFilter,WFilter,x_train.shape[3],NbFilter),dW))(x0)\n",
        "\n",
        "    if flagdownScale > 0 :\n",
        "        x  = keras.layers.Concatenate(axis=-1)([x,x1])\n",
        "    x  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "\n",
        "    for kk in range(0,NbResUnit):\n",
        "        if 1*1 :\n",
        "            dx      = keras.layers.Conv2D(5*DimAE,(1,1),activation='relu', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "        else:\n",
        "            dx  = keras.layers.Lambda(lambda x: scale * x)(x)\n",
        "          \n",
        "        dx_lin  = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "        dx1 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "        dx2 = keras.layers.Conv2D(DimAE,(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(dx)\n",
        "          \n",
        "        dx1 = keras.layers.Multiply()([dx1,dx2])\n",
        "        \n",
        "        dx  = keras.layers.Add()([dx1,dx_lin])\n",
        "        dx  = keras.layers.Activation('tanh')(dx)\n",
        "        x  = keras.layers.Add()([x,dx])\n",
        "\n",
        "    x  = keras.layers.Conv2D(int(x_train.shape[3]/(N_cov+1)),(1,1),activation='linear', padding='same',use_bias=False,kernel_regularizer=keras.regularizers.l2(wl2))(x)\n",
        "\n",
        "    if flagdownScale == 0:\n",
        "        encoder    = keras.models.Model([input_layer,mask],x)\n",
        "    elif flagdownScale == 1:\n",
        "        encoder    = keras.models.Model([input_layer,mask],x1)\n",
        "    elif flagdownScale == 2:\n",
        "        x          = keras.layers.Add()([x,x1]) \n",
        "        encoder    = keras.models.Model([input_layer,mask],x)\n",
        "    elif flagdownScale == 3:\n",
        "        x          = keras.layers.Add()([x,x1]) \n",
        "        encoder    = keras.models.Model([input_layer,mask],[x1,x])\n",
        "   \n",
        "    if flagdownScale == 3:\n",
        "        decoder_input1 = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))    \n",
        "        decoder_input2 = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))    \n",
        "        x1  = keras.layers.Lambda(lambda x: 1. * x)(decoder_input1)\n",
        "        x2  = keras.layers.Lambda(lambda x: 1. * x)(decoder_input2)\n",
        "        decoder       = keras.models.Model([decoder_input1,decoder_input2],[x1,x2])\n",
        "    else:\n",
        "        decoder_input = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))    \n",
        "        x  = keras.layers.Lambda(lambda x: 1. * x)(decoder_input)\n",
        "        decoder       = keras.models.Model(decoder_input,x)\n",
        "      \n",
        "    encoder.summary()\n",
        "    decoder.summary()\n",
        "\n",
        "    if flagdownScale < 3:\n",
        "        input_data = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "        mask       = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "  \n",
        "        x          = decoder(encoder([input_data,mask]))\n",
        "        model_AE   = keras.models.Model([input_data,mask],x)      \n",
        "    elif flagdownScale == 3:\n",
        "        \n",
        "        input_data = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "        mask       = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "        x,xLR      = encoder([input_data,mask])\n",
        "        \n",
        "        model_AE    = keras.models.Model([input_data,mask],x)\n",
        "        model_AE_MR = keras.models.Model([input_data,mask],[x,xLR])\n",
        "\n",
        "    size_tw = int(x_train.shape[3]/(N_cov+1))\n",
        "    #model_AE.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=1e-3))\n",
        "    model_AE.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=1e-3))\n",
        "    model_AE.summary()\n",
        "\n",
        "    DimCAE = DimAE\n",
        "\n",
        "    return encoder, decoder, model_AE, DimCAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg0RKrt2vpZx"
      },
      "source": [
        "def define_DINConvAE(NiterProjection,model_AE,shape,\\\n",
        "                    size_tw,N_cov=0):\n",
        "                     \n",
        "\n",
        "    # encoder-decoder with masked data\n",
        "    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    \n",
        "    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n",
        "    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n",
        "\n",
        "    # Iterations of fixed-point projection\n",
        "    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n",
        "    for kk in range(0,NiterProjection):\n",
        "        x_proj   = model_AE([x,mask])\n",
        "        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n",
        "        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n",
        "        x        = keras.layers.Add()([x,x_proj])\n",
        "\n",
        "    x_proj = model_AE([x,mask]) \n",
        "    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n",
        "\n",
        "    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "\n",
        "    maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n",
        "      \n",
        "    x_proj = global_model_FP([x_input,maskg])\n",
        "\n",
        "  \n",
        "    # AE error with x_proj\n",
        "    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj2 = model_AE([x_proj,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n",
        "    err2    = error(x_proj,x_proj2,mask,size_tw,shape,0,N_cov)\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj3 = model_AE([x_proj,keras.layers.Lambda(lambda x:0.*x)(mask)])\n",
        "    err3    = error(x_proj3,x_proj,mask,size_tw,shape,0,N_cov)\n",
        "    # add all errors\n",
        "    err    = keras.layers.Add()([err1,err2])\n",
        "    err    = keras.layers.Add()([err,err3])\n",
        "\n",
        "    # return global model\n",
        "    global_model_FP_Masked  = keras.models.Model([x_input,mask],err)\n",
        "    global_model_FP.summary()\n",
        "    global_model_FP_Masked.summary()\n",
        "  \n",
        "    return global_model_FP,global_model_FP_Masked\n",
        "\n",
        "def slice_layer(index):\n",
        "    def func(x_input):\n",
        "        return tf.gather(x_input, index, axis=3)\n",
        "    return keras.layers.Lambda(func)\n",
        "\n",
        "def assign_sliced_layer(size_tw,N_cov,x_output):\n",
        "    def func(x_input,x_output):\n",
        "        for i in range(1,(N_cov+1)):\n",
        "            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n",
        "            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n",
        "        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n",
        "                           for i in range(0,N_cov+1)]).T.flatten()\n",
        "        x_proj = slice_layer(index)(x_output)\n",
        "        return x_proj\n",
        "    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n",
        "\n",
        "def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n",
        "    if x1.shape[3]>x2.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    elif x2.shape[3]>x1.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    else:\n",
        "        err   = keras.layers.Subtract()([x1,x2])\n",
        "        err   = keras.layers.Multiply()([err,mask])\n",
        "    err   = keras.layers.Multiply()([err,err])\n",
        "    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n",
        "    err   = keras.layers.GlobalAveragePooling3D()(err)\n",
        "    err   = keras.layers.Reshape((1,))(err)\n",
        "    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n",
        "    return err\n",
        "\n",
        "def keras_custom_loss_function(size_tw):\n",
        "    def insert_Sobel(size_tw,dir=\"x\"):\n",
        "        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n",
        "        if dir==\"x\":\n",
        "            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n",
        "        if dir==\"y\":\n",
        "            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n",
        "        for i in range(size_tw):\n",
        "            kernel_weights[:,:,i,i]=sobel\n",
        "        return kernel_weights\n",
        "    def lossFunction(y_true,y_pred):\n",
        "        mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
        "        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n",
        "        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n",
        "        Gx_true = K.conv2d(y_true, filter_gx, padding=\"same\")\n",
        "        Gy_true = K.conv2d(y_true, filter_gy, padding=\"same\")\n",
        "        Grad_true = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_true,Gx_true]),\\\n",
        "                                       keras.layers.Multiply()([Gy_true,Gy_true])]))\n",
        "        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n",
        "        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n",
        "        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n",
        "        mae_grad = tf.keras.losses.mean_absolute_error(Grad_true, Grad_pred)\n",
        "        alpha= 0.5\n",
        "        loss = ((1.-alpha)*mae) + (alpha*mae_grad)\n",
        "        return loss\n",
        "    return lossFunction\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n",
        "\n",
        "    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n",
        "    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n",
        "    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n",
        "   \n",
        "    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n",
        "    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n",
        "    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n",
        "           \n",
        "    return exp_var_AE_Tr,exp_var_AE_Tt\n",
        "\n",
        "# functions for the evaluation of interpolation and auto-encoding performance\n",
        "def eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt):\n",
        "\n",
        "    mse_AE_Tr        = np.mean( (rec_AE_Tr - x_train)**2 )\n",
        "    var_Tr           = np.mean( (x_train-np.mean(x_train,axis=0)) ** 2 )\n",
        "    exp_var_AE_Tr    = 1. - mse_AE_Tr / var_Tr\n",
        "    \n",
        "    mse_AE_Tt        = np.mean( (rec_AE_Tt - x_test)**2 )\n",
        "    var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n",
        "    exp_var_AE_Tt    = 1. - mse_AE_Tt / var_Tt\n",
        "            \n",
        "    return exp_var_AE_Tr,exp_var_AE_Tt\n",
        "\n",
        "def eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\n",
        "                           mask_test,x_test,x_test_missing,x_test_pred):\n",
        "    mse_train      = np.zeros((2))\n",
        "    mse_train[0]   = np.sum( mask_train * (x_train_pred - x_train_missing)**2 ) / np.sum( mask_train )\n",
        "    mse_train[1]   = np.mean( (x_train_pred - x_train)**2 )\n",
        "    exp_var_train  = 1. - mse_train #/ var_Tr\n",
        "            \n",
        "    mse_test        = np.zeros((2))\n",
        "    mse_test[0]     = np.sum( mask_test * (x_test_pred - x_test_missing)**2 ) / np.sum( mask_test )\n",
        "    mse_test[1]     = np.mean( (x_test_pred - x_test)**2 ) \n",
        "    exp_var_test = 1. - mse_test #/ var_Tt\n",
        "\n",
        "    mse_train_interp        = np.sum( (1.-mask_train) * (x_train_pred - x_train)**2 ) / np.sum( 1. - mask_train )\n",
        "    exp_var_train_interp    = 1. - mse_train_interp \n",
        "    \n",
        "    mse_test_interp        = np.sum( (1.-mask_test) * (x_test_pred - x_test)**2 ) / np.sum( 1. - mask_test )\n",
        "    exp_var_test_interp    = 1. - mse_test_interp\n",
        "            \n",
        "    return mse_train,exp_var_train,mse_test,exp_var_test,mse_train_interp,exp_var_train_interp,mse_test_interp,exp_var_test_interp\n",
        "\n",
        "# function to create recursive paths\n",
        "def mk_dir_recursive(dir_path):\n",
        "    if os.path.isdir(dir_path):\n",
        "        return\n",
        "    h, t = os.path.split(dir_path)  # head/tail\n",
        "    if not os.path.isdir(h):\n",
        "        mk_dir_recursive(h)\n",
        "\n",
        "    new_path = join_paths(h, t)\n",
        "    if not os.path.isdir(new_path):\n",
        "        os.mkdir(new_path)\n",
        "\n",
        "def Gradient(img, order):\n",
        "    \"\"\" calculate x, y gradient and magnitude \"\"\" \n",
        "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
        "    sobelx = sobelx/8.0\n",
        "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n",
        "    sobely = sobely/8.0\n",
        "    sobel_norm = np.sqrt(sobelx*sobelx+sobely*sobely)\n",
        "    if (order==0):\n",
        "        return sobelx\n",
        "    elif (order==1):\n",
        "        return sobely\n",
        "    else:\n",
        "        return sobel_norm\n",
        "\n",
        "def insert_Sobel(size_tw,dir=\"x\"):\n",
        "    kernel_weights=np.zeros((3,3,size_tw,size_tw))\n",
        "    if dir==\"x\":\n",
        "        sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n",
        "    if dir==\"y\":\n",
        "        sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n",
        "    for i in range(size_tw):\n",
        "        kernel_weights[:,:,i,i]=sobel\n",
        "    return kernel_weights\n",
        "\n",
        "# New loss function for unsupervised setting:\n",
        "# L = MAE + ||Grad||^2\n",
        "def keras_custom_loss_function2(size_tw):\n",
        "    def insert_Sobel(size_tw,dir=\"x\"):\n",
        "        kernel_weights=np.zeros((3,3,size_tw,size_tw))\n",
        "        if dir==\"x\":\n",
        "            sobel=np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).T\n",
        "        if dir==\"y\":\n",
        "            sobel=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).T\n",
        "        for i in range(size_tw):\n",
        "            kernel_weights[:,:,i,i]=sobel\n",
        "        return kernel_weights\n",
        "    def lossFunction(y_true,y_pred):\n",
        "        filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n",
        "        filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n",
        "        Gx_pred = K.conv2d(y_pred, filter_gx, padding=\"same\")\n",
        "        Gy_pred = K.conv2d(y_pred, filter_gy, padding=\"same\")\n",
        "        Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "                                       keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n",
        "        loss = K.mean(keras.layers.Multiply()([Grad_pred,Grad_pred]))\n",
        "        return loss\n",
        "    return lossFunction\n",
        "\n",
        "def thresholding(x,thr):\n",
        "    greater = K.greater_equal(x,thr) #will return boolean values\n",
        "    greater = K.cast(greater, dtype=K.floatx()) #will convert bool to 0 and 1    \n",
        "    return greater\n",
        "\n",
        "def slice_layer(index):\n",
        "    def func(x_input):\n",
        "        return tf.gather(x_input, index, axis=3)\n",
        "    return keras.layers.Lambda(func)\n",
        "\n",
        "def assign_sliced_layer(size_tw,N_cov,x_output):\n",
        "    def func(x_input,x_output):\n",
        "        for i in range(1,(N_cov+1)):\n",
        "            index = np.arange(i,(N_cov+1)*size_tw,(N_cov+1),dtype='int32')\n",
        "            x_output = keras.layers.Concatenate()([x_output,slice_layer(index)(x_input)])\n",
        "        index  = np.stack([np.arange(i*size_tw,(i+1)*size_tw) \\\n",
        "                           for i in range(0,N_cov+1)]).T.flatten()\n",
        "        x_proj = slice_layer(index)(x_output)\n",
        "        return x_proj\n",
        "    return keras.layers.Lambda(func,arguments={'x_output':x_output})\n",
        "\n",
        "def error(x1,x2,mask,size_tw,shape,alpha,N_cov):\n",
        "    if x1.shape[3]>x2.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([slice_layer(index)(x1),x2])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    elif x2.shape[3]>x1.shape[3]:\n",
        "        index = np.arange(0,(N_cov+1)*size_tw,N_cov+1,dtype='int32')\n",
        "        err   = keras.layers.Subtract()([x1,slice_layer(index)(x2)])\n",
        "        err   = keras.layers.Multiply()([err,slice_layer(index)(mask)])\n",
        "    else:\n",
        "        err   = keras.layers.Subtract()([x1,x2])\n",
        "        err   = keras.layers.Multiply()([err,mask])\n",
        "    err   = keras.layers.Multiply()([err,err])\n",
        "    err   = keras.layers.Reshape((err.shape[-3],err.shape[-2],err.shape[-1],1))(err)\n",
        "    # normalize err\n",
        "    err   = keras.layers.GlobalAveragePooling3D()(err)\n",
        "    err   = keras.layers.Reshape((1,))(err)\n",
        "    err   = keras.layers.Lambda(lambda x: alpha*x)(err)\n",
        "    return err\n",
        "\n",
        "def regularize_Gradient(x_proj,size_tw):\n",
        "    filter_gx  = K.constant(insert_Sobel(size_tw,\"x\"))\n",
        "    filter_gy  = K.constant(insert_Sobel(size_tw,\"y\"))\n",
        "    def Gradient(tensors):\n",
        "        tensor = tensors[0]\n",
        "        filter = tensors[1]\n",
        "        return K.conv2d(tensor, filter, padding=\"same\")\n",
        "    Gx_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gx])\n",
        "    Gy_pred = keras.layers.Lambda(Gradient)([x_proj, filter_gy])\n",
        "    #Grad_pred = K.sqrt(keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "    #                                    keras.layers.Multiply()([Gy_pred,Gy_pred])]))\n",
        "    Grad_pred = keras.layers.Add()([keras.layers.Multiply()([Gx_pred,Gx_pred]),\\\n",
        "                                        keras.layers.Multiply()([Gy_pred,Gy_pred])])\n",
        "    reg_Gradient   = keras.layers.Reshape((Grad_pred.shape[-3],Grad_pred.shape[-2],Grad_pred.shape[-1],1))(Grad_pred)\n",
        "    reg_Gradient   = keras.layers.GlobalAveragePooling3D()(reg_Gradient)\n",
        "    reg_Gradient   = keras.layers.Reshape((1,))(reg_Gradient)\n",
        "    reg_Gradient   = keras.layers.Lambda(lambda x: 1*x)(reg_Gradient)\n",
        "    return reg_Gradient\n",
        "\n",
        "def define_DINConvAE(NiterProjection,model_AE,shape,\\\n",
        "                     flagUseMaskinEncoder,\\\n",
        "                     size_tw,include_covariates,N_cov=0):\n",
        "\n",
        "    # encoder-decoder with masked data\n",
        "    x_input         = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    mask            = keras.layers.Input((shape[1],shape[2],shape[3]))\n",
        "    \n",
        "    x     = keras.layers.Lambda(lambda x:1.*x)(x_input)\n",
        "    mask_ = keras.layers.Lambda(lambda x:1.-x)(mask)\n",
        "\n",
        "    # Iterations of fixed-point projection\n",
        "    index = np.arange(0,(N_cov+1)*size_tw,N_cov+1)   \n",
        "    for kk in range(0,NiterProjection):\n",
        "        x_proj   = model_AE([x,mask])\n",
        "        x_proj   = keras.layers.Multiply()([x_proj,slice_layer(index)(mask_)])\n",
        "        x        = keras.layers.Multiply()([slice_layer(index)(x),slice_layer(index)(mask)])\n",
        "        x        = keras.layers.Add()([x,x_proj])\n",
        "\n",
        "\n",
        "    x_proj = model_AE([x,mask]) \n",
        "    global_model_FP    = keras.models.Model([x_input,mask],[x_proj])\n",
        "\n",
        "    # randomly sample an additionnal missing data mask\n",
        "    # additive noise + spatial smoothing\n",
        "    if flagUseMaskinEncoder == 1:\n",
        "        WAvFilter     = 3\n",
        "        NIterAvFilter = 3\n",
        "        thrNoise      = 1.5 * stdMask + 1e-7\n",
        "        maskg   = keras.layers.GaussianNoise(stdMask)(mask)\n",
        "        avFilter       = 1./(WAvFilter**3)*np.ones((WAvFilter,WAvFilter,WAvFilter,1,1))\n",
        "        spatialAvLayer = keras.layers.Conv3D(1,(WAvFilter,WAvFilter,WAvFilter),weights=[avFilter],\\\n",
        "                           padding='same',activation='linear',use_bias=False,name='SpatialAverage')\n",
        "        spatialAvLayer.trainable = False\n",
        "        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,3,1,2)))(maskg) \n",
        "        maskg  = keras.layers.Reshape((shape[3],shape[1],shape[2],1))(maskg)\n",
        "        for nn in range(0,NIterAvFilter):\n",
        "            maskg  = spatialAvLayer(maskg) \n",
        "        maskg = keras.layers.Lambda(lambda x: K.permute_dimensions(x,(0,2,3,1,4)))(maskg) \n",
        "        maskg = keras.layers.Reshape((shape[1],shape[2],shape[3]))(maskg)\n",
        "        maskg = keras.layers.Lambda(lambda x: thresholding(x,thrNoise))(maskg)    \n",
        "        maskg  = keras.layers.Multiply()([mask,maskg])\n",
        "        maskg  = keras.layers.Subtract()([mask,maskg])       \n",
        "    else:\n",
        "        maskg = keras.layers.Lambda(lambda x: 1.*x)(mask)\n",
        "\n",
        "    x_proj = global_model_FP([x_input,maskg])\n",
        "    # AE error with x_proj\n",
        "    err1 = error(x_proj,x_input,mask,size_tw,shape,1,N_cov)\n",
        "    # AE error with x_proj\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj_ = x_proj\n",
        "    \n",
        "    x_proj2 = model_AE([x_proj_,keras.layers.Lambda(lambda x:1.-0.*x)(mask)])\n",
        "    err2    = error(x_proj_,x_proj2,mask,size_tw,shape,0,N_cov)\n",
        "    # compute error (x_proj-x_input)**2 with full-1 mask\n",
        "    x_proj3 = model_AE([x_proj_,keras.layers.Lambda(lambda x:0.*x)(mask)])\n",
        "    err3    = error(x_proj3,x_proj_,mask,size_tw,shape,0,N_cov)\n",
        "    # add all errors\n",
        "    err    = keras.layers.Add()([err1,err2])\n",
        "    err    = keras.layers.Add()([err,err3])\n",
        "\n",
        "    # return global model\n",
        "    global_model_FP_Masked  = keras.models.Model([x_input,mask],[err,x_proj])\n",
        "\n",
        "    global_model_FP.summary()\n",
        "    global_model_FP_Masked.summary()\n",
        "    return global_model_FP,global_model_FP_Masked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcs8QZ4uvpZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f988e450-fd84-4113-fcf8-5e52dace19a5"
      },
      "source": [
        "#Apply model     \n",
        "encoder, decoder, model_AE, DimCAE = fl27(globParams,x_train,mask_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11, 11, 1, 20)\n",
            "(11, 11, 1, 20)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 64, 64, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 1)    0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 20)   2420        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 20)   400         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 100)  2000        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 16, 16, 20)   0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 20)   0           multiply[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 16, 16, 20)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 20)   0           conv2d_1[0][0]                   \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 100)  2000        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 16, 16, 20)   0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 20)   2000        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 20)   0           multiply_1[0][0]                 \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 20)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 20)   0           add_1[0][0]                      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 100)  2000        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 16, 16, 20)   0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 20)   0           multiply_2[0][0]                 \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 20)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 20)   0           add_3[0][0]                      \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 100)  2000        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 16, 16, 20)   0           conv2d_16[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 20)   0           multiply_3[0][0]                 \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 20)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 20)   0           add_5[0][0]                      \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 100)  2000        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 16, 16, 20)   0           conv2d_20[0][0]                  \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 20)   0           multiply_4[0][0]                 \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 20)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 20)   0           add_7[0][0]                      \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 100)  2000        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 16, 16, 20)   0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 20)   0           multiply_5[0][0]                 \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 20)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 20)   0           add_9[0][0]                      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 100)  2000        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 16, 16, 20)   0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 20)   0           multiply_6[0][0]                 \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 20)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 20)   0           add_11[0][0]                     \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 100)  2000        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, 16, 16, 20)   0           conv2d_32[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 20)   0           multiply_7[0][0]                 \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 20)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 16, 16, 20)   0           add_13[0][0]                     \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 100)  2000        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_8 (Multiply)           (None, 16, 16, 20)   0           conv2d_36[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 16, 16, 20)   0           multiply_8[0][0]                 \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 20)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 16, 16, 20)   0           add_15[0][0]                     \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 100)  2000        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_9 (Multiply)           (None, 16, 16, 20)   0           conv2d_40[0][0]                  \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 20)   2000        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 20)   0           multiply_9[0][0]                 \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 20)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 20)   0           add_17[0][0]                     \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 1)    20          add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 64, 64, 1)    16          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 64, 64, 40)   360         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 64, 64, 1)    360         conv2d_43[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 64, 64, 1)         0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Functional)              (None, 64, 64, 1)    83576       input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Functional)            (None, 64, 64, 1)    0           model[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLreoecvpZw"
      },
      "source": [
        "### Train-Model - FP - Iterated projection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEbLPGz_vpZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf152631-6fff-4459-bd12-11095940845b"
      },
      "source": [
        "def flagProcess4_Optim0(dict_global_Params,x_train,x_train_missing,mask_train,gt_train,\\\n",
        "                    x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE):\n",
        "\n",
        "    for key,val in dict_global_Params.items():\n",
        "        exec(\"globals()['\"+key+\"']=val\")\n",
        "\n",
        "    meanTr = stdsc.mean_\n",
        "    stdTr = np.mean(stdsc.var_)\n",
        "    # ***************** #\n",
        "    # model compilation #\n",
        "    # ***************** #\n",
        "\n",
        "    # model fit\n",
        "    NbProjection   = [0,0,2,2,5,5,10,15,14]\n",
        "    NbProjection   = [5,5,5,5]\n",
        "    lrUpdate       = [1e-3,1e-4,1e-5,1e-5,1e-5,1e-6,1e-6,1e-5,1e-6]\n",
        "    if flagTrOuputWOMissingData==0:\n",
        "        lrUpdate   = [1e-4,1e-5,1e-6,1e-7]\n",
        "    else:\n",
        "        lrUpdate   = [1e-3,1e-4,1e-5,1e-6]\n",
        "    IterUpdate     = [0,3,10,15,20,25,30,35,40]\n",
        "    #IterUpdate     = [0,6,15,20]\n",
        "    val_split      = 0.1\n",
        "    \n",
        "    iterInit = 0\n",
        "    IterTrainAE = 0\n",
        "    IterUpdateInit = 10000\n",
        "    \n",
        "    ## initialization\n",
        "    x_train_init = np.copy(x_train_missing)\n",
        "    x_test_init  = np.copy(x_test_missing)\n",
        "\n",
        "    comptUpdate = 0\n",
        "\n",
        "    # ******************** #\n",
        "    # Start Learning model #\n",
        "    # ******************** #\n",
        "        \n",
        "    print(\"..... Start learning AE model\")\n",
        "    for iter in tqdm(range(iterInit,Niter)):\n",
        "        if iter == IterUpdate[comptUpdate]:\n",
        "            # update DINConvAE model\n",
        "            NBProjCurrent = NbProjection[comptUpdate]\n",
        "            print(\"..... Update/initialize number of projections in DINCOnvAE model # %d\"%(NbProjection[comptUpdate]))\n",
        "            global_model_FP,global_model_FP_Masked = define_DINConvAE(NbProjection[comptUpdate],model_AE,x_train.shape,\\\n",
        "                                                                          flagUseMaskinEncoder,\\\n",
        "                                                                          size_tw,N_cov)\n",
        "            if flagTrOuputWOMissingData == 1:\n",
        "                #global_model_FP.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "                global_model_FP.compile(loss=keras_custom_loss_function(size_tw),optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "            else:\n",
        "                global_model_FP_Masked.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "                #global_model_FP_Masked.compile(loss=['mean_squared_error',keras_custom_loss_function2(size_tw)],loss_weights=[1.0,1e-10],optimizer=keras.optimizers.Adam(lr=lrUpdate[comptUpdate]))\n",
        "            if comptUpdate < len(NbProjection)-1:\n",
        "                comptUpdate += 1\n",
        "        \n",
        "        # gradient descent iteration            \n",
        "        if flagTrOuputWOMissingData == 1:\n",
        "            history = global_model_FP.fit([x_train_init,mask_train],gt_train,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs = NbEpoc,\n",
        "                  verbose = 1, \n",
        "                  validation_split=val_split)\n",
        "        else:\n",
        "            history = global_model_FP_Masked.fit([x_train_init,mask_train],[np.zeros((x_train_init.shape[0],1)),gt_train],\n",
        "                  batch_size=batch_size,\n",
        "                  epochs = NbEpoc,\n",
        "                  verbose = 1, \n",
        "                  validation_split=val_split)\n",
        "\n",
        "        # *********************** #\n",
        "        # Prediction on test data #\n",
        "        # *********************** #\n",
        "\n",
        "        # trained full-model\n",
        "        x_train_pred    = global_model_FP.predict([x_train_init,mask_train])\n",
        "        x_test_pred     = global_model_FP.predict([x_test_init,mask_test])\n",
        "\n",
        "        # trained AE applied to gap-free data\n",
        "        if flagUseMaskinEncoder == 1:\n",
        "          rec_AE_Tr     = model_AE.predict([x_train,np.zeros((mask_train.shape))])\n",
        "          rec_AE_Tt     = model_AE.predict([x_test,np.zeros((mask_train.shape))])\n",
        "        else:\n",
        "          rec_AE_Tr     = model_AE.predict([x_train,np.ones((mask_train.shape))])\n",
        "          rec_AE_Tt     = model_AE.predict([x_test,np.ones((mask_test.shape))])\n",
        "\n",
        "\n",
        "        mse_train,exp_var_train,\\\n",
        "        mse_test,exp_var_test,\\\n",
        "        mse_train_interp,exp_var_train_interp,\\\n",
        "        mse_test_interp,exp_var_test_interp =\\\n",
        "        eval_InterpPerformance(mask_train,x_train,x_train_missing,x_train_pred,\\\n",
        "                               mask_test,x_test,x_test_missing,x_test_pred)\n",
        "        \n",
        "        # interpolation and reconstruction score for the center image\n",
        "        # when dealing with time series\n",
        "        if x_train_init.shape[3] > 0 :\n",
        "            \n",
        "            dWCenter    = 32  \n",
        "            \n",
        "            dT = np.floor( x_train_init.shape[3] / 2 ).astype(int)\n",
        "            mse_train_center        = np.mean( (x_train_pred[:,:,:,dT] - x_train[:,:,:,dT] )**2 )\n",
        "            mse_train_center_interp = np.sum( (x_train_pred[:,:,:,dT]  - x_train[:,:,:,dT] )**2 * (1.-mask_train[:,:,:,dT])  ) / np.sum( (1.-mask_train[:,:,:,dT]) )\n",
        "            \n",
        "            mse_test_center         = np.mean( (x_test_pred[:,:,:,dT] - x_test[:,:,:,dT] )**2 )\n",
        "            mse_test_center_interp  = np.sum( (x_test_pred[:,:,:,dT]  - x_test[:,:,:,dT] )**2 * (1.-mask_test[:,:,:,dT])  ) / np.sum( (1-mask_test[:,:,:,dT]) )\n",
        "            \n",
        "            var_train_center        = np.var(  x_train[:,:,:,dT] )\n",
        "            var_test_center         = np.var(  x_test[:,:,:,dT] )\n",
        "            \n",
        "            exp_var_train_center         = 1.0 - mse_train_center / var_train_center\n",
        "            exp_var_train_interp_center  = 1.0 - mse_train_center_interp / var_train_center\n",
        "            exp_var_test_center          = 1.0 - mse_test_center  / var_test_center\n",
        "            exp_var_test_interp_center   = 1.0 - mse_test_center_interp/ var_test_center\n",
        "        # AE performance of the trained AE applied to gap-free data\n",
        "        exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n",
        "        \n",
        "        print(\".......... Auto-encoder performance when applied to gap-free data\")\n",
        "        print('.... explained variance AE (Tr)  : %.2f%%'%(100.*exp_var_AE_Tr))\n",
        "        print('.... explained variance AE (Tt)  : %.2f%%'%(100.*exp_var_AE_Tt))\n",
        "        \n",
        "        if flagUseMaskinEncoder == 1:\n",
        "        \n",
        "            exp_var_AE_Tr,exp_var_AE_Tt = eval_AEPerformance(x_train,rec_AE_Tr,x_test,rec_AE_Tt)\n",
        "        \n",
        "            print('.... explained variance AE (Tr) with mask  : %.2f%%'%(100.*exp_var_AE_Tr))\n",
        "            print('.... explained variance AE (Tt) with mask  : %.2f%%'%(100.*exp_var_AE_Tt))\n",
        "\n",
        "\n",
        "\n",
        "        # update training data\n",
        "        if iter > IterUpdateInit:\n",
        "            # mask = 0(missing data) ; 1(data)\n",
        "          x_train_init = mask_train * x_train_missing + (1.-mask_train) * x_train_pred\n",
        "          x_test_init  = mask_test  * x_test_missing  + (1.-mask_test)  * x_test_pred\n",
        "    return global_model_FP,global_model_FP_Masked\n",
        "print('ready')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWWtqOlmvpZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985cb99e-b3e0-40c6-d3ca-523b2c56f63d"
      },
      "source": [
        "global_model_FP,global_model_FP_Masked=flagProcess4_Optim0(globParams,x_train,x_train_missing,mask_train,gt_train,x_test,x_test_missing,mask_test,gt_test,lday_test,encoder,decoder,model_AE,DimCAE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/18 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "..... Start learning AE model\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 64, 64, 1)    0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       lambda_2[0][0]                   \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 add_40[0][0]                     \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 add_41[0][0]                     \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 add_42[0][0]                     \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 add_43[0][0]                     \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 add_44[0][0]                     \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 64, 64, 1)    0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 64, 64, 1)    0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_21 (Multiply)          (None, 64, 64, 1)    0           lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_20 (Multiply)          (None, 64, 64, 1)    0           model_2[0][0]                    \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 64, 64, 1)    0           multiply_21[0][0]                \n",
            "                                                                 multiply_20[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 64, 64, 1)    0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 64, 64, 1)    0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_23 (Multiply)          (None, 64, 64, 1)    0           lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_22 (Multiply)          (None, 64, 64, 1)    0           model_2[1][0]                    \n",
            "                                                                 lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 64, 64, 1)    0           multiply_23[0][0]                \n",
            "                                                                 multiply_22[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 64, 64, 1)    0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 64, 64, 1)    0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_25 (Multiply)          (None, 64, 64, 1)    0           lambda_11[0][0]                  \n",
            "                                                                 lambda_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_24 (Multiply)          (None, 64, 64, 1)    0           model_2[2][0]                    \n",
            "                                                                 lambda_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 64, 64, 1)    0           multiply_25[0][0]                \n",
            "                                                                 multiply_24[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 64, 64, 1)    0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 64, 64, 1)    0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_27 (Multiply)          (None, 64, 64, 1)    0           lambda_14[0][0]                  \n",
            "                                                                 lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_26 (Multiply)          (None, 64, 64, 1)    0           model_2[3][0]                    \n",
            "                                                                 lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 64, 64, 1)    0           multiply_27[0][0]                \n",
            "                                                                 multiply_26[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 64, 64, 1)    0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 64, 64, 1)    0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_29 (Multiply)          (None, 64, 64, 1)    0           lambda_17[0][0]                  \n",
            "                                                                 lambda_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_28 (Multiply)          (None, 64, 64, 1)    0           model_2[4][0]                    \n",
            "                                                                 lambda_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 64, 64, 1)    0           multiply_29[0][0]                \n",
            "                                                                 multiply_28[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Functional)            (None, 64, 64, 1)    83576       input_6[0][0]                    \n",
            "                                                                 lambda_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_21 (Lambda)              (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       model_3[0][0]                    \n",
            "                                                                 lambda_21[0][0]                  \n",
            "                                                                 model_3[0][0]                    \n",
            "                                                                 lambda_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_23 (Lambda)              (None, 64, 64, 1)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 64, 64, 1)    0           model_3[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 64, 64, 1)    0           model_3[0][0]                    \n",
            "                                                                 model_2[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_30 (Multiply)          (None, 64, 64, 1)    0           subtract[0][0]                   \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_32 (Multiply)          (None, 64, 64, 1)    0           subtract_1[0][0]                 \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract_2 (Subtract)           (None, 64, 64, 1)    0           model_2[7][0]                    \n",
            "                                                                 model_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_31 (Multiply)          (None, 64, 64, 1)    0           multiply_30[0][0]                \n",
            "                                                                 multiply_30[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_33 (Multiply)          (None, 64, 64, 1)    0           multiply_32[0][0]                \n",
            "                                                                 multiply_32[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_34 (Multiply)          (None, 64, 64, 1)    0           subtract_2[0][0]                 \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 64, 64, 1, 1) 0           multiply_31[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 64, 64, 1, 1) 0           multiply_33[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_35 (Multiply)          (None, 64, 64, 1)    0           multiply_34[0][0]                \n",
            "                                                                 multiply_34[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d (Globa (None, 1)            0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_1 (Glo (None, 1)            0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 64, 64, 1, 1) 0           multiply_35[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1)            0           global_average_pooling3d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1)            0           global_average_pooling3d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_2 (Glo (None, 1)            0           reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 1)            0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_22 (Lambda)              (None, 1)            0           reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 1)            0           global_average_pooling3d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 1)            0           lambda_20[0][0]                  \n",
            "                                                                 lambda_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_24 (Lambda)              (None, 1)            0           reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 1)            0           add_45[0][0]                     \n",
            "                                                                 lambda_24[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "(11, 11, 1, 20)\n",
            "(11, 11, 1, 20)\n",
            "41/41 [==============================] - 161s 3s/step - loss: 0.1566 - add_46_loss: 0.0043 - model_3_loss: 0.1523 - val_loss: 0.1306 - val_add_46_loss: 0.0026 - val_model_3_loss: 0.1280\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 89s 2s/step - loss: 0.1430 - add_46_loss: 0.0015 - model_3_loss: 0.1415 - val_loss: 0.1156 - val_add_46_loss: 0.0011 - val_model_3_loss: 0.1144\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1176 - add_46_loss: 7.4288e-04 - model_3_loss: 0.1168 - val_loss: 0.1098 - val_add_46_loss: 9.0096e-04 - val_model_3_loss: 0.1089\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 109s 3s/step - loss: 0.1171 - add_46_loss: 5.6330e-04 - model_3_loss: 0.1165 - val_loss: 0.1089 - val_add_46_loss: 8.0988e-04 - val_model_3_loss: 0.1081\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 104s 3s/step - loss: 0.1194 - add_46_loss: 4.7985e-04 - model_3_loss: 0.1189 - val_loss: 0.1058 - val_add_46_loss: 8.0115e-04 - val_model_3_loss: 0.1050\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 94s 2s/step - loss: 0.1212 - add_46_loss: 6.0333e-04 - model_3_loss: 0.1206 - val_loss: 0.1058 - val_add_46_loss: 7.4489e-04 - val_model_3_loss: 0.1051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|â–Œ         | 1/18 [11:59<3:23:56, 719.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 61.80%\n",
            ".... explained variance AE (Tt)  : 63.85%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 92s 2s/step - loss: 0.1182 - add_46_loss: 5.5913e-04 - model_3_loss: 0.1177 - val_loss: 0.1051 - val_add_46_loss: 7.2118e-04 - val_model_3_loss: 0.1044\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 94s 2s/step - loss: 0.1178 - add_46_loss: 5.5526e-04 - model_3_loss: 0.1173 - val_loss: 0.1047 - val_add_46_loss: 6.9292e-04 - val_model_3_loss: 0.1040\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 91s 2s/step - loss: 0.1171 - add_46_loss: 5.3478e-04 - model_3_loss: 0.1166 - val_loss: 0.1038 - val_add_46_loss: 6.8131e-04 - val_model_3_loss: 0.1031\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1176 - add_46_loss: 5.4793e-04 - model_3_loss: 0.1171 - val_loss: 0.1046 - val_add_46_loss: 7.0657e-04 - val_model_3_loss: 0.1039\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 112s 3s/step - loss: 0.1164 - add_46_loss: 5.2976e-04 - model_3_loss: 0.1159 - val_loss: 0.1093 - val_add_46_loss: 7.5485e-04 - val_model_3_loss: 0.1086\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1168 - add_46_loss: 5.2665e-04 - model_3_loss: 0.1163 - val_loss: 0.1025 - val_add_46_loss: 6.7325e-04 - val_model_3_loss: 0.1018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|â–ˆ         | 2/18 [22:56<3:06:54, 700.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 64.40%\n",
            ".... explained variance AE (Tt)  : 66.28%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 107s 3s/step - loss: 0.1160 - add_46_loss: 5.2233e-04 - model_3_loss: 0.1155 - val_loss: 0.1021 - val_add_46_loss: 6.4394e-04 - val_model_3_loss: 0.1015\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1153 - add_46_loss: 5.0429e-04 - model_3_loss: 0.1148 - val_loss: 0.1019 - val_add_46_loss: 6.4424e-04 - val_model_3_loss: 0.1012\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 102s 2s/step - loss: 0.1153 - add_46_loss: 5.0144e-04 - model_3_loss: 0.1148 - val_loss: 0.1008 - val_add_46_loss: 6.2816e-04 - val_model_3_loss: 0.1002\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1150 - add_46_loss: 4.9089e-04 - model_3_loss: 0.1145 - val_loss: 0.0999 - val_add_46_loss: 6.5785e-04 - val_model_3_loss: 0.0992\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 106s 3s/step - loss: 0.1155 - add_46_loss: 4.9655e-04 - model_3_loss: 0.1150 - val_loss: 0.1023 - val_add_46_loss: 6.5265e-04 - val_model_3_loss: 0.1017\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1154 - add_46_loss: 4.9422e-04 - model_3_loss: 0.1149 - val_loss: 0.1008 - val_add_46_loss: 6.2675e-04 - val_model_3_loss: 0.1002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|â–ˆâ–‹        | 3/18 [33:44<2:51:16, 685.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 66.19%\n",
            ".... explained variance AE (Tt)  : 67.92%\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_25 (Lambda)              (None, 64, 64, 1)    0           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       lambda_25[0][0]                  \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 add_47[0][0]                     \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 add_48[0][0]                     \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 add_49[0][0]                     \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 add_50[0][0]                     \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 add_51[0][0]                     \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_28 (Lambda)              (None, 64, 64, 1)    0           lambda_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_29 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_27 (Lambda)              (None, 64, 64, 1)    0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_37 (Multiply)          (None, 64, 64, 1)    0           lambda_28[0][0]                  \n",
            "                                                                 lambda_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_36 (Multiply)          (None, 64, 64, 1)    0           model_2[8][0]                    \n",
            "                                                                 lambda_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 64, 64, 1)    0           multiply_37[0][0]                \n",
            "                                                                 multiply_36[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_31 (Lambda)              (None, 64, 64, 1)    0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_32 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_30 (Lambda)              (None, 64, 64, 1)    0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_39 (Multiply)          (None, 64, 64, 1)    0           lambda_31[0][0]                  \n",
            "                                                                 lambda_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_38 (Multiply)          (None, 64, 64, 1)    0           model_2[9][0]                    \n",
            "                                                                 lambda_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 64, 64, 1)    0           multiply_39[0][0]                \n",
            "                                                                 multiply_38[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_34 (Lambda)              (None, 64, 64, 1)    0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_35 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_33 (Lambda)              (None, 64, 64, 1)    0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_41 (Multiply)          (None, 64, 64, 1)    0           lambda_34[0][0]                  \n",
            "                                                                 lambda_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_40 (Multiply)          (None, 64, 64, 1)    0           model_2[10][0]                   \n",
            "                                                                 lambda_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 64, 64, 1)    0           multiply_41[0][0]                \n",
            "                                                                 multiply_40[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_37 (Lambda)              (None, 64, 64, 1)    0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_38 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_36 (Lambda)              (None, 64, 64, 1)    0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_43 (Multiply)          (None, 64, 64, 1)    0           lambda_37[0][0]                  \n",
            "                                                                 lambda_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_42 (Multiply)          (None, 64, 64, 1)    0           model_2[11][0]                   \n",
            "                                                                 lambda_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 64, 64, 1)    0           multiply_43[0][0]                \n",
            "                                                                 multiply_42[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_40 (Lambda)              (None, 64, 64, 1)    0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_41 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_39 (Lambda)              (None, 64, 64, 1)    0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_45 (Multiply)          (None, 64, 64, 1)    0           lambda_40[0][0]                  \n",
            "                                                                 lambda_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_44 (Multiply)          (None, 64, 64, 1)    0           model_2[12][0]                   \n",
            "                                                                 lambda_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 64, 64, 1)    0           multiply_45[0][0]                \n",
            "                                                                 multiply_44[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_42 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_5 (Functional)            (None, 64, 64, 1)    83576       input_8[0][0]                    \n",
            "                                                                 lambda_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_44 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       model_5[0][0]                    \n",
            "                                                                 lambda_44[0][0]                  \n",
            "                                                                 model_5[0][0]                    \n",
            "                                                                 lambda_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_46 (Lambda)              (None, 64, 64, 1)    0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract_3 (Subtract)           (None, 64, 64, 1)    0           model_5[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract_4 (Subtract)           (None, 64, 64, 1)    0           model_5[0][0]                    \n",
            "                                                                 model_2[14][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_46 (Multiply)          (None, 64, 64, 1)    0           subtract_3[0][0]                 \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_48 (Multiply)          (None, 64, 64, 1)    0           subtract_4[0][0]                 \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract_5 (Subtract)           (None, 64, 64, 1)    0           model_2[15][0]                   \n",
            "                                                                 model_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_47 (Multiply)          (None, 64, 64, 1)    0           multiply_46[0][0]                \n",
            "                                                                 multiply_46[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_49 (Multiply)          (None, 64, 64, 1)    0           multiply_48[0][0]                \n",
            "                                                                 multiply_48[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_50 (Multiply)          (None, 64, 64, 1)    0           subtract_5[0][0]                 \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 64, 64, 1, 1) 0           multiply_47[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 64, 64, 1, 1) 0           multiply_49[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_51 (Multiply)          (None, 64, 64, 1)    0           multiply_50[0][0]                \n",
            "                                                                 multiply_50[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_3 (Glo (None, 1)            0           reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_4 (Glo (None, 1)            0           reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_51[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 1)            0           global_average_pooling3d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 1)            0           global_average_pooling3d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_5 (Glo (None, 1)            0           reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_43 (Lambda)              (None, 1)            0           reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_45 (Lambda)              (None, 1)            0           reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 1)            0           global_average_pooling3d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 1)            0           lambda_43[0][0]                  \n",
            "                                                                 lambda_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_47 (Lambda)              (None, 1)            0           reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 1)            0           add_52[0][0]                     \n",
            "                                                                 lambda_47[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/6\n",
            "(11, 11, 1, 20)\n",
            "(11, 11, 1, 20)\n",
            "41/41 [==============================] - 161s 3s/step - loss: 0.1137 - add_53_loss: 4.3849e-04 - model_5_loss: 0.1132 - val_loss: 0.0994 - val_add_53_loss: 6.1832e-04 - val_model_5_loss: 0.0988\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 120s 3s/step - loss: 0.1063 - add_53_loss: 4.8375e-04 - model_5_loss: 0.1058 - val_loss: 0.0995 - val_add_53_loss: 6.1591e-04 - val_model_5_loss: 0.0988\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 132s 3s/step - loss: 0.1178 - add_53_loss: 4.6132e-04 - model_5_loss: 0.1174 - val_loss: 0.0996 - val_add_53_loss: 6.1365e-04 - val_model_5_loss: 0.0990\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 119s 3s/step - loss: 0.1127 - add_53_loss: 4.4615e-04 - model_5_loss: 0.1123 - val_loss: 0.0993 - val_add_53_loss: 6.1583e-04 - val_model_5_loss: 0.0987\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 99s 2s/step - loss: 0.1120 - add_53_loss: 5.2374e-04 - model_5_loss: 0.1115 - val_loss: 0.0993 - val_add_53_loss: 6.1296e-04 - val_model_5_loss: 0.0987\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 112s 3s/step - loss: 0.1135 - add_53_loss: 6.1553e-04 - model_5_loss: 0.1129 - val_loss: 0.0993 - val_add_53_loss: 6.1246e-04 - val_model_5_loss: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|â–ˆâ–ˆâ–       | 4/18 [47:29<2:49:36, 726.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 66.72%\n",
            ".... explained variance AE (Tt)  : 68.38%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1134 - add_53_loss: 4.7952e-04 - model_5_loss: 0.1129 - val_loss: 0.0990 - val_add_53_loss: 6.1692e-04 - val_model_5_loss: 0.0984\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1134 - add_53_loss: 4.8021e-04 - model_5_loss: 0.1129 - val_loss: 0.0994 - val_add_53_loss: 6.1096e-04 - val_model_5_loss: 0.0987\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 99s 2s/step - loss: 0.1133 - add_53_loss: 4.7811e-04 - model_5_loss: 0.1128 - val_loss: 0.0991 - val_add_53_loss: 6.1196e-04 - val_model_5_loss: 0.0984\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1133 - add_53_loss: 4.7812e-04 - model_5_loss: 0.1128 - val_loss: 0.0991 - val_add_53_loss: 6.1223e-04 - val_model_5_loss: 0.0985\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 93s 2s/step - loss: 0.1133 - add_53_loss: 4.7834e-04 - model_5_loss: 0.1128 - val_loss: 0.0992 - val_add_53_loss: 6.1006e-04 - val_model_5_loss: 0.0986\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 94s 2s/step - loss: 0.1132 - add_53_loss: 4.7770e-04 - model_5_loss: 0.1127 - val_loss: 0.0990 - val_add_53_loss: 6.1025e-04 - val_model_5_loss: 0.0984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|â–ˆâ–ˆâ–Š       | 5/18 [58:17<2:32:24, 703.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 66.85%\n",
            ".... explained variance AE (Tt)  : 68.49%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1132 - add_53_loss: 4.7730e-04 - model_5_loss: 0.1127 - val_loss: 0.0990 - val_add_53_loss: 6.1111e-04 - val_model_5_loss: 0.0984\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1131 - add_53_loss: 4.7638e-04 - model_5_loss: 0.1127 - val_loss: 0.0988 - val_add_53_loss: 6.1188e-04 - val_model_5_loss: 0.0982\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1132 - add_53_loss: 4.7864e-04 - model_5_loss: 0.1127 - val_loss: 0.0993 - val_add_53_loss: 6.0730e-04 - val_model_5_loss: 0.0987\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1131 - add_53_loss: 4.7607e-04 - model_5_loss: 0.1126 - val_loss: 0.0987 - val_add_53_loss: 6.1090e-04 - val_model_5_loss: 0.0981\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 102s 2s/step - loss: 0.1131 - add_53_loss: 4.7666e-04 - model_5_loss: 0.1126 - val_loss: 0.0992 - val_add_53_loss: 6.0707e-04 - val_model_5_loss: 0.0986\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 101s 2s/step - loss: 0.1131 - add_53_loss: 4.7637e-04 - model_5_loss: 0.1127 - val_loss: 0.0987 - val_add_53_loss: 6.0910e-04 - val_model_5_loss: 0.0981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [1:09:14<2:17:52, 689.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 66.94%\n",
            ".... explained variance AE (Tt)  : 68.57%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 99s 2s/step - loss: 0.1130 - add_53_loss: 4.7486e-04 - model_5_loss: 0.1125 - val_loss: 0.0985 - val_add_53_loss: 6.1513e-04 - val_model_5_loss: 0.0979\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1131 - add_53_loss: 4.7773e-04 - model_5_loss: 0.1126 - val_loss: 0.0989 - val_add_53_loss: 6.0700e-04 - val_model_5_loss: 0.0983\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1130 - add_53_loss: 4.7503e-04 - model_5_loss: 0.1125 - val_loss: 0.0986 - val_add_53_loss: 6.0857e-04 - val_model_5_loss: 0.0980\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1130 - add_53_loss: 4.7578e-04 - model_5_loss: 0.1125 - val_loss: 0.0988 - val_add_53_loss: 6.0569e-04 - val_model_5_loss: 0.0982\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1129 - add_53_loss: 4.7463e-04 - model_5_loss: 0.1125 - val_loss: 0.0987 - val_add_53_loss: 6.0757e-04 - val_model_5_loss: 0.0981\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1129 - add_53_loss: 4.7436e-04 - model_5_loss: 0.1124 - val_loss: 0.0986 - val_add_53_loss: 6.0802e-04 - val_model_5_loss: 0.0979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [1:19:58<2:03:52, 675.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.02%\n",
            ".... explained variance AE (Tt)  : 68.63%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 101s 2s/step - loss: 0.1129 - add_53_loss: 4.7357e-04 - model_5_loss: 0.1124 - val_loss: 0.0985 - val_add_53_loss: 6.0786e-04 - val_model_5_loss: 0.0979\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1129 - add_53_loss: 4.7408e-04 - model_5_loss: 0.1125 - val_loss: 0.0985 - val_add_53_loss: 6.0709e-04 - val_model_5_loss: 0.0979\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1129 - add_53_loss: 4.7548e-04 - model_5_loss: 0.1124 - val_loss: 0.0987 - val_add_53_loss: 6.0525e-04 - val_model_5_loss: 0.0981\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1128 - add_53_loss: 4.7297e-04 - model_5_loss: 0.1124 - val_loss: 0.0983 - val_add_53_loss: 6.0647e-04 - val_model_5_loss: 0.0977\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1128 - add_53_loss: 4.7380e-04 - model_5_loss: 0.1123 - val_loss: 0.0985 - val_add_53_loss: 6.0557e-04 - val_model_5_loss: 0.0979\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1128 - add_53_loss: 4.7357e-04 - model_5_loss: 0.1123 - val_loss: 0.0985 - val_add_53_loss: 6.0498e-04 - val_model_5_loss: 0.0979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [1:30:46<1:51:15, 667.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.15%\n",
            ".... explained variance AE (Tt)  : 68.75%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 94s 2s/step - loss: 0.1128 - add_53_loss: 4.7284e-04 - model_5_loss: 0.1124 - val_loss: 0.0987 - val_add_53_loss: 6.0410e-04 - val_model_5_loss: 0.0981\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1128 - add_53_loss: 4.7211e-04 - model_5_loss: 0.1124 - val_loss: 0.0982 - val_add_53_loss: 6.0714e-04 - val_model_5_loss: 0.0976\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1127 - add_53_loss: 4.7282e-04 - model_5_loss: 0.1123 - val_loss: 0.0984 - val_add_53_loss: 6.0637e-04 - val_model_5_loss: 0.0978\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1127 - add_53_loss: 4.7438e-04 - model_5_loss: 0.1122 - val_loss: 0.0988 - val_add_53_loss: 6.0339e-04 - val_model_5_loss: 0.0982\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 95s 2s/step - loss: 0.1128 - add_53_loss: 4.7148e-04 - model_5_loss: 0.1123 - val_loss: 0.0981 - val_add_53_loss: 6.1815e-04 - val_model_5_loss: 0.0975\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1129 - add_53_loss: 4.7425e-04 - model_5_loss: 0.1125 - val_loss: 0.0981 - val_add_53_loss: 6.0962e-04 - val_model_5_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [1:41:43<1:39:38, 664.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.08%\n",
            ".... explained variance AE (Tt)  : 68.65%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 101s 2s/step - loss: 0.1127 - add_53_loss: 4.7217e-04 - model_5_loss: 0.1122 - val_loss: 0.0984 - val_add_53_loss: 6.0419e-04 - val_model_5_loss: 0.0978\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1127 - add_53_loss: 4.7150e-04 - model_5_loss: 0.1122 - val_loss: 0.0983 - val_add_53_loss: 6.0526e-04 - val_model_5_loss: 0.0977\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 106s 3s/step - loss: 0.1127 - add_53_loss: 4.7263e-04 - model_5_loss: 0.1122 - val_loss: 0.0984 - val_add_53_loss: 6.0475e-04 - val_model_5_loss: 0.0977\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 104s 3s/step - loss: 0.1126 - add_53_loss: 4.7103e-04 - model_5_loss: 0.1121 - val_loss: 0.0981 - val_add_53_loss: 6.0736e-04 - val_model_5_loss: 0.0975\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 95s 2s/step - loss: 0.1127 - add_53_loss: 4.7248e-04 - model_5_loss: 0.1122 - val_loss: 0.0981 - val_add_53_loss: 6.1301e-04 - val_model_5_loss: 0.0974\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1127 - add_53_loss: 4.7219e-04 - model_5_loss: 0.1122 - val_loss: 0.0980 - val_add_53_loss: 6.0893e-04 - val_model_5_loss: 0.0974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [1:52:39<1:28:15, 661.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.13%\n",
            ".... explained variance AE (Tt)  : 68.69%\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_48 (Lambda)              (None, 64, 64, 1)    0           input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_49 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       lambda_48[0][0]                  \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 add_54[0][0]                     \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 add_55[0][0]                     \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 add_56[0][0]                     \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 add_57[0][0]                     \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 add_58[0][0]                     \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_51 (Lambda)              (None, 64, 64, 1)    0           lambda_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_52 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_50 (Lambda)              (None, 64, 64, 1)    0           lambda_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_53 (Multiply)          (None, 64, 64, 1)    0           lambda_51[0][0]                  \n",
            "                                                                 lambda_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_52 (Multiply)          (None, 64, 64, 1)    0           model_2[16][0]                   \n",
            "                                                                 lambda_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 64, 64, 1)    0           multiply_53[0][0]                \n",
            "                                                                 multiply_52[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_54 (Lambda)              (None, 64, 64, 1)    0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_55 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_53 (Lambda)              (None, 64, 64, 1)    0           lambda_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_55 (Multiply)          (None, 64, 64, 1)    0           lambda_54[0][0]                  \n",
            "                                                                 lambda_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_54 (Multiply)          (None, 64, 64, 1)    0           model_2[17][0]                   \n",
            "                                                                 lambda_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 64, 64, 1)    0           multiply_55[0][0]                \n",
            "                                                                 multiply_54[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_57 (Lambda)              (None, 64, 64, 1)    0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_58 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_56 (Lambda)              (None, 64, 64, 1)    0           lambda_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_57 (Multiply)          (None, 64, 64, 1)    0           lambda_57[0][0]                  \n",
            "                                                                 lambda_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_56 (Multiply)          (None, 64, 64, 1)    0           model_2[18][0]                   \n",
            "                                                                 lambda_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 64, 64, 1)    0           multiply_57[0][0]                \n",
            "                                                                 multiply_56[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_60 (Lambda)              (None, 64, 64, 1)    0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_61 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_59 (Lambda)              (None, 64, 64, 1)    0           lambda_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_59 (Multiply)          (None, 64, 64, 1)    0           lambda_60[0][0]                  \n",
            "                                                                 lambda_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_58 (Multiply)          (None, 64, 64, 1)    0           model_2[19][0]                   \n",
            "                                                                 lambda_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 64, 64, 1)    0           multiply_59[0][0]                \n",
            "                                                                 multiply_58[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_63 (Lambda)              (None, 64, 64, 1)    0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_64 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_62 (Lambda)              (None, 64, 64, 1)    0           lambda_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_61 (Multiply)          (None, 64, 64, 1)    0           lambda_63[0][0]                  \n",
            "                                                                 lambda_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_60 (Multiply)          (None, 64, 64, 1)    0           model_2[20][0]                   \n",
            "                                                                 lambda_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 64, 64, 1)    0           multiply_61[0][0]                \n",
            "                                                                 multiply_60[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_65 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_7 (Functional)            (None, 64, 64, 1)    83576       input_10[0][0]                   \n",
            "                                                                 lambda_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_67 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       model_7[0][0]                    \n",
            "                                                                 lambda_67[0][0]                  \n",
            "                                                                 model_7[0][0]                    \n",
            "                                                                 lambda_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_69 (Lambda)              (None, 64, 64, 1)    0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_6 (Subtract)           (None, 64, 64, 1)    0           model_7[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_7 (Subtract)           (None, 64, 64, 1)    0           model_7[0][0]                    \n",
            "                                                                 model_2[22][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_62 (Multiply)          (None, 64, 64, 1)    0           subtract_6[0][0]                 \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_64 (Multiply)          (None, 64, 64, 1)    0           subtract_7[0][0]                 \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_8 (Subtract)           (None, 64, 64, 1)    0           model_2[23][0]                   \n",
            "                                                                 model_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_63 (Multiply)          (None, 64, 64, 1)    0           multiply_62[0][0]                \n",
            "                                                                 multiply_62[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_65 (Multiply)          (None, 64, 64, 1)    0           multiply_64[0][0]                \n",
            "                                                                 multiply_64[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_66 (Multiply)          (None, 64, 64, 1)    0           subtract_8[0][0]                 \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_63[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_65[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_67 (Multiply)          (None, 64, 64, 1)    0           multiply_66[0][0]                \n",
            "                                                                 multiply_66[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_6 (Glo (None, 1)            0           reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_7 (Glo (None, 1)            0           reshape_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_16 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_67[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 1)            0           global_average_pooling3d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 1)            0           global_average_pooling3d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_8 (Glo (None, 1)            0           reshape_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_66 (Lambda)              (None, 1)            0           reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_68 (Lambda)              (None, 1)            0           reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_17 (Reshape)            (None, 1)            0           global_average_pooling3d_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 1)            0           lambda_66[0][0]                  \n",
            "                                                                 lambda_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_70 (Lambda)              (None, 1)            0           reshape_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 1)            0           add_59[0][0]                     \n",
            "                                                                 lambda_70[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/6\n",
            "(11, 11, 1, 20)\n",
            "(11, 11, 1, 20)\n",
            "41/41 [==============================] - 143s 2s/step - loss: 0.1208 - add_60_loss: 4.2272e-04 - model_7_loss: 0.1204 - val_loss: 0.0981 - val_add_60_loss: 6.0690e-04 - val_model_7_loss: 0.0975\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 82s 2s/step - loss: 0.1074 - add_60_loss: 5.5805e-04 - model_7_loss: 0.1069 - val_loss: 0.0982 - val_add_60_loss: 6.0553e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 83s 2s/step - loss: 0.1106 - add_60_loss: 5.1592e-04 - model_7_loss: 0.1101 - val_loss: 0.0982 - val_add_60_loss: 6.0572e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 83s 2s/step - loss: 0.0983 - add_60_loss: 4.9622e-04 - model_7_loss: 0.0978 - val_loss: 0.0982 - val_add_60_loss: 6.0515e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 84s 2s/step - loss: 0.1050 - add_60_loss: 5.1794e-04 - model_7_loss: 0.1045 - val_loss: 0.0982 - val_add_60_loss: 6.0461e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 84s 2s/step - loss: 0.1093 - add_60_loss: 4.4788e-04 - model_7_loss: 0.1088 - val_loss: 0.0982 - val_add_60_loss: 6.0492e-04 - val_model_7_loss: 0.0976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [2:02:46<1:15:16, 645.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.24%\n",
            ".... explained variance AE (Tt)  : 68.81%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1125 - add_60_loss: 4.7126e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0501e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1125 - add_60_loss: 4.7133e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0514e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1125 - add_60_loss: 4.7124e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0486e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1125 - add_60_loss: 4.7125e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0501e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1125 - add_60_loss: 4.7109e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0479e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1125 - add_60_loss: 4.7143e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0550e-04 - val_model_7_loss: 0.0976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [2:13:34<1:04:37, 646.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.23%\n",
            ".... explained variance AE (Tt)  : 68.80%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 94s 2s/step - loss: 0.1125 - add_60_loss: 4.7116e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0474e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1124 - add_60_loss: 4.7104e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0488e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 114s 3s/step - loss: 0.1124 - add_60_loss: 4.7109e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0466e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 115s 3s/step - loss: 0.1124 - add_60_loss: 4.7103e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0451e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 117s 3s/step - loss: 0.1124 - add_60_loss: 4.7101e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0467e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 117s 3s/step - loss: 0.1124 - add_60_loss: 4.7131e-04 - model_7_loss: 0.1120 - val_loss: 0.0981 - val_add_60_loss: 6.0541e-04 - val_model_7_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [2:25:26<55:29, 665.93s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.23%\n",
            ".... explained variance AE (Tt)  : 68.80%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1124 - add_60_loss: 4.7125e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0455e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 96s 2s/step - loss: 0.1124 - add_60_loss: 4.7092e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0460e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 99s 2s/step - loss: 0.1124 - add_60_loss: 4.7103e-04 - model_7_loss: 0.1120 - val_loss: 0.0981 - val_add_60_loss: 6.0488e-04 - val_model_7_loss: 0.0975\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 117s 3s/step - loss: 0.1125 - add_60_loss: 4.7080e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0424e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 116s 3s/step - loss: 0.1124 - add_60_loss: 4.7104e-04 - model_7_loss: 0.1120 - val_loss: 0.0981 - val_add_60_loss: 6.0483e-04 - val_model_7_loss: 0.0975\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 117s 3s/step - loss: 0.1124 - add_60_loss: 4.7097e-04 - model_7_loss: 0.1120 - val_loss: 0.0981 - val_add_60_loss: 6.0495e-04 - val_model_7_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [2:37:11<45:09, 677.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.25%\n",
            ".... explained variance AE (Tt)  : 68.82%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 136s 3s/step - loss: 0.1124 - add_60_loss: 4.7112e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0463e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 139s 3s/step - loss: 0.1124 - add_60_loss: 4.7084e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0431e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 140s 3s/step - loss: 0.1124 - add_60_loss: 4.7083e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0449e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 136s 3s/step - loss: 0.1124 - add_60_loss: 4.7072e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0417e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 134s 3s/step - loss: 0.1124 - add_60_loss: 4.7084e-04 - model_7_loss: 0.1120 - val_loss: 0.0982 - val_add_60_loss: 6.0441e-04 - val_model_7_loss: 0.0976\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 135s 3s/step - loss: 0.1124 - add_60_loss: 4.7102e-04 - model_7_loss: 0.1120 - val_loss: 0.0981 - val_add_60_loss: 6.0468e-04 - val_model_7_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [2:52:00<37:02, 740.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.26%\n",
            ".... explained variance AE (Tt)  : 68.83%\n",
            "..... Update/initialize number of projections in DINCOnvAE model # 5\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_71 (Lambda)              (None, 64, 64, 1)    0           input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_72 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       lambda_71[0][0]                  \n",
            "                                                                 input_13[0][0]                   \n",
            "                                                                 add_61[0][0]                     \n",
            "                                                                 input_13[0][0]                   \n",
            "                                                                 add_62[0][0]                     \n",
            "                                                                 input_13[0][0]                   \n",
            "                                                                 add_63[0][0]                     \n",
            "                                                                 input_13[0][0]                   \n",
            "                                                                 add_64[0][0]                     \n",
            "                                                                 input_13[0][0]                   \n",
            "                                                                 add_65[0][0]                     \n",
            "                                                                 input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_74 (Lambda)              (None, 64, 64, 1)    0           lambda_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_75 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_73 (Lambda)              (None, 64, 64, 1)    0           lambda_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_69 (Multiply)          (None, 64, 64, 1)    0           lambda_74[0][0]                  \n",
            "                                                                 lambda_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_68 (Multiply)          (None, 64, 64, 1)    0           model_2[24][0]                   \n",
            "                                                                 lambda_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 64, 64, 1)    0           multiply_69[0][0]                \n",
            "                                                                 multiply_68[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_77 (Lambda)              (None, 64, 64, 1)    0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_78 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_76 (Lambda)              (None, 64, 64, 1)    0           lambda_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_71 (Multiply)          (None, 64, 64, 1)    0           lambda_77[0][0]                  \n",
            "                                                                 lambda_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_70 (Multiply)          (None, 64, 64, 1)    0           model_2[25][0]                   \n",
            "                                                                 lambda_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 64, 64, 1)    0           multiply_71[0][0]                \n",
            "                                                                 multiply_70[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_80 (Lambda)              (None, 64, 64, 1)    0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_81 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_79 (Lambda)              (None, 64, 64, 1)    0           lambda_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_73 (Multiply)          (None, 64, 64, 1)    0           lambda_80[0][0]                  \n",
            "                                                                 lambda_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_72 (Multiply)          (None, 64, 64, 1)    0           model_2[26][0]                   \n",
            "                                                                 lambda_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 64, 64, 1)    0           multiply_73[0][0]                \n",
            "                                                                 multiply_72[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_83 (Lambda)              (None, 64, 64, 1)    0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_84 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_82 (Lambda)              (None, 64, 64, 1)    0           lambda_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_75 (Multiply)          (None, 64, 64, 1)    0           lambda_83[0][0]                  \n",
            "                                                                 lambda_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_74 (Multiply)          (None, 64, 64, 1)    0           model_2[27][0]                   \n",
            "                                                                 lambda_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 64, 64, 1)    0           multiply_75[0][0]                \n",
            "                                                                 multiply_74[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_86 (Lambda)              (None, 64, 64, 1)    0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_87 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_85 (Lambda)              (None, 64, 64, 1)    0           lambda_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_77 (Multiply)          (None, 64, 64, 1)    0           lambda_86[0][0]                  \n",
            "                                                                 lambda_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_76 (Multiply)          (None, 64, 64, 1)    0           model_2[28][0]                   \n",
            "                                                                 lambda_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 64, 64, 1)    0           multiply_77[0][0]                \n",
            "                                                                 multiply_76[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_88 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_9 (Functional)            (None, 64, 64, 1)    83576       input_12[0][0]                   \n",
            "                                                                 lambda_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_90 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 64, 64, 1)    83576       model_9[0][0]                    \n",
            "                                                                 lambda_90[0][0]                  \n",
            "                                                                 model_9[0][0]                    \n",
            "                                                                 lambda_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_92 (Lambda)              (None, 64, 64, 1)    0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_9 (Subtract)           (None, 64, 64, 1)    0           model_9[0][0]                    \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_10 (Subtract)          (None, 64, 64, 1)    0           model_9[0][0]                    \n",
            "                                                                 model_2[30][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_78 (Multiply)          (None, 64, 64, 1)    0           subtract_9[0][0]                 \n",
            "                                                                 input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_80 (Multiply)          (None, 64, 64, 1)    0           subtract_10[0][0]                \n",
            "                                                                 input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_11 (Subtract)          (None, 64, 64, 1)    0           model_2[31][0]                   \n",
            "                                                                 model_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_79 (Multiply)          (None, 64, 64, 1)    0           multiply_78[0][0]                \n",
            "                                                                 multiply_78[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_81 (Multiply)          (None, 64, 64, 1)    0           multiply_80[0][0]                \n",
            "                                                                 multiply_80[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_82 (Multiply)          (None, 64, 64, 1)    0           subtract_11[0][0]                \n",
            "                                                                 input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_18 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_79[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_20 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_81[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_83 (Multiply)          (None, 64, 64, 1)    0           multiply_82[0][0]                \n",
            "                                                                 multiply_82[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_9 (Glo (None, 1)            0           reshape_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_10 (Gl (None, 1)            0           reshape_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_22 (Reshape)            (None, 64, 64, 1, 1) 0           multiply_83[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_19 (Reshape)            (None, 1)            0           global_average_pooling3d_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "reshape_21 (Reshape)            (None, 1)            0           global_average_pooling3d_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_11 (Gl (None, 1)            0           reshape_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_89 (Lambda)              (None, 1)            0           reshape_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_91 (Lambda)              (None, 1)            0           reshape_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_23 (Reshape)            (None, 1)            0           global_average_pooling3d_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 1)            0           lambda_89[0][0]                  \n",
            "                                                                 lambda_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_93 (Lambda)              (None, 1)            0           reshape_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 1)            0           add_66[0][0]                     \n",
            "                                                                 lambda_93[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 83,576\n",
            "Trainable params: 83,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/6\n",
            "(11, 11, 1, 20)\n",
            "(11, 11, 1, 20)\n",
            "41/41 [==============================] - 165s 3s/step - loss: 0.1164 - add_67_loss: 4.3825e-04 - model_9_loss: 0.1160 - val_loss: 0.0981 - val_add_67_loss: 6.0456e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 99s 2s/step - loss: 0.1101 - add_67_loss: 5.1171e-04 - model_9_loss: 0.1096 - val_loss: 0.0981 - val_add_67_loss: 6.0461e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 100s 2s/step - loss: 0.1095 - add_67_loss: 5.2843e-04 - model_9_loss: 0.1089 - val_loss: 0.0981 - val_add_67_loss: 6.0464e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 98s 2s/step - loss: 0.1095 - add_67_loss: 4.3670e-04 - model_9_loss: 0.1091 - val_loss: 0.0981 - val_add_67_loss: 6.0458e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 97s 2s/step - loss: 0.1146 - add_67_loss: 4.7797e-04 - model_9_loss: 0.1141 - val_loss: 0.0981 - val_add_67_loss: 6.0454e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 116s 3s/step - loss: 0.1052 - add_67_loss: 4.8428e-04 - model_9_loss: 0.1047 - val_loss: 0.0981 - val_add_67_loss: 6.0459e-04 - val_model_9_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [3:04:48<24:58, 749.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.26%\n",
            ".... explained variance AE (Tt)  : 68.83%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 117s 3s/step - loss: 0.1124 - add_67_loss: 4.7088e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0454e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 120s 3s/step - loss: 0.1124 - add_67_loss: 4.7088e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0457e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 118s 3s/step - loss: 0.1124 - add_67_loss: 4.7088e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0456e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 120s 3s/step - loss: 0.1124 - add_67_loss: 4.7085e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0450e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 121s 3s/step - loss: 0.1124 - add_67_loss: 4.7086e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0451e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 120s 3s/step - loss: 0.1124 - add_67_loss: 4.7085e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0452e-04 - val_model_9_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [3:17:40<12:36, 756.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.26%\n",
            ".... explained variance AE (Tt)  : 68.83%\n",
            "Epoch 1/6\n",
            "41/41 [==============================] - 101s 2s/step - loss: 0.1124 - add_67_loss: 4.7086e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0453e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 2/6\n",
            "41/41 [==============================] - 102s 2s/step - loss: 0.1124 - add_67_loss: 4.7087e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0451e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 3/6\n",
            "41/41 [==============================] - 101s 2s/step - loss: 0.1124 - add_67_loss: 4.7085e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0452e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 4/6\n",
            "41/41 [==============================] - 102s 2s/step - loss: 0.1124 - add_67_loss: 4.7086e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0450e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 5/6\n",
            "41/41 [==============================] - 103s 3s/step - loss: 0.1124 - add_67_loss: 4.7086e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0455e-04 - val_model_9_loss: 0.0975\n",
            "Epoch 6/6\n",
            "41/41 [==============================] - 104s 3s/step - loss: 0.1124 - add_67_loss: 4.7084e-04 - model_9_loss: 0.1119 - val_loss: 0.0981 - val_add_67_loss: 6.0446e-04 - val_model_9_loss: 0.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [3:28:33<00:00, 695.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".......... Auto-encoder performance when applied to gap-free data\n",
            ".... explained variance AE (Tr)  : 67.27%\n",
            ".... explained variance AE (Tt)  : 68.83%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYGiJA8lvpZ-"
      },
      "source": [
        "### PrÃ©diction / Interpolation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl3eUXPVvpZ_"
      },
      "source": [
        "Pred_GM = global_model_FP.predict([y_pred_missing,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "Pred_AE = model_AE.predict([y_pred_missing,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "\n",
        "#.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O46naj1sfJ9m"
      },
      "source": [
        "Pred_AE_norm = stdsc.inverse_transform(Pred_AE.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = stdsc.inverse_transform(Pred_GM.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fZum6PJXi25"
      },
      "source": [
        "Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+medabs) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+medabs).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEF-7BCz6n9M"
      },
      "source": [
        "Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+mean_Tr) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "\n",
        "#Pred_GM = ((Pred_GM*std_Tr)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "#Pred_GM_msk_norm = stdsc.inverse_transform(Pred_GM_mask.reshape(len(y_pred),-1)).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6mAqLFFqJoP",
        "outputId": "aaa7a46b-11db-49ba-eade-724ca1dd41fc"
      },
      "source": [
        "print(Pred_GM_norm.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(360, 64, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqM26-Gjuw3y"
      },
      "source": [
        "Pred_AE_norm[np.where(Pred_AE_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n",
        "Pred_GM_norm[np.where(Pred_GM_norm>np.nanmax(gt_pred))]=np.nanmax(gt_pred)\n",
        "Pred_AE_norm[np.where(Pred_AE_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n",
        "Pred_GM_norm[np.where(Pred_GM_norm<np.nanmin(gt_pred))]=np.nanmin(gt_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAqH_TH7pjLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "c45d0de7-978e-46fa-f3b9-eb6a50c86087"
      },
      "source": [
        "i=0\n",
        "plt.subplot(221)\n",
        "plt.imshow(Pred_GM_norm.reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[0])\n",
        "plt.colorbar()\n",
        "plt.subplot(222)\n",
        "plt.imshow(Pred_GM_norm.reshape(Pred_GM_norm.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])[50])\n",
        "plt.colorbar()\n",
        "\n",
        "print(np.nanmax(Pred_GM_norm),np.nanmax(Pred_AE_norm),np.nanmax(gt_pred))\n",
        "print(np.nanmin(Pred_GM_norm),np.nanmin(Pred_AE_norm),np.nanmin(gt_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.4053140266074076 -1.7323652999268637 -0.5334281921386719\n",
            "-4.0007500854553655 -4.000840831664391 -4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Y0nL_QsB6C"
      },
      "source": [
        "plt.imshow()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNx-Zi_4q0qV",
        "outputId": "bd03399b-e574-44ad-d206-7af24dfd629a"
      },
      "source": [
        "meantrue=np.empty(len(gt_pred))\n",
        "meanpred=np.copy(meantrue)\n",
        "for i in range(len(gt_pred)):\n",
        "  meanpred[i]=np.nanmean(Pred_AE_norm[i])\n",
        "  meantrue[i]=np.nanmean(gt_pred[i])\n",
        "plt.plot(meanpred)\n",
        "plt.plot(meantrue)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbec66afa90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIf6haKOSsX"
      },
      "source": [
        "# Some metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbOIMlSGURRi",
        "outputId": "60f6bebc-9ea8-4d5e-d3f7-623ea75fabab"
      },
      "source": [
        "#from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.nanmean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def RMSE(a,b):\n",
        "    \"\"\" Compute the Root Mean Square Error between 2 n-dimensional vectors. \"\"\" \n",
        "    return np.sqrt(np.nanmean((a-b)**2))\n",
        "\n",
        "\n",
        "def Getmetrics(Target,Pred):\n",
        "    Target_value = Target.reshape(Target.shape)[np.where(~np.isnan(Target))]\n",
        "    Pred_value   = Pred.reshape(Target.shape)[np.where(~np.isnan(Target))]\n",
        "    Target_flat  = Target_value.flatten()\n",
        "    Pred_flat    = Pred_value.flatten()\n",
        "    Metrics=dict()\n",
        "\n",
        "    return {'EVS':explained_variance_score(Target_flat,Pred_flat),'RMSE':RMSE(Target_flat,Pred_flat),'NRMSE':RMSE(Target_flat,Pred_flat)/np.nanmean(Target_flat),'MAbsEr%':mean_absolute_percentage_error(Target_flat,Pred_flat),'MaxEr':max_error(Target_flat,Pred_flat),'MAbsEr':median_absolute_error(Target_flat,Pred_flat),'RÂ²':r2_score(Target_flat,Pred_flat)}\n",
        "\n",
        "   #lissage donnÃ©e entrÃ©e flatn + nan\n",
        "#Metric=Getmetrics(stdsc.fit_transform(gt_pred.reshape(len(y_pred),-1)),Pred_GM )\n",
        "testAE=np.copy(Pred_AE_norm)\n",
        "testAE[np.where(testAE<np.nanmin(gt_pred))]=np.nanmin(gt_pred)\n",
        "#print(np.nanmin(testAE))\n",
        "MetricGM=Getmetrics(gt_pred,Pred_GM_norm)\n",
        "MetricAE=Getmetrics(gt_pred,Pred_AE_norm)\n",
        "print(MetricGM,MetricAE)\n",
        "print(Getmetrics(gt_pred,testAE),Getmetrics(gt_pred,Pred_AE_norm),MetricGM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'EVS': 0.7327389851907187, 'RMSE': 0.28132012671795137, 'NRMSE': -0.07628929802424594, 'MAbsEr%': 5.355910060013508, 'MaxEr': 1.7077053272061877, 'MAbsEr': 0.08686242196207683, 'RÂ²': 0.719328967552334} {'EVS': 0.6778243973825961, 'RMSE': 0.30193940823726484, 'NRMSE': -0.08188090119613645, 'MAbsEr%': 5.862410385339343, 'MaxEr': 1.7077053272061877, 'MAbsEr': 0.08514354877077279, 'RÂ²': 0.6766777573140119}\n",
            "{'EVS': 0.6778244019037626, 'RMSE': 0.30193940822706306, 'NRMSE': -0.0818809011933699, 'MAbsEr%': 5.862409503387738, 'MaxEr': 1.7077053272061877, 'MAbsEr': 0.08514354877077279, 'RÂ²': 0.6766777573358604} {'EVS': 0.6778243973825961, 'RMSE': 0.30193940823726484, 'NRMSE': -0.08188090119613645, 'MAbsEr%': 5.862410385339343, 'MaxEr': 1.7077053272061877, 'MAbsEr': 0.08514354877077279, 'RÂ²': 0.6766777573140119} {'EVS': 0.7327389851907187, 'RMSE': 0.28132012671795137, 'NRMSE': -0.07628929802424594, 'MAbsEr%': 5.355910060013508, 'MaxEr': 1.7077053272061877, 'MAbsEr': 0.08686242196207683, 'RÂ²': 0.719328967552334}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Unvvl9mB2Bm"
      },
      "source": [
        "np.save('/content/drive/MyDrive/GENN_pred_normbestP00',testAE)\n",
        "np.save('/content/drive/MyDrive/GENN_GM_norm200',Pred_GM_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaQwDECHhn8u",
        "outputId": "49c7fd8a-5218-4fa2-e117-7d52e5e0d5b1"
      },
      "source": [
        "global_model_FP.save(\"/content/drive/MyDrive/modelGENN1.h5\")\n",
        "model_AE.save(\"/content/drive/MyDrive/modelGENN.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Hhd6tSXCt8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "df2df602-d1fc-4347-9635-07658c25c4cf"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/modelGENN.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        " \n",
        "# load model\n",
        "model = load_model('modelGENN.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7600f359cd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/modelGENN.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloadtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq06kb4Pjoe_"
      },
      "source": [
        "seriepred=[]\n",
        "for i in range(len(y_pred)-45):\n",
        "    seriepred.append(y_pred_missing[i:i+45])\n",
        "SP=np.array(seriepred)\n",
        "SP[:,15:,:,:]=np.nan\n",
        "mask_sp=np.copy(SP)\n",
        "mask_sp[np.where(np.isnan(mask_sp))]=0;mask_sp[np.where(mask_sp!=0)]=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-vxcJRnhJTm"
      },
      "source": [
        "y_sp_predAE=np.copy(SP.reshape(SP.shape[0],SP.shape[1],SP.shape[2],SP.shape[3]))\n",
        "y_sp_predGM=np.copy(y_sp_predAE)\n",
        "def predsp(y_pred,mask_pred):\n",
        "    gt_pred=y_pred.reshape(y_pred.shape[0],y_pred.shape[1],y_pred.shape[2])\n",
        "\n",
        "    Pred_GM = global_model_FP.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "    Pred_AE = model_AE.predict([y_pred,mask_pred]).reshape(gt_pred.shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "\n",
        "    Pred_AE_norm = (Pred_AE.reshape(len(y_pred),-1)+mean_Tr) .reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "    Pred_GM_norm = (Pred_GM.reshape(len(y_pred),-1)+mean_Tr).reshape(Pred_AE.shape[0],Pred_AE.shape[1],Pred_AE.shape[2])\n",
        "    return Pred_AE_norm,Pred_GM_norm\n",
        "\n",
        "for i in range(len(SP)):\n",
        "  y_sp_predAE[i], y_sp_predGM[i]=predsp(SP[i],mask_sp[i])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "QXRTkvMOtFyO",
        "outputId": "5ecafa9b-6283-44d0-cfab-ffa53bcbdb8e"
      },
      "source": [
        "plt.imshow(y_sp_predAE[50,30])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fcac7d0bb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGpPjY8Rle3L"
      },
      "source": [
        "np.save('/content/drive/MyDrive/GENN_pred_SPAE',y_sp_predAE)\n",
        "np.save('/content/drive/MyDrive/GENN_pred_SPGM',y_sp_predAE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnvjMmNx8Bht",
        "outputId": "64d8b8e0-ff3f-41a3-b036-ed51f5d4b07a"
      },
      "source": [
        "flagPred = True\n",
        "seriepred=[]\n",
        "seriepredmask=[]\n",
        "Tseriepred=[]\n",
        "for i in range(len(y_pred)-45):\n",
        "    seriepred.append(y_pred_missing[i:i+45])\n",
        "    seriepredmask.append(mask_pred[i:i+45])\n",
        "    Tseriepred.append(y_pred[i:i+45])\n",
        "SP=np.array(seriepred)\n",
        "SPm=np.array(seriepredmask)\n",
        "TSP=np.array(Tseriepred)\n",
        "del (seriepred,seriepredmask,Tseriepred)\n",
        "TSP=(TSP.reshape(len(SP),SP.shape[1],-1)+mean_Tr).reshape(TSP.shape[0],TSP.shape[1],TSP.shape[2],TSP.shape[3])\n",
        "if flagPred:\n",
        "  SP[:,30:45]=np.nan\n",
        "  SPm[:,30:45]=0\n",
        "  \n",
        "print(SP.shape)\n",
        "Pred_GM_all = np.full((SP.shape[0],SP.shape[1],SP.shape[2],SP.shape[3]),np.nan)\n",
        "Pred_AE_all = np.copy(Pred_GM_all)\n",
        "for i in tqdm(range(len(SP))):\n",
        "  Pred_GM_all[i] = global_model_FP.predict([SP[i],SPm[i]]).reshape(SP[i].shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "  Pred_AE_all[i] = model_AE.predict([SP[i],SPm[i]]).reshape(SP[i].shape[0],gt_pred.shape[1],gt_pred.shape[2])\n",
        "\n",
        "Pred_AE_all_norm = (Pred_AE_all.reshape(len(SP),SP.shape[1],-1)).reshape(SP.shape[0],SP.shape[1],SP.shape[2],SP.shape[3])\n",
        "Pred_GM_all_norm = (Pred_GM_all.reshape(len(SP),SP.shape[1],-1)).reshape(SP.shape[0],SP.shape[1],SP.shape[2],SP.shape[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/315 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(315, 45, 64, 64, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 315/315 [01:06<00:00,  4.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6Uan_xX4hAr",
        "outputId": "76900836-0307-4d5d-9b6e-43a6c0070bdc"
      },
      "source": [
        "test=Pred_GM_all_norm[4,30:]-Pred_GM_all_norm[50,30:]\n",
        "print(np.nanmin(test),np.nanmax(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "7-cio-e3EFlD",
        "outputId": "5015e189-563f-4ae4-a769-ab283088081c"
      },
      "source": [
        "meanGM=np.empty(len(Pred_GM_all_norm))\n",
        "meanAE=np.empty(len(Pred_GM_all_norm))\n",
        "meantarget= np.copy(meanGM)\n",
        "for i in tqdm(range(len(Pred_GM_all_norm))):\n",
        "  meanGM[i]=RMSE(Pred_GM_all_norm[i,30:],TSP[i,30:])\n",
        "  meantarget[i]=np.nanmean(TSP[i,30:])\n",
        "  meanAE[i]=np.nanmean(Pred_AE_all_norm[i,30:])\n",
        "plt.plot(meanGM)\n",
        "#plt.plot(meanAE)\n",
        "#plt.plot(meantarget)\n",
        "print(meantarget.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 315/315 [00:00<00:00, 998.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(315,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKss4mMMFSEU"
      },
      "source": [
        "seriepredi=[]\n",
        "for i in range(len(y_pred)-45):\n",
        "    seriepredi.append(testAE[i:i+45])\n",
        "SPui=np.array(seriepredi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfHS1KfssdUx"
      },
      "source": [
        "np.save('/content/drive/MyDrive/Pred_GENN',Pred_GM_all_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al8sqnKZxfzz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}